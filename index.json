[{"categories":null,"content":" For as long as I’ve been interested in software development, I’ve been interested in how software makes it onto a computer. “Works on my machine” was never quite enough… how would it work on someone else’s computer? Here’s a stroll down memory lane, starting from the 90s. ","date":"2023-04-23","objectID":"/posts/software-distribution/:0:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"QBasic (early 90s) In the early 90s, when I was about 8 years old, someone showed me that my computer came with a piece of software called QBasic - it came with the MS-DOS operating system. Although nobody in my family knew how to use it, and this was long before I had access to the internet, it came with an impressive set of examples as well as an interactive reference manual that I recall as being very thorough. Having messed around with it and made a few animations and utilities, I thought it would be cool to give copies to my classmates to play around with; y’know, like a professional software developer would. QBasic’s opening screen The software, as I wrote it, was a collection of source code files - just text files with a .BAS extension. For anyone to run those programs, they’d have to open QBasic themselves, select “File→Open”, navigate to my file, then use the “Run” menu to actually run the program. And presumably figure out how to exit QBasic when they’re done. Now, 8-year-olds in the 90s were used to computers being slightly harder to operate, e.g. typing out a command or two to open a game; indeed, friends did figure this out. But this still felt like a super janky way to distribute software. What I actually wanted to do was provide a “self-contained” program, one where you simply enter its name and it starts up, like any other DOS program I’d seen. Ideally, it would have the fashionable .EXE extension (the term “EXE file” seemed pretty much synonymous with “program”). Note - Batch files What I wanted to do was allow people to run LUTZKY1.BAS with one command. This could’ve been accomplished by adding a file LUTZKY1.BAT (BAT for MS-DOS Batch, not BAS) with these contents: @REM Turn off janky \"print each command\" behavior @REM Mind the load-bearing @ at the start of each line... @ECHO OFF QBASIC /RUN LUTZKY1.BAS I would’ve needed to terminate the program using the SYSTEM command rather than END. This way, indeed typing LUTZKY1 into the prompt would’ve run my program and exit normally. However: I don’t think I knew how to do that It still flashes the QBasic IDE on startup I was still relying on QBasic being installed on the destination machine, and I knew (though?) older versions of MS-DOS didn’t include it. Having things in multiple files still seemed “off”. I now wonder if I could’ve designed a file to work both as the batch file and as the BASIC file. I had heard rumor of the “professional, expensive” bit of software I needed - a compiler, which would perform the right magic to me a shiny, self-contained LUTZKY1.EXE. But this sounded like an expensive thing to even ask my parents for, never mind the fact I had no idea where one buys software - the local shops only seemed to stock games and office productivity software. Note In 2023, I found out that this software was called QuickBASIC… not confusing at all, surely the Q in QBasic didn’t stand for “Quick” and they weren’t both abbreviated “QB”. For whatever reason, this was important enough to me to try some truly wacky stuff. I vaguely remember messing around blindly with files on my computer, trying to generate an EXE file complete with an icon - efforts included taking something called the “PIF Editor”, which creates shortcuts to files and ostensibly adds icons to them… and replacing one of the system EXE files with it, in case the filename was “magical”. The real magic was young me learning the valuable lesson that I should’ve made a backup of this file before replacing it. ","date":"2023-04-23","objectID":"/posts/software-distribution/:1:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"Visual Basic (late 90s) By the late 90s, Windows 9x came around along with Microsoft Office, which had a wonderful capability: Visual Basic for Applications. this gave me my first experience writing actual GUI applications, strangely embedded within an Excel spreadsheet. Most memorably, Pokémon was a huge deal at the time, and I had created “APCO - A Pokémon Card Organizer” - a trivial deck building app. Note - Pokémon On April 1st, 1997, the very first episode of the Pokémon anime was shown on Israel, on channel 6; I was the official “hero of the day” guest, as a Pokémon expert. I got to this position by nitpicking on some “kids’ portal” website that their Pokémon page contained inaccuracies, which landed me a job as their Pokémon card strategy reviewer; I was 11, so they paid me in Pokémon cards. For the anime premiere I was interviewed by Dana Dvorin; I have sadly been unable to find any footage of this hilariously awkward interview. Once again, I wanted to distribute this software - perhaps using this magical thing I now had access to called The Internet. And, once again, sending an excel XLS file around with a big “click me to start the actual program button” seemed, well, janky. Amazingly, a friend had a copy of “really real Visual Basic” (the coveted compiler I had heard of), and was able to convert my janky app-in-XLS to a proper shiny EXE file. Slight caveat - there was a runtime library that had to be distributed alongside it, or it wouldn’t work. This got me looking at installers. All “serious” software was proudly using InstallShield (this was before these newfangled .MSI files - even the installer was a shiny .EXE!), but looking at a trial version left me scratching my head at how things should be organized. Finally, a self-extracting RAR file (yay shareware WinRAR) did the trick. I vaguely recall successfully uploading the finished product to some download site of the era, probably Tucows. If your software didn’t come this way in the 90s, was it even real software? ","date":"2023-04-23","objectID":"/posts/software-distribution/:2:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"Linux (early 2000s) In high school, I was first introduced to Linux. It (Mandrake 8.1) came in 3 CDs burned by a guy who couldn’t have seemed shadier if he had pulled them out of a trench-coat. Regardless, it was enlightening: How can this possibly be legally free? Wait, it just comes with a compiler? What do you mean the compiler doesn’t contain a GUI? It was a fascinating dive into understanding what my computer even is; while I was old enough to remember pre-Windows days, I had switched to Linux from Windows 981, so all of my experience with Windows was as a graphical wrapper running inside DOS. For instance, not having drive letters (A, B nor C) was wild. Note: Gentoo I didn’t spend long with Mandrake before switching to Gentoo Linux, where installing software is accomplished with the emerge command. The emerge command magically (to me, at the time) gets the software from the internet and compiles it. In my mind, I was Hackerman. In reality, it was more often “sorry dad, you can’t use the computer today, a new version of KDE just came out and the build will take a few hours”. I stuck with Gentoo until college1, when a stack of remarkably slick-looking envelopes with Ubuntu CDs showed up. At this point Linux started seeming serious, and the “year of the linux desktop” meme started to get to me. Ubuntu also killed off install-fests2, as installing it was too easy to justify getting friends and pizza together. My grandma got my old PC with it, so I can proudly say my grandma is a former Gentoo user. She exclusively used the browser, but whenever she needed support I was the only one who could provide it, as any other support people invariably tried to get her to find the “start” menu, even when the problem was entirely within gmail. ↩︎ If anyone has footage of the install-fest I was forced to trick Moshik Afia to go to, as part of פעם בחיים on Yes, please send it my way! ↩︎ As I dove deeper into Linux, I realized I’m seeing some of the older jank once again. Lots of software came as shell scripts that ran java, meaning you had to have the Java Runtime Environment installed. Python software came as scripts, which needed not only Python itself installed, but usually some additional python libraries. At this point I noticed the following: This only seems less janky in Linux because executables usually don’t have filename extensions; the difference between a “clean .EXE” and a “janky .BAT” is tucked away in the file contents. “Proper” C programs also need a bunch of stuff installed along with them. The Linux ecosystem has a dizzying array of solutions to this problem. From meticulously2 packaging DEB files through FlatPak/Snap/whatever through Docker3. I’m the kind of nerd who’s excitedly following FasterThanLime’s series about how Nix presumably does this better than anything else. ","date":"2023-04-23","objectID":"/posts/software-distribution/:3:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"Afterword - the web At some point, probably too gradually for me to notice, web apps became actual apps. XMLHttpRequest is horribly named, but pretty transformative when used by sites to dynamically fetch more information; Javascript had gradually transformed to “the Assembly language of the web” (i.e. it’s the thing stuff compiles to4); but the really cool thing about web apps remains distribution: Just give people the URL. Yes, there’s work to do. You need a server, you need to handle its uptime and connectivity (cloud has made this effectively trivial, even moreso for quick demos with things like ngrok). The app itself also needs to be written differently: updates are nontrivial, if any state is saved then backwards-compatibility becomes difficult, you need to handle different browsers (and different device types); it’s not easy. But a giant ecosystem has developed around solving these problems, and the infrastructure to use the web has become, by comparison, effectively ubiquitous. And to my 8-year-old self, there’d be nothing cooler than that: “Forget the floppies, just give a note with your address to your classmates; it’s basically guaranteed to work on their computer”. Windows 2000 had pretty much skipped home PCs around me, and XP was new and untrustworthy. ↩︎ The Debian New Maintainers’ Guide, which explains how to do this, starts off with “social dynamics of Debian” before getting into the details of actually packaging anything. ↩︎ Sometimes described as “It works on your machine? Then we’ll ship your machine.” credit ↩︎ I think compiling stuff to WASM is becoming more popular nowadays. ↩︎ ","date":"2023-04-23","objectID":"/posts/software-distribution/:4:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"The blog has accumulated a few unrelated bits and bobs, linked here: Russian stress mark Linux stuff TTime3 ","date":"2023-01-18","objectID":"/stuff/:0:0","tags":null,"title":"Stuff","uri":"/stuff/"},{"categories":null,"content":"It’s December 2022, let’s try Rust 🦀 As you can tell by previous posts on this blog, I used to be quite a fan of Go; I use it at work often, and some features about it are legitimately great: Package management, “static duck typing” (structural typing), providing interfaces while stepping away from inheritance, all quite nice (and present in Rust). I wasn’t too unhappy with the repetitive error handling, generics are finally coming into play, and nothing I write is anywhere near performance-critical enough for me to care about GC overhead (though I did glance firmly at the binary size once in a while). But come December, as I decided to give Advent of Code a go this year, I figured I’d try to use it to learn a new language: Rust. Now, Rust has been steadily gaining popularity for a while, but two recent events caused me to pay attention: In September, a CTO from Microsoft gave Rust a significant endorsement. In that same month, Linus Torvalds effectively announced that Rust was coming to the Linux kernel. When those two agree on something, I figured, it’s probably worth paying attention. To my delight, someone else — fasterthanlime — was doing Advent of Code in Rust. In fact, he was doing a day-by-day “let’s learn rust while solving Advent of Code” series. Part 1 includes everything you need to get started, tooling and all, and a delightfully unusual introduction to file I/O which I won’t spoil. Other ways of getting started with Rust When getting started with Rust, I tried a few things out from https://www.rust-lang.org/learn, but my recommendation is this: Before installing it, before going to the book, before any of that — go do rustlings, specifically use their Gitpod link. This will set up a free gitpod “cloud IDE” (VSCode-based), reasonably configured for Rust, and you can get right to live exercises. Having spent some time with Rust, I now see more and more faults with other programming languages. Others have written many words about this; fasterthanlime has a couple of very detailed posts in this direction; the folks at Discord wrote a great post about switching from go to rust to eliminate GC latency. But I’d like to talk about something far, far simpler. Let’s talk about null checks. ","date":"2023-01-16","objectID":"/posts/rust/:1:0","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Things that may or may not be there My initial sense of Rust is that it involves a lot of fighting with the compiler… and the compiler being right. Getting code to build is much more difficult than I’m used to, but when it builds — it works. Not always, but with a much higher likelihood than I’ve seen elsewhere. To explain this phenomenon, let’s take a look at cases when data is allowed to be absent. It is often useful, in code, to deal with something that may or may not be present. I’ve recently had the unpleasant experience of dealing with soccer1 for work2; I still don’t quite get it, so this example might not make any sense, but bear with me: Let’s imagine that a soccer Team has several players (each of which is a Person with a name and age), and may or may not have a coach, who is also a Person. In JSON, that would look like this: { \"players\": [ {\"name\": \"John Doe\", \"age\": 24}, {\"name\": \"Richard Roe\", \"age\": 25} ], // Might be absent: \"coach\": {\"name\": \"Mark Moe\", \"age\": 53} } Suppose you write some code to handle such a Team, and, say, return whether or not any of the players are older than the coach. ","date":"2023-01-16","objectID":"/posts/rust/:2:0","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Go In Go, you’d probably end up doing something like this: struct Team { Players []Person Coach *Person } func (t * Team) anyPlayersOlderThanCoach() bool { if t.Coach == nil { // YOU WILL FORGET return false // TO DO THIS PART, } // I ASSURE YOU. for _, p in t.Players { if p.Age \u003e t.Coach.Age { // ...so ^^^^^^^ will sometimes crash. return true } } return false } At some point you will encounter a team without a coach, and your code will panic and exit with an error. It won’t even be a useful error message — it’ll be something like this (but probably with many more goroutines). panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x480c76] goroutine 1 [running]: main.main() /tmp/sandbox3217875017/prog.go:17 +0x16 Program exited./Op The issue is that the null (well, nil) pointer is used as a way to indicate “something that is not there”, and Go — just like C — uses pointers both to indicate “we’re dealing with pointing at memory addresses” and to indicate “we’re dealing with something that may be absent”. Worse yet, because most teams do have coaches, this will be a rare case. It’ll likely be shuffled off into the back of the bug queue as a “rare crash”, waiting to jump on you when somehow a coach-free team makes it to the world cup finals. ","date":"2023-01-16","objectID":"/posts/rust/:2:1","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Rust Although rust does support pointers (null and otherwise), those are usually relegated to unsafe code. In day-to-day rust, indicating that a value might be absent is done using std::Option. If you were recreating the same naive approach as Go, you’d end up writing something like this: struct Team { players: Vec\u003cPerson\u003e, coach: Option\u003cPerson\u003e, } impl Team { fn any_players_older_than_coach(\u0026self) -\u003e bool { // Don't code like this, but... if self.coach.as_ref().is_none() { // This is the return false // part you will } // forget to do. let coach_age = self.coach.as_ref().unwrap().age; // ...so this part will crash: ^^^^^^^^ self.players.iter().any(|p| p.age \u003e coach_age) } } Note Yes, Rust’s support for functional-style programming blows Go’s out of the water. Yes, I’m salty. The error you’d get for forgetting to check whether coach.as_ref().is_none() is actually a bit better: thread 'main' panicked at 'called `Option::unwrap()` on a `None` value', src/main.rs:13:45 However, there’s an extremely handy smoking gun here — unwrap itself. That’s not a function that usually gets used in production3 code. A reviewer or linter should be able to catch it. The function should actually be written like this: impl Team { fn any_players_older_than_coach(\u0026self) -\u003e bool { match \u0026self.coach { None =\u003e false, Some(definitely_a_coach) =\u003e self.players.iter().any(|p| p.age \u003e definitely_a_coach.age), // definitely_a_coach can be called \"coach\" as well, // and usually would - but it's a different variable // with a different type. } } } Importantly, the type of definitely_a_coach is not Option\u003cPerson\u003e — it’s Person. That is, when using match (which is fairly standard), the guarantee that “you made sure the thing is actually there” happens at compile time. Omitting the None case is a compilation error. Note This is a great example of how Rust moves head-scratches from runtime to compile-time. It’s a big part of why it’s harder to get Rust code to build. In fact, there’s an equivalent way to write this, shorter, but providing the same safety guarantees: impl Team { fn any_players_older_than_coach(\u0026self) -\u003e bool { if let Some(definitely_a_coach) = \u0026self.coach { return self.players.iter().any(|p| p.age \u003e definitely_a_coach.age) } false // Omitting this is also a compilation error; // it won't let you forget the \"else\" case. } } Importantly, the syntax that might panic (unwrap) is quite different, easy to pick out, and does not have to be used at all. In contrast, in other languages, like Go, we don’t get the opportunity to notice that it’s happening. The coach pointer gets dereferenced using the same syntax, whether or not it’s guaranteed to not be nil. ","date":"2023-01-16","objectID":"/posts/rust/:2:2","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Other languages Haskell This seems to be equivalent to the Haskell Maybe type. If I were smart enough to code in Haskell, I’d be sure. One of the nice things about Rust is that it allows writing code in imperative style without understanding monads. Java Java 8 introduced java.util.Optional, which does the same thing as Rust’s Option. However, the safety guarantees are more limited: You can check ifPresent() and use get(), but this is no better than checking if a standard reference would be null (that is — nothing makes sure that you did so, and if nothing is there — get() throws an exception). Note Apparently some external inspectors do check for this, e.g. https://rules.sonarsource.com/java/RSPEC-3655 You can use orElse(defaultValue), which makes sense in some cases, but not always (what if it’s a temperature-in-celsius that might be absent? You can’t use 0° as a default value). You can use various other methods like filter and map, but that requires callback-style programming (which I don’t think is the norm for Java). At the end of the day, Java’s legacy is probably a limiting factor here — your code likely needs to interoperate with a pile of code that simply uses null the traditional way for “thing that is not there”. Finally, researching for this post showed at least one guide claiming the following as Misuse of Optional: Passing an Optional parameter to a method Having an Optional field (also discussed here), exactly as we’re doing here. …so I guess you’re stuck null-checking for those cases. C++ C++17 adds std::optional. I haven’t tried it out, but judging from a quick read, it appears to be more robust than Java’s, but still far less safe than Rust’s: You’re still checking has_value() and risking an exception when calling value() (…does your codebase even allow for exceptions?), or using value_or if a sentinel value is acceptable. ","date":"2023-01-16","objectID":"/posts/rust/:2:3","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Why does this matter? Go is often regarded as a memory-safe4 language. And that’s technically correct in this case — if you get a null dereference, your code will simply crash, as opposed to some crazy Undefined Behavior. Presumably your production setup is resilient to crashes, and you’ll catch these crashes in pre-production anyway. …except, it’ll take you a while to do that. And the crash will seem quite esoteric, and might not even happen in pre-production (does your test data contain teams without coaches?)… and, once again, if a coach-free team suddenly plays a very popular match, are you really set up to deal with such consistent crashes? It’s possible to build automatic tooling for detecting these cases, and people far smarter than myself are already doing so. Unfortunately, applying them to legacy code is an even harder. I’ve seen such a “you did not check for null” static analyzer completely miss a case quite similar to the above; and while we did catch it in pre-production, a lot of people wasted a lot of needless time on it. This is also only one (relatively-simple) example of what Rust does about safety. A more elaborate example is mutexes: A rust mutex “holds” the protected data, requiring you to lock() it to even access the data. This means that the type-system guarantees that the mutex protects whatever it’s meant to protect. In Go, however, the protected value just wears the mutex as a hat — so the compiler has no clue. (There’s at least one person porting this idea into C++) So examine your programming language; see what safety guarantees you’d like it to have (try to use the ones it already does!); and perhaps look at Rust for a bit of inspiration. Short for — did you know? — Association Football. I live in Ireland, which plays multiple kinds of football, so I find “soccer” to be the more specific term. ↩︎ I really don’t like watching any kind of sportsball, but there was a fair bit of excitement around the recent FIFA World Cup, and my involvement extended to having to watch some of those matches. Live 🙄. In contrast, to relax in the evenings, I did AoC — so I effectively watch soccer for a living and code for fun. ↩︎ Rust actually has many useful-while-prototyping functions, like todo!(). ↩︎ And people use that reasoning to build some pretty cool stuff, like https://gokrazy.org. ↩︎ ","date":"2023-01-16","objectID":"/posts/rust/:3:0","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":" One young-child-parenting trick that has worked well for us is white noise. It might be because it emulates in-the-womb-noises, drowns out other noises, or gives baby something to fixate on - but it often does a great job of calming him to sleep. Nearly a year old now, he thankfully doesn’t usually need it for night sleeps, but it’s helpful for a “cranky-because-tired” nap or getting him to sleep for another half-hour when he decides to wake up very early. There are quite a few ways to play white noise, and many cheap mobile battery-powered devices will do the trick just fine. However, I wanted a bit more control, at least for when we’re at home: It’d be useful to turn on the noise remotely, as entering a cranky baby’s room sometimes riles him up. It’d be useful to (gradually!) turn off the noise remotely, especially as my wife doesn’t like the sound and it can be made worse with a baby monitor. I’d like to customize the sound itself (we’re actually going for more of a pink/brown noise) After trying out several options, I went for using a Google Home Mini; we have several of those lying around (they used to come as free gifts with various purchases), the audio quality is reasonable, and it’s compact and clean-looking. Although it does respond to a “play white noise” command, that plays this 1-hour-long segment, which is too short. Instead, I created a 10 hour version with customized parameters like so (mostly inspired here): sox -c1 -n result.ogg \\ synth 36000 brownnoise synth pinknoise \\ mix synth sine amod 0.1 90 ffmpeg -i result.ogg result.mp3 Why is the conversion to MP3 important? See quirks. The rest is a matter of hooking it up to homeassistant. The media_player.play_media service gets it to play just fine. To make it easy to toggle, I created an input boolean and automation to start or stop media when it changes. Because the google home can also be stopped directly, I added a second automation which sets the input boolean off when that happens. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:0:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Main dashboard toggle Having the white-noise-toggle on the main dashboard (an old chromebook in kiosk mode) is quite useful, especially when babysitters are involved. (There’s also a physical button, driven by ESPHome, in the nursery - but that’s not quite remote). My wife had a great idea for styling this toggle - showing a picture of the baby awake when the white noise is off, and asleep when it’s on: type: picture-entity show_state: true show_name: true entity: input_boolean.white_noise_toggle state_image: \"off\": local/awake.jpg \"on\": local/sleeping.jpg name: White Noise tap_action: action: toggle hold_action: action: more-info The hold_action: more-info thing is quite useful, as it can quickly indicate how long the white noise was on, approximating how long the nap has been so far (assuming the white noise does its job). ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:1:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Secondary controls For additional control, in a separate tab of the dashboard, I have the following: type: vertical-stack cards: - type: entities entities: - entity: media_player.googlehome1234 type: custom:slider-entity-row icon: mdi:volume-high name: White noise volume - entity: input_boolean.white_noise_toggle secondary_info: last-changed - type: markdown content: \"Note: White noise volume is usually 40%. If it's off, it shows as 0%.\" This allows easily controlling the volume (when it’s on!), reminds us of what the “usual” volume setting is, and also quickly displays how long ago it was last toggled. slider-entity-row is an extension, which can be obtained here. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:2:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Quirks While this setup works quite well, it has a couple of annoying quirks. Firstly, the Google Home plays a fairly loud chime before starting to play the white noise. Secondly, this involves the Google Home loading a ~300MB file. Originally I used ogg, and although it’s usually cached, in some cases this could be a ~30-second process, with no user feedback visible. I’ve considered having the script play a shorter clip multiple times over, but the playback has unpleasant gaps in that case (and risks repeating that loud chime). However, it seems that when pointing to an mp3 file, audio starts playing immediately, without having to first finish downloading the whole file. The Google Home is pretty opaque about this, but experimentation seems to show this is consistent. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:3:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Afterword Overall, this process of getting familiar with HomeAssistant and its various integrations has been delightful, with great community support and debuggability. My first thoughts were “I don’t need this - my projects are simple and I can code them myself” - but the plethora of readily available integrations and the polished UI has made it well worth my time learning, and making changes is a breeze. And if my child sleeps better for it, that’s a win in my book. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:4:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":" I run a small home server, which - among other things - has backups of data from cloud providers, in case I lose access to them; this data is sensitive and should therefore be encrypted. However, disk encryption requires a secret, and there are - generally speaking - four ways to go about that: Store the key on the same server as the encrypted disk Store the key on detachable media, attached to the same server as the encrypted disk Store the key on a different server Store the key in your brain (this is known as a “passphrase” or “password”) Using a separate server is a bit more complicated than I’d like to go (and is not always supported, e.g. in the free version of TrueNAS Core), and storing the key on the same server won’t protect me in case the server is stolen. For my usecase, it’s an easily burgler-accessible NUC. Detchable media will have to remain attached, as I want to be able to reboot remotely (I’ve heard some interesting suggestions, e.g. “store the key in a USB key glued to your desk so the burgler will probably just disconnect it from the server”). The last option is the simplest and most convenient, except when rebooting. When rebooting an encrypted system that uses a passphrase, you essentially have to do the following: Learn that a reboot is required (about once every 12 days on my server, for a kernel security update) Connect to the server to reboot it Wait for it to reboot Connect to the server again to input the passphrases I always hate actions with a “wait” part to them, so I figured - wouldn’t it be nice to input the passphrases as part of the reboot process? That way I essentially shave off steps 3 and 4. The idea is to allow just the next boot to load the encrypted bits without entering any passwords, authorized by, well, someone who knows the relevant passwords. Hopefully burglars aren’t sophisticated enough to target my machine on kernel patch days. My particular system uses ZFS-on-linux with a couple of encrypted filesystems, and the following is an implementation using systemd and Go. I do think the idea is useful enough for other passphrase-encrypted systems (e.g. LUKS). The overall design is: Before rebooting, you run the go binary on the server as root. It will: Figure out which ZFS filesystems currently have a loaded key Ask for the password for those (and check that it’s correct) Create /zfs-reboot-passphrase.sh with the passphrases embedded shellescape turns out to be useful, as fmt.Sprintf(\"%q\", password) insists on using double quotes, which doesn’t prevent bash from interpreting strings. On boot, the zfs-reboot-passphrase systemd service will check if /zfs-reboot-passphrase.sh exists and run it. It will: Load the embedded passphrases and mount the relevant filesystems shred -u itself - rewrite itself with random data to prevent undeletion, and then delete itself. The specific implementation isn’t super-clean nor important, but I’m attaching it as-is (buyer beware) for completeness. Hopefully it serves as inspiration for something useful. /lib/systemd/system/zfs-reboot-passphrase.service: [Unit] Description=Mount remaining ZFS filesystems with passphrase After=zfs.service ConditionPathExists=/zfs-reboot-passphrase.sh [Service] Type=oneshot ExecStart=/zfs-reboot-passphrase.sh [Install] WantedBy=multi-user.target load_keys.tmpl: #!/bin/bash {{ range $path, $password := .}} echo {{ $password }} | zfs load-key {{ $path }} {{ end }} {{ range $path, $password := . }} zfs mount {{ $path }} {{ end }} exec shred -u $0 main.go: package main import ( \"embed\" \"flag\" \"fmt\" \"io\" \"os\" \"os/exec\" \"os/user\" \"strings\" \"text/template\" \"golang.org/x/term\" \"gopkg.in/alessio/shellescape.v1\" ) var ( //go:embed *.tmpl templatesFS embed.FS templates = template.Must(template.ParseFS(templatesFS, \"*.tmpl\")) skipPasswordCheck = flag.Bool(\"skip_password_check\", false, \"Do not check entered passwords\") outputFile = flag.String(\"output_file\", \"/zfs-reboot-passphrase.sh\", \"Write output to this file (blank is stdout)\") ) f","date":"2022-01-26","objectID":"/posts/preload-key/:0:0","tags":["software"],"title":"Preloading disk encryption keys","uri":"/posts/preload-key/"},{"categories":["Newborn parenting software"],"content":" As noted in the previous post, I decided that the implementation is more appropriate for a microcontroller than a full-fledged computer. While the Arduino is probably the best-known microcontroller, the standard one doesn’t have wifi (the one with wifi is ~$50). The ESP8266, on the other hand, is a microcontroller chip with wifi capabilities, available1 on dev boards like the NodeMCU for about $2 apiece - so I bought a few of them. The ESP8266 is sometimes used as a wifi add-on for Arduino, but it’s quite capable as a microcontroller on its own (and the newer ESP32 is faster). So what’s the difference between a (very small) computer and a microcontroller? A Raspberry Pi boots off an SD card, usually to a full-fledged Linux operating system; you’d operate it either directly with a monitor and keyboard, or connect remotely using SSH. You can install/create software on it as you would on a “full-size” computer, and I usually do this in Go (although Python is more popular). Conversely, a microcontroller will usually run only one program, which you need to build on a separate computer, connect it over USB to the microcontroller board, and flash it. This has a number of advantages, including simplicity and pretty-much-instant boot. Coding for the ESP8266 can be done using the same tooling as Arduino - namely, in C++2, on the Arduino IDE. However, during this project I learned of PlatformIO, which is far more comfortable to work with: It’s integrated into VSCode, and git, auto-formatting, autocomplete and VIM keybindings all work nicely. It also provides a more organized approach to unit testing (practically absent in Arduino IDE) and per-project dependency management (you can list what each project needs and have it auto-install). This made the project fun enough for a few iterations. One quirk of working with the BabyBuddy API is that reporting a diaper change requires supplying the time of change, even if our intention is “right now”. That’s easy enough on a Linux system, but microcontrollers don’t generally have clocks. Thankfully, libraries such as ESPDateTime provide NTP support baked right into your program. At this point, the NodeMCU version worked, and replaced the previous implementation: Poobuttons v2 - nodeMCU on breadboard Indeed, this version fits neatly onto a single (full-sized) breadboard. It’s not quite Ben Eater grade, but the NodeMCU is pretty good for breadboard mounting, and using solid-core jumpers let me make it much neater than the previous iteration. However, at this point we realized there was a missing feature: We were never quite sure if we had pressed the button, especially if we were performing a diaper change together3 . A couple of LEDs can only convey so much information. I decided to repurpose my shitty cardboard LCD case for this project. These tactile buttons have quite short feet - they don’t make it through the cardboard, and I insisted on avoiding using a perfboard and soldering iron - as, at the time, I had neither. I ultimately decided to reuse the mini-breadboard from the previous version; like many (all?) breadboards, its bottom is an adhesive pad; I didn’t even bother to remove the resistors from V1, they add a certain design flare to it. With a few iterations on the UI, it was wife-approved: Custom characters are fully supported in C++ (though, not in Go), so I got nice labels for the tactile buttons, as well as a heartbeat4 to indicate that NTP is still working. Poobuttons v3 - nodeMCU with LCD in cardboard Overall, the project has been a blast, and the result is everyday-useful. Working on it has made me realize how much I need my own space for late-night electronics projects, but that’s a project for another day. Actually available - as in, as opposed to Raspberry Pi 0w, they’re in stock in many places at the moment. ↩︎ Unfortunately, TinyGo does not yet support wifi. ↩︎ We call this procedure Formula 1. ↩︎ 2nd row from the bottom, rightmost column; you can see it fading out in this s","date":"2021-10-10","objectID":"/posts/software-parenting-3/:0:0","tags":["software","life","hardware"],"title":"Newborn parenting software - part 3","uri":"/posts/software-parenting-3/"},{"categories":["Newborn parenting software"],"content":" With BabyBuddy now installed and running properly (see previous post), and an always-on display showing the latest information, we now got into the swing of using it. We loved the timeline for “what happened while I as sleeping”; we loved the food amount reports; and because we had a consistent “feed, then change, then wait 15 minutes with baby upright to reduce spit-up” system, the display’s “time since last change” box was super useful as well. However, as you might imagine, we did not love handling a freshly-re-diapered baby with one hand while using the other to unlock the phone and navigate to the “yes he pooped now” page in a web app. My first idea was to create voice commands for the Nest Home Mini in the room. However, it’s prone to misunderstanding us; you have to enunciate, and even then the speech recognition is mostly tuned to preexisting Google Assistant commands, and tends to guess that we aren’t really saying words like “pee” or “poo”. Furthermore, the baby might be crying, or worse yet - lightly sleeping, at risk of being woken up by our voice (or the assistant’s). What we needed was a button (well, two - one for pee and one for poo). I had a Raspberry Pi ZeroW lying around from a previous project and decided to use it for this (the small OLED display wasn’t used for this project, but I didn’t find a good reason to take it off yet; more on that later). With bits I had from a generic “learn electronics” kit (which I bought for the specific purpose of having such bits), I created the user interface: Two buttons, a green LED for “OK”, a red LED for “something went wrong”; all tied together by some jumper cables and a mini breadboard. The Raspberry Pi would handle communicating with BabyBuddy’s API (over wifi), reading the buttons, and driving the LEDs. The setup was indeed quite similar to PiTemp’s with the software written in Go, cross-compiled, and run on startup using systemd. PooButtons on Raspberry Pi ZeroW One annoying quirk with the Raspberry Pi Zero for this is that it would register phantom button presses; they’d be quite rare, fewer than 5 a day, but that’s certainly enough to mess up diaper reporting. I’m not sure if it’s something about the particular GPIO pins I used (GPIO24, GPIO22), and disconnecting the OLED display didn’t work. I ended up following the old joke: How many software engineers does it take to change a lightbulb? None, it’s a hardware problem. How many hardware engineers does it take to change a lightbulb? None, they’ll fix it in the software drivers. Specifically it ended up looking something like this (with another goroutine listening on the resulting channel): const ( debounceTime = 2 * time.Second stableTime = 100 * time.Millisecond ) func listenButtons(ch chan\u003c- int) { pull := gpio.PullUp edge := gpio.FallingEdge level := gpio.Low for i, pin := range []gpio.PinIO{ pinButton1, // GPIO24 pinButton2, // GPIO22 } { n := i + 1 pin := pin go func() { for { time.Sleep(debounceTime) if err := pin.In(pull, edge); err != nil { log.Fatalf(\"Failed to set pin to input: %v\", err) } if pin.WaitForEdge(-1) { log.Printf(\"Got edge, waiting %v for stability\", stableTime) time.Sleep(stableTime) if pin.Read() == level { log.Print(\"Signal was stable, counting as press\") ch \u003c- n } else { log.Print(\"Signal did not remain stable, discarding\") } } else { log.Print(\"WaitForEdge returned false, ignoring\") } } }() } } It’s not ideal, but it seemed to work; certainly seemed like it should be library code, for someone smarter to debug. Indeed, it turns out that the periph.io library had a Debounce function to help with this, but at the time it wasn’t implemented at all (and now that I’ve spent some time on it, it’s partially implemented). Ultimately, the device worked rather well, and the button pushes were quite satisfying, especially after a particularly nasty diaper change (AKA a poonami). However, it did leave a lot to be desired: The cabling was flimsy and patchy (the pins coming from the ribbon were easy","date":"2021-10-05","objectID":"/posts/software-parenting-2/:0:0","tags":["software","life","hardware"],"title":"Newborn parenting software - part 2","uri":"/posts/software-parenting-2/"},{"categories":["Newborn parenting software"],"content":" A few months ago, I became a father. To help overcome some of the challenges of raising a newborn, I decided to employ my standard MO - software; preferably the kind where I understand what it’s doing. It’s been working well, and I learned a lot doing it - several blog posts’ worth, in fact. For this story to make sense, it bears mentioning that our conditions are pretty much optimal for it: My employer provides a generous parental leave for the non-birth parent; we decided in advance to formula-feed, which allows us to share that load, which means we need to communicate about it; my partner is an early bird whereas I am a night-owl, meaning we essentially have separate shifts necessitating a handoff; and, critically, we’re the type of people who like everything being super-organized and scheduled and spreadsheet-y (calms us down, gives us an illusion of control). Furthermore, our baby is remarkably consistent, being hungry right about every 3 hours - so the question we ended up constantly asking (of each other and our phones) was “how long since the baby ate”. We knew in advance we’d need some sort of a baby tracking app, of which there are many. After some research, I found that few of the free ones are designed to be used from multiple devices (e.g. dad’s and mom’s phones), which is a hard requirement. We found two contenders: Baby+ and BabyBuddy. ","date":"2021-10-03","objectID":"/posts/software-parenting-1/:0:0","tags":["software","life"],"title":"Newborn parenting software - part 1","uri":"/posts/software-parenting-1/"},{"categories":["Newborn parenting software"],"content":"Baby+ Baby+ is an Android and iPhone app for tracking babies; it follows pregnancy+, which we were quite happy with (especially as, before the birth, our responsiveness requirements were looser - I’ll get to that). It can track quite a few things, but not Tummy Time for one (in our case it turns out to be pretty important). Like pregnancy+, the design is very aesthetically pleasing, and it regularly shows timely, short, and useful articles for the parents. While the app does have cloud sync, it doesn’t have a web UI (it’s phone/tablet-only) nor an open HTTP API for me to reasonably code against. It does have an export function, but it’s only really intended for importing by the app itself as backup. It’s super-clunky to work with - I know because I ended up using it to perform some analysis with a spreadsheet(“how long is the baby going between feeds”). The biggest disadvantage of Baby+ is that it doesn’t really support multiple users. From the app’s internal FAQ (only available after installing it and setting up an account): How can I use this app with my partner? You can share the app by logging in with the same email and password. If you use your device and enter data (e.g. a note) then you need to minimise or close the app for it to send the new data to the server […]. Important: the app is designed to be used by on person at a a time […] otherwise data can be overwritten or deleted. […] allow a few mins for the data to sync (the second device should also have the app closed for a few mins at this point so it can fetch the data […]). Please note that you will encounter data loss if you are using the app on two devices at the same time. I’d guess that the app basically talks to the server on startup, compares timestamps of its entire database, and downloads or uploads the entire database depending on which version is newer. The startup time checks out: Starting Baby+ on an android phone, after closing it so it syncs, takes about 7 seconds; an eternity in screaming-baby-debug-time. Furthermore, that doesn’t include sync time, and old data will be shown for a few more seconds before the sync is complete; that starts off with slight frights (“the baby didn’t eat for 5 hours?! oh, wait, actually 1 hour”), and eventually devolves into distrusting the app. This felt like a silly problem to have; almost any web-based app would have none of these issues. Furthermore, I thought, there’s surely an open-source one where I could fix any annoyances I have myself. Indeed, that would be BabyBuddy. ","date":"2021-10-03","objectID":"/posts/software-parenting-1/:1:0","tags":["software","life"],"title":"Newborn parenting software - part 1","uri":"/posts/software-parenting-1/"},{"categories":["Newborn parenting software"],"content":"BabyBuddy BabyBuddy is an open-source web app, self-described as “to help caregivers track sleep, feedings, diaper changes, and tummy time to learn about and predict baby’s needs without (as much) guess work”. I describe it as “the dumbest-sounding idea ever - sleep-deprived parents of newborns creating and maintaining baby-tracking software as a hobby”. It turns out to be wonderful, and is what we use today. It requires self-hosting (but provides a button to do that easily on Heroku), but works remarkably well. It didn’t work exactly like I wanted, but that just provided ample opportunity to hack on it. Before we could use it, I had to make it more mobile-friendly. While it technically worked on phones, it had several usability issues, which I described in #229: horizontal scrolling was needed in places; the “Timeline” view didn’t show a lot of the critical bits of info, requiring more clicks; the contrast was too low for sunlight; and more. Fortunately, through some wonderful collaboration from the author, I was able to quickly get it into a wife-acceptable state and transition us over from Baby+. As I hacked on the project, I added a Gitpod config and a link to the README. This allows people to hack on Babybuddy without installing any software whatsoever - everything is done through, essentially, a free tier cloud instance (on which my config will install everything needed) with a browser-builtin VSCode UI. I used this today to whip up another pull request. In addition to being quick and comfortable to use, BabyBuddy allowed me to set up two integrations that I had in mind. The first is an always-on display, essentially intended as “the baby clock”. It’s positioned by the couch where we usually feed, so it’s great as a feeding timer as well. I had started out with an old tablet (Huawei T3 Mediapad) running wallpanel - this is a form of “kiosk” application, which locks the device into a mode where it always runs the browser on a particular page (the device has no other credentials on it, so it’s reasonably safe). The tablet’s battery, unfortunately, did not like that - seemingly having the screen on discharges it faster than it can charge, and after a few weeks the tablet refused to charge at all. I’ve therefore switched to using an old ASUS C100P Chromebook running kiosk - this gives the benefit of having a physical keyboard, useful for entering the food amounts. The second integration I call “poobuttons” - a couple of tactile buttons on the changing dresser which tell BabyBuddy to mark a diaper (they are labeled “poo” and “pee”). This is both easier than fumbling with a phone touchscreen and, frankly, way more satisfying. The next posts will detail the iterations of these buttons and how I built them. This has been a wonderful and challenging journey so far. I wonder what else I’ll find myself building. ","date":"2021-10-03","objectID":"/posts/software-parenting-1/:2:0","tags":["software","life"],"title":"Newborn parenting software - part 1","uri":"/posts/software-parenting-1/"},{"categories":null,"content":" Good code comments only describe why the code is (or isn’t!) doing something. When teaching coding or reviewing code, I sometimes encounter comments describing what it’s doing, and those are almost always harmful. To be clear, I’m talking about code comments, not documentation comments. This nuance is different in every language and setup, but for Go, this is it: // UsefulFunction does useful things. This is a documentation // comment, and will be displayed in godoc, IDE autocomplete, // and more. func UsefulFunction() { // this and all of the below are code comments // count visitors // // x is the visitor counter x := 0 x++ // increment x } ","date":"2021-05-02","objectID":"/posts/comments/:0:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Document “why” In some code, things are done for non-intuitive reasons. It’s worth pointing that out - it makes your code easier to read for a newcomer trying to understand why it’s written that way. In this example, technically sumOfIntsWithThreshold will work absolutely correctly without its input being sorted, but it turns out that it will be faster if it is. sort.Ints(a) // improves performance; see https://stackoverflow.com/questions/11227809 x := sumOfIntsWithThreshold(a, 128) Other good “why” examples are code being written in a less-intuitive way to make a particular test possible or to avoid a specific edge-case - be sure to note what those are. If a well-researched algorithm is being used, definitely add a reference to it, including the best URL you have for someone who wants a quick overview of how it works. ","date":"2021-05-02","objectID":"/posts/comments/:1:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Document “why not” In some code, the reader might see something missing, a pattern apparently broken. Sometimes this is for a good reason, as keeping with the pattern would cause a bug. More specifically, you might be fixing a bug by breaking the pattern. In this example, especially if you’re removing a line sort.Strings(c), it’s a good idea to leave a comment explaining why it shouldn’t be there. func handle(a, b, c []string) {} sort.Strings(a) sort.Strings(b) // don't sort c, we need to keep its original order for foo foo(c) } ","date":"2021-05-02","objectID":"/posts/comments/:2:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Don’t document “what” when it’s trivial You might be asking yourself “what’s the harm in a comment if it isn’t needed. The answer is that it can be misleading; code will function correctly even if it’s out-of-sync with its comments, so comments aren’t always updated when code is changed, leading to this canonical example: // increment x by 1 x += 2 In less-trivial cases, the reader can be left scratching their head for far longer than they would’ve if the comment weren’t there in the first place. ","date":"2021-05-02","objectID":"/posts/comments/:3:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Documenting “sections” is a code smell If your code looks is divided using comments into “sections”, it’s probably long and difficult to reason about: func ServeSite(o io.Writer) { //// Get site data //// f := os.Open(\"data.md\") defer f.Close() parser := markdown.NewParser(f) data := parser.Parse() //// Get layout data //// f2 := os.Open(\"layout.cfg\") defer f2.Close() layoutReader := awesomelayout.NewReader(layoutOpts.Defaults) // Name \"data\" is already in use\" dataOfLayout := layoutReader.Read(f2) //// Set up HTML renderer //// renderer := htmlrender.NewRenderer() renderer.SetHTMLMode(\"my-favorite-html-style\") renderer.SetCompression(\"max-compression\") renderer.Render(o, data, dataOfLayout) } This gets even messier if you don’t sneakily omit error handling. In any case, the section headers are reasonable (albeit not great) candidates for function names: func ServeSite(o io.Writer) { siteData := getSiteData() layoutData := getLayoutData() renderer := setupHTMLRenderer() renderer.Render(o, data, dataOfLayout) } func getSiteData() markdown.Data { f := os.Open(\"data.md\") defer f.Close() p := markdown.NewParser(f) return p.Parse() } func getLayoutData() awesomelayout.Data { f := os.Open(\"layout.cfg\") defer f.Close() r := awesomelayout.NewReader(layoutOpts.Defaults) return layoutReader.Read(f) } func setupHTMLRenderer() htmlrenderer.Renderer {} r := htmlrender.NewRenderer() r.SetHTMLMode(\"my-favorite-html-style\") r.SetCompression(\"max-compression\") return r } The main ServeSite function is now much easier to read. The “section names” are now function names, and are less likely to fall out of date. And as a bonus, the scope of many variables is reduced - so the reader doesn’t have to keep them in mind, and we can use short names for them. ","date":"2021-05-02","objectID":"/posts/comments/:4:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Don’t leave code scars around Finally, just a pet peeve - while it’s absolutely fine to “comment out” code while developing, you usually shouldn’t commit this to version control. I like calling these “code scars”: x := getMaxValue() // x = 3 handle(x) In this case, x = 3 was there for testing “what if getMaxValue returns 3”. You should not commit this. However, a possible exception can be if you’re documenting “why not” as above - if it comes with an explanation. ","date":"2021-05-02","objectID":"/posts/comments/:5:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Conclusion Code is meant to be read by machines and humans, with comments generally being intended for humans to read. Therefore, all of these should be taken as guidelines rather than gospel. Hopefully this post can be of some use for people trying to reason about comment etiquette, or perhaps for code reviewers wanting to point their reviewees at a preexisting summary. ","date":"2021-05-02","objectID":"/posts/comments/:6:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":" I had been looking for an excuse to mess around with Raspberry Pi for a while, and found one: I wanted a graph of temperature and humidity over time, and - while we’re at it - a nice display of those two. Technically speaking, I already have a Nest thermostat which should provide those, but it won’t display humidity and there’s no easy way to get a graph off it (besides, then I’d need another excuse for messing around with a Pi). The code for the final result is in https://github.com/lutzky/pitemp. ","date":"2021-03-14","objectID":"/posts/pitemp/:0:0","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"Stage 1: LCD and DHT Hardware: A Raspberry Pi Zero W a friend gave me (that’ll become important later on) A DHT11 temperature \u0026 humidity sensor A 4x20 character LCD; apparently an HD44780 controller or compatible. This was my first time coding for hardware on the raspberry pi, and it went fairly well. ","date":"2021-03-14","objectID":"/posts/pitemp/:1:0","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"LCD quirks Getting the degree symbol (°, ASCII 0xb0) was a bit of a challenge. While the official HD44780 spec shows it should be available with “ROM Code A02” (i.e. Latin mode), it’s not clear if this can be toggled in software, and the characters my unit displayed matched “ROM Code A00” (Japanese)… mostly, that is. Some characters were malformed, and the unofficial library I used didn’t support custom characters (which the hardware seems to support). Fortunately, the Japanese ROM code had a Handakuten symbol (ﾟ, like the circle from ぽ but as a separate character), which is close enough. The LCD was also quite slow to refresh, the way I was using it; any faster than 1 hz would lead to corruption, meaning that the “second-by-second” clock display I wanted wasn’t feasible. Finally, the LCD unit is much, much large than the Raspberry Pi Zero, and has to be wired awkwardly to it. With some covid-lockdown-induced creativity, a twist tie, and a bit of sewing thread (!), I turned the box it came in into a “case”. LCD in a cardboard box “case” ","date":"2021-03-14","objectID":"/posts/pitemp/:1:1","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"Cross compilation While the Pi Zero is certainly capable of being a fully-fledged Go development environment, it’s not a fast one (and me using a cheap old SD card isn’t helping). I got a much faster edit-compile-run loop by working on my main laptop, cross-compiling for ARM, and scp-ing the result over. That’s despite Go’s hefty statically-build binaries (7-12MB for these, depending on stripping). Cross compiling is done like so (e.g. in a convenience script): sudo apt install gcc-arm-linux-gnueabi export CC=arm-linux-gnueabi-gcc CGO_ENABLED=1 GOOS=linux GOARM=6 GOARCH=arm go -o main.arm build main.go For build-and-run-on-save, this can be used with entr. However, because you can’t modify an executable file as it runs (in this case), you need to use a temporary file. On my laptop, I run: find | entr -c -s \"./build.sh \u0026\u0026 scp main.arm TARGET-MACHINE:main.arm.new Then, on the pi, I run: ls main.arm.new | sudo entr -r -c -s \"cp main.arm.new main \u0026\u0026 exec ./main\" ","date":"2021-03-14","objectID":"/posts/pitemp/:1:2","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"Stage 2: PiOLED I looked for a not-so-ridiculously-large display, and found adafruit’s PiOLED to be perfect. Its HAT form factor makes for a much tidier device, and the display itself is reminiscent of the 2007 Sansa Clip m300 (albeit monochromatic). Library support is also much better, thanks to http://periph.io. That being said, my friend soldered the Pi’s pins on “downwards”, as this is apparently more convenient when using it on a breadboard. I figured it’s time to order my own Pi Zero (you can get them with the pins pre-soldered, facing “up”); I later found that this might be configurable, but it’d still be pretty awkward. The PiOLED library (actually periph.io’s ssd1306 library) essentially lets you render an image.Image; since these are also trivially renderable to PNG, I could speed up development even further by adding an HTTP endpoint to serve the current image, even if the hardware isn’t present; this also let me zoom into the rendered image instead of squinting at the actual display, making it easier to align things pixel-by-pixel. I eventually ended up separating the code into two binaries - pitemp would communicate with the sensors and provide an HTTP endpoint, whereas pitemp_pioled (and pitemp_lcd) would communicate with pitemp and the physical display (or run in --simulator mode on my laptop, for HTTP-endpoint-only rendering). I’m quite happy with the final result: PiTemp with PiOLED Happy hacking! ","date":"2021-03-14","objectID":"/posts/pitemp/:2:0","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":" This is as good a time as any to give a quick tour of my “homelab” or server drawer. The external view is rather innocuous: A visually inoffensive Nest Wifi, a rather elegant Nest Thermostat (shame that the display can’t be always-on), and the gorgeous Nintendo Switch dock cover my partner got me. The TV aerial is tucked to the back, a reasonable compromise between “gets reception” and “hidden away and ugly”. The TV is mounted on upside-down IKEA boxes which we painted to roughly match the rest, hiding some botched carpentry behind the TV. External view You may note some cables heading down through a hole in the woodwork (yeah, I could probably make them a bit neater on the way down): Through the hole When opened, the drawer shows the Virgin Media router (in Modem Mode), hooked up to the Nest Wifi and back into a small switch. The TV is hardwired in, and so is the NUC i3 media server (“Michael”, replacing the previous server “George”). The NUC is wearing a 4TB USB HDD as a hat. Everything is quite low-powered, and Michael usually hovers around 42°C. Top view Finally, here’s how everything is powered. The guy who built it thought 10 sockets (8 in the drawer, 2 behind the TV) was overkill. It was not. Power view ","date":"2021-01-03","objectID":"/posts/server-drawer/:0:0","tags":["networking"],"title":"Server drawer","uri":"/posts/server-drawer/"},{"categories":null,"content":" 2020 being what it is, I’ve been working from home for quite a while. We decided to convert our spare bedroom into a home office, and I realized how nice it is to have a proper desk at home, even for non-work stuff (I haven’t had one in over 10 years!). That being said, wifi is a challenge with the apartment’s structure. (Diagram below is approximate; I’ll explain why and how it was created in a bit.) Approximate apartment structure; explanation on how and why it was created coming in a bit. My broadband comes in via a cable connection in the living room - the modem and router/AP sit in the bottom middle of the room. Before WFH times we would occasionally work from home, mostly from the living room, which was the only place with chairs. To get wifi in the bedrooms (one of which is now labeled “office”), I used a TP-link powerline pack - i.e. one thing stuck to a power socket by the router in the living room, and another in the bedroom. Or the hallway. The tradeoffs were these: We wanted to have it as close to the bedroom as possible, so we’d have good reception there. Having it in the bedroom let us hard-wire the TV to it. It’d have better performance the closer it was to the living room. While I’m not sure what the electrical topology of my apartment is, the further from the living room it got, the worse its “reception” got - i.e. the slower and less reliable its communication with the one in the living room would be. So for the most part, it worked. We’d get the odd disconnections or slowness, but it was used mostly on our phones, so we could switch wifi off (or, better yet, just go to sleep or get out of bed). There was one annoying issue though - roaming never worked right. Giving the powerline wifi network a different name worked OK, but we’d have to manually switch networks; especially on my partner’s iPhone, which tends to be “sticky” (and requires more taps to switch wifi networks to boot). Giving the powerline wifi network the same name (SSID) and password worked OK for roaming most of the time, but not always - and now it was quite difficult to tell, when a problem occurred, if it was due to our phones looking for the wrong AP; turning wifi off and on again didn’t always fix this. Working from home, connectivity suddenly became important. We have a ton of video meetings, we’re using our laptops all day, and sometimes we need to move around quickly - we can’t both have meetings in the home office, so one of us needs to switch to the living room table and have the connection work with minimal extra fiddling. I decided two get a two-pack of Nest Wifi devices (a Router and a Point). Over time, I found a third one was necessary, and still doesn’t always work quite right. Unfortunately, running ethernet to the home office isn’t currently a possibility (…but should definitely be a priority for any renovation). After some messing around, I came up with a solution, but figured I’d try and understand if I can do better by analyzing the apartment. So, step 1 - I needed a floor plan. I do not have one of my apartment, but the 3D visualization the realtor provided was still up and had a “measurement” tool. So I went to http://floorplanner.com and used that visualization to sketch up the diagram above. The point of this was the next step: In a wonderful company-internal talk about home wifi (this is a common issue in Israel, where many apartments have concrete-walled shelters), the neat mapping capability of Unifi’s controller software was shown. While I don’t own any Unifi gear, I installed the controller software (available as a neat docker container), imported my diagram, drew the walls, and positioned my living room router. Router in the living room This is, naturally, only an estimate; the AP model is wrong, the -64dBm client sensitivity is just a guess, as are the wall widths and materials; reflections also aren’t taken into account (and I suspect the Nest Wifi is making good use of those). The washing machine and dryer in ","date":"2020-12-10","objectID":"/posts/wfh-wifi/:0:0","tags":["networking"],"title":"WFH Wifi","uri":"/posts/wfh-wifi/"},{"categories":null,"content":" In the 90s, my family (along with much of the rest of the world) filmed a lot of home videos. At some point we converted them to what we believed to be DVD for preservation and ease-of-access, but this was actually VCD (which has somewhat worse compatibility), burned on CD-R (which degrades faster than you might think), and optical media has pretty much become extinct as well. In a family visit in 2018 I found the old stash of original video cassettes, flew them with me from Israel to Ireland, and got a local shop called DVD Centre to re-rip them - these guys provide the great service of uploading directly to Dropbox. I’ve been spending some sporadic time on weekends rewatching all of these, cataloguing them into what Googlers call a “one-pager” - a long document that may span many pages if printed out, but can be loaded by normal software with simple search functionality (a Google Doc, in my case). This is great for searching by name or event to more easily locate the right video. The tapes are still quite long though - usually 1-2 hours, and can be logically split into smaller segments. They also often have audio issues, such as audio only coming out of one side or having very inconsistent volume. For the last few weekends (2020 is a weird year that gives me more time to do this kind of thing), I’ve been working my way through the videos, correcting audio and splitting them into smaller logical chunks. I’ve uploaded them to Google Drive and shared with my family, who can now easily access them right from their phones from a different continent. It’s been bringing back many memories and feels like a worth preservation effort for these memories. Here’s my workflow, in case it’s useful for anyone else: ","date":"2020-11-07","objectID":"/posts/editing-old-family-videos/:0:0","tags":null,"title":"Editing old family videos","uri":"/posts/editing-old-family-videos/"},{"categories":null,"content":"Audio corrections First, split the audio stream into a separate file so you can modify it with the software of your choice. I use ffmpeg for this. The ffprobe program lets me determine the current audio type, which is aac in my case, so I do: ffmpeg -i ORIGINAL_VIDEO.mov -vn -acodec copy output-audio.aac Now I open output-audio.aac in Audacity, and perform: If only one audio stream is available, downmix stereo to mono so it at least comes out of both speakers. (Tracks -\u003e Mix -\u003e Mix Stereo down to Mono) Normalize, to get the baseline audio levels comfortable (Effects -\u003e Normalize) As a personal choice, to get the audio levels consistent, I apply extremely aggressive compression - Effects -\u003e Compressor, lowest possible threshold (-60 dB here), maximal possible ratio (10:1), attack time of 0.2 seconds and release time of 1.0 seconds. This destroys any dynamic range, but the forced consistency of audio levels helped me pick up what people are saying - they were being recorded from various distances at varying noise levels. There’s a lot more processing you can do here (graphic equalization may be a good idea), but the ones I described worked well as “catch-all” fixes that I could apply to all audio without thinking about it too much. Export this in the same audio format (again, aac in my case - I’d use ffprobe on the original to see the approximate bitrate, but it’s not necessary to match it precisely), and recombine like so: ffmpeg -i ORIGINAL_VIDEO.mov -i output-audio-fixed.aac -c:v copy -map 0✌️0 -map 1🅰️0 ORIGINAL_VIDEO_sound_fixed.mov This method was both faster and more flexible than using the video editors I have at my disposable. ","date":"2020-11-07","objectID":"/posts/editing-old-family-videos/:1:0","tags":null,"title":"Editing old family videos","uri":"/posts/editing-old-family-videos/"},{"categories":null,"content":"Splitting video Note from the future (2021-12-25): LosslessCut does a far better job of this than my hacky scripts, and is far easier to use. At this point, I watch the video through, writing down key points of what’s going on with approximate time-codes. It helps to do 3-4 different tapes of this before moving forward, as it gives you a feel for what the “logical separation” to smaller chunks is. I usually define those chunks as “different set of consecutive days” (usually just one), but it helps to have all the timecodes available in text so you don’t have to re-watch. I recommend using a player that supports faster-than-realtime viewing, such as VLC (speed up, stop on “hey what was that”, rewind, watch at regular speed). This is the most time-consuming part. After this, I decide on the section structure, and need to determine the precise frames where I want to split. Since most video players aren’t designed to “go back one frame”, I actually open the video in a video editor (the free HitFilm Express, in my case). I start with the rough time-codes from the previous step, and step frame-by-frame back-and-forth until I find the first and last usable frames of a section. I write these to a points.txt file with the following syntax: 00:00:00:00-00:15:48:13 00:15:50:17-00:40:14:01 ... Here, the format is Hour:Minute:Second:Frame - in my case the video is 25 FPS, so Frame is between 00 and 24. Next, I want to split the video using ffmpeg - this can be done without recoding, which is much faster (on my laptop - a few seconds per section, as opposed to multiple minutes) and doesn’t degrade quality. For the timecodes above, the correct split commands are: ffmpeg -ss 0:00:00.000 -i audio_corrected.mov -to 0:15:48.520 -c copy segment_1.mov ffmpeg -ss 0:15:50.680 -i audio_corrected.mov -to 0:24:23.360 -c copy segment_2.mov These are annoying to create manually, because: The timecode for ffmpeg is given in milliseconds, so 13 frames in 25fps becomes 520 milliseconds. The -to offset is from the section’s start (so it’s more of a -length), and subtraction is hard. So, of course, I wrote some code to do this for me. It takes a points.txt as described above, and outputs the appropriate series of commands. All that’s left to do is to let the commands run, upload the videos, and wait for Google Drive’s video-rendering to catch up. Good luck on your video preservation adventure! ","date":"2020-11-07","objectID":"/posts/editing-old-family-videos/:2:0","tags":null,"title":"Editing old family videos","uri":"/posts/editing-old-family-videos/"},{"categories":null,"content":" When presenting SRE postmortem culture, and the importance of its blamelessness, I always find it useful to present its antithesis. As it’s often-claimed that the Eskimo have many words for snow, my home country of Israel has a word for covering one’s ass - כסת\"ח, pronounced /kastáχ/, an abbreviation of כיסוי תחת. This abbreviation is impressively conjugatable; for example, the term מכוסת\"ח roughly corresponds to “appears as though it was made while covering one’s ass”. I have it on good authority that the italian term “Paraculo” is closely related. Ori Katz’s blog post provides a wonderful introduction to this concept. I bring this translated version before you as a warning example of the importance of blame-free culture. Notes in (OL:) are translator’s notes. I have attempted to represent the original (Hebrew) post as accurately as possible. ","date":"2019-07-12","objectID":"/posts/asscover/:0:0","tags":null,"title":"Ass-cover","uri":"/posts/asscover/"},{"categories":null,"content":"The translated blog post One of the common and erroneous beliefs is that the primary business of people responsible for something - be they politicians, military commanders, civilian managers etc. - is managing the thing they’re responsible for. This belief is fed by the illusion of control, which has us overestimating the importance of conscious actions of people as reasons for things that happen, and underestimating blind luck and circumstances that are outside the control of those involved. The truth is that many things happen for no reason, by chance. A commander might make all the correct decisions in battle, but still lose due to an error in judgement by his superiors or subordinates. A businessperson might make the worst possible decisions, and still turn a profit because the entire field of his business has had an impressive profit surge due to an external reason, or because a competitor went bankrupt. A minister can make correct decisions that would only affect the following term of office, and be criticized for decisions made by his predecessor or a global economic crisis outside of their control. Therefore, in many cases the best managers, politicians and commanders (and anyone else who manages anything) are those who excel at the following task: Make the bad things that happened during their shift look like someone else’s fault, as external circumstances outside their control or bad luck, and make the good things that happened during their tenure look like they happened thanks to them. Truly, many of the managers I’ve met are experts in this matter - the ass-covering ability. Ass-covering is far more than military slang intending to describe amusing phenomena. Ass-covering is the way a world works when there’s uncertainty about people’s ability to properly perform their job; when there’s no way to accurately measure the output of most people in most professions, especially higher-ranking ones, and it’s impossible to separate individual contributions from external influences. Ass-covering is the way our world works. Many things which seem as though they shouldn’t exist in a logical world with rational humans have their roots in ass-covering. For example, recruitment screening agencies. If there are ten measures of stupidity in the business world, recruitment screening agencies have taken at least eight upon themselves1. Upon first exposure to the phenomenon, people are astounded by its scope, the superficiality of the tests and interviews, and the cheap psychology behind the whole matter. The truth is that recruitment screening agencies exist for a very good reason: it’s difficult to find good employees. People (especially those who read my post on the matter) don’t represent themselves fairly during job interviews, school grades don’t accurately predict the required traits for an excellent employee, and ultimately hiring a new employee is always a wager. And once there’s uncertainty, ass-covering slithers its way in. When an HR officer at a certain company needs to hire new people, they can make this wager themselves, or they can send them to one of the recruitment screening agencies. There, the potential employees will pass a variety of tests which, as is known for decades, predict next-to-nothing; they will be asked to draw trees in order to see that they draw pretty and optimistic trees; to fill in blanks such as “the child was sad when …” (recommended: “when an analyst at the recruitment screening agency decided he wasn’t a good fit for the job, and he was forced to kill them”), et cetera. If the candidates turn out to be bad employees, the HR officer can always say “they passed ScreenAgent”. It isn’t their responsibility. In his book “Rationality, Fairness, Happiness”, economics nobel laureate Daniel Kahneman describes tests he performed decades ago on IDF officer’s course candidates (it’s possible the same tests are being performed today). He and his colleagues gave soldiers various tasks, and observed which ","date":"2019-07-12","objectID":"/posts/asscover/:1:0","tags":null,"title":"Ass-cover","uri":"/posts/asscover/"},{"categories":null,"content":"Appendix: Related terms I highly recommend understanding the related term “Sentry Syndrome” (תסמונת הש\"ג), explained in the Wikipedia entry for Night of the Gliders. A related slang term to כסת\"ח/Kastach/Asscover is בלת\"ם/Baltam. It’s an abbreviation of בלתי מתוכנן, or “unplanned”, but is used as a noun (one Baltam, many Baltamim), representing an unexpected event that throws a wrench in your plans. This is often the result of poor planning, possibly as a result of lack of taking responsibility due to ass-cover. The presence of these within blameful culture also necessitates additional ass-covering, altogether creating the בלת\"ם-כסת\"ח cycle. OL: This is a Talmud reference. Originally: “Ten measures of beauty descended to the world, nine were taken by Jerusalem.” ↩︎ OL: Lieutenant Commander, the 4th rank of officers in naval terminology. ↩︎ OL: For those familiar with the font, the signature was originally in Guttman Yad Brush; the signature is represented in Comic Sans, an appropriate approximation. ↩︎ ","date":"2019-07-12","objectID":"/posts/asscover/:2:0","tags":null,"title":"Ass-cover","uri":"/posts/asscover/"},{"categories":null,"content":" Now that we’re done yak shaving, we can start talking about mutation testing. As an engineer at Google, I often use the Go programming language (which I really enjoy), so that is my choice for these examples; however, mutation testing is available for other languages. ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:0","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"Constructing Bolson people Let’s start with an example; we have a people package, where a person has an age and a name. For these people to be appropriate for our quest, they need to be over 18, have names with at least two whitespace-separated words in them, and have those names end with -son. You can claim those are the strangest software project requirements you’ve ever had all you want, I know better. package people import ( \"strings\" ) type person struct { name string age int } func checkAge(p person) bool { return p.age \u003e 18 } func checkValidName(p person) bool { return len(strings.Fields(p.name)) \u003e 1 } func checkBolsonPolicy(p person) bool { return strings.HasSuffix(p.name, \"son\") } func validatePerson(p person) bool { return checkAge(p) \u0026\u0026 checkValidName(p) \u0026\u0026 checkBolsonPolicy(p) } Now, validatePerson performs the overall validation, but we’ve split it into smaller check* functions to make them simple to test independently, in case the requirements get more complicated in the future. Here are the tests: package people import \"testing\" type testSet []struct { person person want bool } func runTestSet(t *testing.T, check func(person) bool, tests testSet) { t.Helper() for _, tc := range tests { got := check(tc.person) if tc.want != got { t.Errorf(\"check(%#v) = %t; want %t\", tc.person, got, tc.want) } } } func TestCheckAge(t *testing.T) { runTestSet(t, checkAge, testSet{ {person{age: 5}, false}, {person{age: 17}, false}, {person{age: 19}, true}, }) } func TestCheckValidName(t *testing.T) { runTestSet(t, checkValidName, testSet{ {person{name: \"\"}, false}, {person{name: \"Ohad Lutzky\"}, true}, {person{name: \"John J.J. Schmidt\"}, true}, }) } func TestCheckBolsonPolicy(t *testing.T) { runTestSet(t, checkBolsonPolicy, testSet{ {person{name: \"Hudson\"}, true}, {person{name: \"Rhondson\"}, true}, {person{name: \"Eriksen\"}, false}, }) } func TestValidPerson(t *testing.T) { runTestSet(t, validatePerson, testSet{ {person{\"Rito Fryson\", 19}, true}, {person{\"Greyson\", 20}, false}, {person{\"Zora Kapson\", 15}, false}, }) } Running go test -cover will show us that we have 100% test coverage! Hurray! However, danger lurks. In a couple of months, a newcomer to the team will refactor validatePerson to add logging indicating why a person is considered invalid, all the tests will pass… and suddenly one “Christian Eriksen” is counted by the system as valid. How can this be? All the tests still pass, and we had 100% coverage! ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:1","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"Using mutation testing Let’s see if mutation testing can help us out. I put my code in $GOPATH/src/github.com/lutzky/people, so I install and run zimmski/go-mutesting: $ go get -v github.com/zimmski/go-mutesting $ go-mutesting github.com/lutzky/people/... PASS \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.0\" with checksum 252162809c884e5616872b71196c90df --- /home/lutzky/gopath/src/github.com/lutzky/people/people.go 2018-08-05 00:13:44.333319200 +0100 +++ /tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.1 2018-08-05 10:15:30.013388991 +0100 @@ -22,5 +22,5 @@ } func validatePerson(p person) bool { - return checkAge(p) \u0026\u0026 checkValidName(p) \u0026\u0026 checkBolsonPolicy(p) + return checkAge(p) \u0026\u0026 checkValidName(p) \u0026\u0026 true } FAIL \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.1\" with checksum 996748ab09eeca8feb3f87ecf23b8319 PASS \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.2\" with checksum 7be514fe57e53f4d02ce1e128641333f PASS \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.3\" with checksum 88a83b2731fda42ae4f3ac9350191c9f The mutation score is 0.750000 (3 passed, 1 failed, 0 duplicated, 0 skipped, total is 4) What the mutation testing package does is take the test-covered code (all of people.go, in our case) and attempt to modify it at random, so that it will still build, but the logic will change; things like removing statements, changing conditions in if statements, or in this case - changing an arbitrary boolean value to true. If the code is correct and tested properly, any such mutated version of the code (“mutant”) should not pass the tests (the tests should “kill the mutant”). In this case, it appears that modifying checkBolsonPolicy(p) to true (which is the same as just removing it and the preceding \u0026\u0026) does not cause any tests to fail. Indeed, in TestValidPerson, none of the test cases violate the Bolson policy! If we try adding a test case person{\"Bob Rasmussen\", 15} this mutant would still survive, as checkAge(p) would return false; so we have to make sure checkBolsonPolicy on its own is sufficient to identify this test case as invalid. Indeed, adding person{\"Bob Rasmussen\", 19} to the test cases for TestValidPerson gets a mutation score of 1.0, fixing our problem. ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:2","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"Drawbacks Mutation testing can sometimes be noisy. For example, if we write validatePerson like so: func validatePerson(p person) bool { result := true result = result \u0026\u0026 checkAge(p) result = result \u0026\u0026 checkValidName(p) result = result \u0026\u0026 checkBolsonPolicy(p) return result } …then the following mutant would survive: --- bla 2021-05-09 15:57:12.242530400 +0100 +++ bla 2021-05-09 15:57:12.242530400 +0100 @@ -23,7 +23,7 @@ func validatePerson(p person) bool { result := true - result = result \u0026\u0026 checkAge(p) + result = true \u0026\u0026 checkAge(p) result = result \u0026\u0026 checkValidName(p) result = result \u0026\u0026 checkBolsonPolicy(p) I would treat this mutant possibility as very “meh”. So much like you shouldn’t necessarily fail your build if coverage is less than 100%, you probably shouldn’t fail your build if the mutation score is less than 1.0, and quite likely not based on the mutation score at all. It would help if there were a way to annotate lines as “do not mutate”. While zimmski/go-mutesting does support blacklisting of specific mutants, these blacklists are based on the checksum of the mutated code, which would have to be updated every time the tested code changes. Happy testing! ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:3","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":" I’ve been planning to write a blog post about Mutation Testing, and finally got around to it a couple of weeks ago. I set up my example, and looked to some publicly-available mutation testing tools for my programming language of choice, Go (I get to use it quite often as an engineer in Google). The best-maintained one appears to be go-mutesting, so I figured I’ll try it out. Unfortunately, I ran into a build issue with one of its depdencies: ../../../github.com/zimmski/osutil/capture.go:79: cannot assign to _Cmacro_stderr() ../../../github.com/zimmski/osutil/capture.go:79: cannot assign to _Cmacro_stdout() ../../../github.com/zimmski/osutil/capture.go:103: cannot assign to _Cmacro_stderr() ../../../github.com/zimmski/osutil/capture.go:103: cannot assign to _Cmacro_stdout() Yak shaving time! This was covered in zimmski/osutil#8, which showed it was an incompatibility with Go 1.10. ","date":"2018-08-04","objectID":"/posts/ioutil-yakshave/:0:0","tags":null,"title":"The osutil yakshave","uri":"/posts/ioutil-yakshave/"},{"categories":null,"content":"Testing the issue It turns out there’s a really convenient way to check this using Docker (which I finally took the time to learn for the umpteenth iteration of the show downloading stack): docker run -it --rm golang:1.9 go get -v github.com/zimmski/osutil This will download a minimal image for getting (using git), building, and running Go code, extract it, get the zimmski/osutil package, run the tests (successfully), and clean up after itself, leaving no trace on your system other than the cached base image for golang:1.9. Change the 1.9 to a 1.10 and the process will be identical, except for the version of Go, and fail. In my opinion that’s pretty astoundingly convenient, especially as the whole thing takes just under 38 seconds. We’re cheating here, of course - docker needs to be preinstalled, and you could solve this in other ways (e.g. gvm). However, docker is pretty ubiquitous nowadays (Google Cloud Shell conveniently includes it), and this method does have the benefit of testing on a completely clean image (no surprise dependencies). We can use a similar technique to test our fix, once we have it: On the host, go get github.com/zimmski/osutil, and from the downloaded directory, run: docker run -it --rm -v $PWD:/go/src/github.com/zimmski/osutil golang:1.10 \\ bash -c \"cd /go/src/github.com/zimmski/osutil; go get -t -v; go test -v\" This will mount the current directory into the GOPATH of the docker image (conveniently at /go), get the required dependencies, and run our tests. You could modify this one-liner to not remove the image every time, but seeing as it only takes 7 seconds on consequent runs, I didn’t bother. ","date":"2018-08-04","objectID":"/posts/ioutil-yakshave/:0:1","tags":null,"title":"The osutil yakshave","uri":"/posts/ioutil-yakshave/"},{"categories":null,"content":"The issue and the fix The root cause here is in capture.go, which provides the Capture and CaptureWithCGo functions. These get a func() callback, capture whatever it outputs to stdout and stderr, and return them as a string. The Capture function only works with pure Go code, and CaptureWithCGo is meant to support code that includes CGo as well. The latter assumes that the CGo code would use the C stdout and stderr globals (which are FILE * pointers which are used by printf and fprintf), so it creates a pipe and points stdout and stderr at it. This has two problems: Assigning to stdout and stderr is no longer allowed in Go 1.10 (and, according to golang/go#25221, was never intentionally allowed). Functions could output to standard output and error in other ways, such as calling external programs or using the write system call. This is true for the Capture function as well, but I wanted to modify as little behavior as possible. Technically, the behavior-preserving solution could be to just use freopen instead, but I didn’t know about it at the time. In general, capturing output using redirects seems to me like it should capture all output, regardless of how it’s generated. To accomplish this, let’s first have a look a how shells accomplish redirects. $ strace -f bash -c '/bin/echo hello \u003e /tmp/redirected' ... [pid 20210] openat(AT_FDCWD, \"/tmp/redirected\", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3 [pid 20210] dup2(3, 1) = 1 [pid 20210] close(3) = 0 [pid 20210] execve(\"/bin/echo\", [\"/bin/echo\", \"hello\"], 0x556c1736e260 /* 30 vars */) = 0 ... Here, strace runs a parent bash process (pid 20209, not shown in the trace above), which forks into PID 20210 which ultimately ends up running /bin/echo (and not the echo bash builtin). To accomplish the redirect, bash does the following: Open the requested file, which ends up being file descriptor 3. Use the dup2 system call to overwrite file descriptor 1 (standard output) with the same file descriptor as 3. Now this open file has two descriptors pointing at it. Close file descriptor 3; this reduces the number of file descriptors pointing at /tmp/redirected back to one. Finally, uses execve to replace the running program with /bin/echo, which will (as always) output to file descriptor 1, which now points to /tmp/redirected. No matter how echo internally causes output to appear (even if it ran yet another binary), the output would always go to /tmp/redirected. It’s worth mentioning that the dup system call is similar to the dup2 system call, but the caller doesn’t choose the destination file descriptor; instead, the first available file descriptor is used and returned. This technique is the basic one behind the fix. The old method was, roughly: Save the old os.Stdout, os.Stderr, C.stdout, and C.stderr objects Open a pipe - this gets you two file descriptors (w.Fd() and r.Fd()) Point the Go objects os.Std{out,err} at w.Fd() by just assigning w to them Point the C objects C.std{out,err} at w.Fd() by opening it with fdopen and assigning the result to them. (This no longer works) Call the callback function Copy from the r end of the pipe to a buffer using io.Copy. When the method returns (using defer), restore the four objects we saved The new technique is, roughly: Use syscall.Dup to save file descriptors 1 and 2 (standard output and error) Open the pipe as before Use syscall.Dup2 to overwrite file descriptors 1 and 2 with w.Fd() When the method returns, restore the original file descriptors Call the callback function Close all instances of the w end of the pipe Copy from the r end of the pipe to a buffer using io.Copy. WHen the method returns, restore the original file descriptors 1 and 2 When closing all instances of the w end of the pipe, this means w.Fd(), syscall.Stdout, and syscall.Stderr. If any of those three stays open, the underlying file descriptor will still count as open, and io.Copy will never return. To demonstrate this, let’s take a look at a simplified version (no error handling, don’","date":"2018-08-04","objectID":"/posts/ioutil-yakshave/:0:2","tags":null,"title":"The osutil yakshave","uri":"/posts/ioutil-yakshave/"},{"categories":null,"content":" My native language, Hebrew, has a useful term - the “Matzliah” method. It’s documented in a hebrew wikipedia entry, but my translation can’t make it past the draft stage. I’ll add my translation here for posterity: The “Matzliah” (Hebrew: מַצְלִיחַ) method is a common phrase in Hebrew slang, translating roughly as “Works”, which describes exploitation of other people’s lack of attention, and capitalization on their account. Its name is based on a joke, which tells of a restaurant customer, who discovers a charge for an item called “Matzliah”, which they don’t remember ordering. To the question of what dish this is, the waiter responds: “If the customer pays, it works (matzliah)”. In its most common and most negative description, the method exists between two parties who have a business or other relationship. It is based on premeditated and hidden dishonesty, and includes an attempt of one side to perform an action that affects the other. The effect of the action depends on the second party and their ability to detect the attempt. With detection, the first party withdraws the action. The Israeli law of consumer protection determines in section 13D1 (A) that if a customer was overcharged in an ongoing deal beyond the amount the business-owner is allowed to charge according to the details of their agreement, the business-owner will return the excess with interest and indexation, in 4 business days. Furthermore, the businessman will compensate the consumer at 16 Israeli new shekel for their expenses. ","date":"2017-10-23","objectID":"/posts/matzliah/:0:0","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":"Usage of the method This method is most prevalent in the financial field, for example: A commercial company increases its service charge without notifying the customer; this is done under the assumption that the customer, who is used to get their monthly charge, will not notice the change. If the assumption turns out to be true, it “works”; if the customer notices and appeals the charge - it “doesn’t work”, and the company will correct the charge, with barely any damage (e.g. public relations damage). The constant rule of this method, from which it gets is name, is “if it works - it works; if it doesn’t work - it doesn’t work”; in other words, there’s a chance the attempt will succeed, and conversely, little to no damage will happen if it won’t, so there’s nothing to lose and it’s worth trying. The Matzliah method occurs in other fields as well: A business-owner that doesn’t pay their employees the full wage and benefits they deserve Litigation intended to intimidate into settlement, such as vexatious litigation. A business-owner deducts taxes for expenses, when they are unsure if the expenses are deductible or not. If the IRS does not review this business, it works. If a review occurs, they will remove the deduction. A failing politician is called to resign, but does not hurry to do so, assuming that the public is otherwise occupied. If the public notices, the politician can always resign. An insurance company dismisses a claimant’s demand for payment with various claims, such as contradicting with the terms of the policy. If the claimant does not respond nor refer to the courts, the insurance company profits (due to non-payment). If the claimant does refer to the courts, the insurance company will offer to settle for a partial sum, hoping that the claimant, due to pressure and interest in shortening legal proceedings, will agree to it. The insurance company will, at most, pay part of the policy’s sum. (See Insurance bad faith). In The Rainmaker, a young lawyer called Rudy Baylor deals with an insurance company operating with the Mazliah method: it would initially deny every insurance claim submitted, and only pay claimants that continued to fight for their rights. A softer version of the Mazliah version is “at least we tried”, or “can’t blame us for trying”. In this version, an attempt is made to gain an advantage, but not necessarily with fair means. For example, haggling by presenting unreasonably extreme opening positions. ","date":"2017-10-23","objectID":"/posts/matzliah/:0:1","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":"See also Patent troll ","date":"2017-10-23","objectID":"/posts/matzliah/:0:2","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":"External links A verdict denouncing the “Matzliah” method Insurance companies and the “Matzliah” method, at the Israeli bar association. ","date":"2017-10-23","objectID":"/posts/matzliah/:0:3","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew due to the target audience. TL;DR - TransportDroidIL can no longer function. תקלה ב-TransportDroidIL לצערי, האפליקציה TransportDroidIL הפסיקה לפעול, והסיבה היא כזו שלא מאפשרת תיקון. אני ממליץ בחום על החלופה Google Maps. ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:0:0","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"שאלות ותשובות ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:0","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"למה האפליקציה הפסיקה לעבוד? האפליקציה TransportDroidIL פועלת ע\"י בקשת נתונים מאתר אגד או משרד אתר התחבורה, תוך שימוש במנגנון ה\"שפה חופשית\". שני האתרים השתנו בצורות שונות, שלא מאפשרות לאפליקציה לפעול יותר: באתר משרד התחבורה, מנגנון ה\"שפה חופשית\" כבר לא עובד כלל - קופצת ההודעה [object Object], ומאחורי הקלעים ניתן לראות שהאתר לא מקבל מרכיב ה\"שפה החופשית\" תשובה. באתר אגד, מנגנון ה\"שפה החופשית\" עדיין פועל,והשתנה יחסית מעט, ויכול בהחלט להיות אפשרי לגרום לאפליקציה לעבוד איתו שוב, אבל… ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:1","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"רגע רגע, בעצם האפליקציה לא עושה שום דבר ומביאה את כל הנתונים מאתרים קיימים? אז למה כתבת אותה? נכון! הסיבה שכתבתי את האפליקציה הייתה שהאתרים האלה, בספטמבר 2010, לא היו מותאמים לטלפונים ניידים והשימוש בהם מהנייד היה כאב-ראש מוחלט. למעשה, אתר משרד התחבורה עדיין לא מותאם, ונראה כיום דומה מאוד לאיך שאתר אגד נראה ב-2010. האפליקציה הייתה מיועדת אך ורק לתת ממשק משתמש נוח יותר לאותם האתרים. למרבה השמחה, אתר אגד מותאם כיום בצורה פחות-או-יותר סבירה לטלפונים ניידים. לא מושלם, אבל בהחלט שמיש. אך, חשוב מכל… ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:2","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"בתכל’ס יש אפליקציות יותר מוצלחות, כמו Google Maps, אז למה להשתמש באתרים האלה בכלל? אין יותר סיבה! ב-2010 Google Maps אמנם לא סיפקה מידע תחבורה ציבורית בישראל, אבל כיום המידע קיים שם בצורה מלאה ומקיפה. המידע מגיע לגוגל ישירות מאתר מאגרי המידע הממשלתיים, בפורמט GTFS המותאם לכך. זו האפליקציה בה אני משתמש כיום. המידע המסופק הוא, כמו תמיד, מידע של לוחות זמנים ולא מידע זמן-אמת. כולי תקווה שחברות האוטובוסים יתחילו לפרסם מידע זמן-אמת בפורמט GTFS-realtime, אשר יגרום לכך ש-Google Maps ואפליקציות אחרות יוכלו להראות מידע מציאות יותר על זמן הגעת האוטובוסים. ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:3","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"מי פיתח את האפליקציה ומה הקשר שלו לעניין? אני המפתח המקורי של האפליקציה - שמי אוהד לוצקי. התחלתי לעבוד על תוכנות שמביאות מידע מאתר משרד התחבורה בזמן שהייתי סטודנט בטכניון שנוסע הרבה באוטובוסים, בערך ב-2007. ב-2010 המרתי את התוכנה לאפליקציית אנדרואיד כשהייתי בצבא ונסעתי הרבה באוטובוסים; כמה חברים התעניינו, והעליתי את התוכנה ל-Play Store. חבר טוב מהלימודים, חגי, שלח מספר שיפורים ואף הוסיף מנגנון עדכוני-זמן-אמת, אשר היה תלוי בחסדי האתרים של חברות אוטובוס ספציפיות שסיפקו, גם הן, את המידע בצורה לא-סטנדרטית. בשלב כלשהו עלו אפליקציות חלופיות לרשת, דוגמת Moovit - אך אף אחד מהן לא מצאה חן בעיניי. בפרט, ל-Moovit לקח זמן רב לעלות, בעוד שהאפליקציה שלי הייתה מיועדת למבט מהיר תוך כדי שהאוטובוס מתקרב לתחנה. בשלב כלשהו (2012 לכל המאוחר) משרד התחבורה התחיל לפרסם מידע GTFS שאפשר לגוגל להציג מידע תחבורה ציבורית בישראל, ואני הפסקתי להשתמש באפליקציה שכתבתי. Google Maps מראה את התחנות על מפה, רשימת תחנות-ביניים ועוד. עם זאת, מאחר ולאפליקציה עוד היה מספר לא-קטן של משתמשים (קצת יותר מ-55,000 בשיא), המשכתי לתקן בעיות קטנות כשהן צצו וכשהיה לי זמן. כיום אני עובד בגוגל בעצמי - לא בצוות של Google Maps, אלא בצוות Search. אני בהחלט חושב שגוגל מספקים מענה טוב יותר לתחבורה ציבורית מאשר TransportDroidIL 😄 ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:4","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"The Faculty Programmer Sharon, a close friend of mine, has been studying psychology for the past few years. At some point she needed to run an experiment in the field of perception. While the exact form of the experiment was pending professor vetting, she did know that the experiment will take place with a user sitting in front of a desktop computer, responding to various stimuli, often with the reaction time being recorded. Seeing as programming is not in her faculty’s curriculum (a mistake, in my opinion), the students are provided with a faculty programmer. Dozens of students would contact this jaded craftsman, describe what they need, wait patiently, and then - as it happens in the world of software - receive something almost, but not quite, entirely unlike what they asked for. I was all too happy to help (and owe Sharon an insurmountable number of favors to start with), but had nothing to start with at the time. The weeks and months passed, I was deep into my move and training at my new job1, and happily suggesting (using my limited understanding of psychology) experiments. When the final proposal was authorized, the timing was inconvenient - I was going on a business trip to California the next day, putting a 10 hour time difference between Sharon and myself. No matter. The experiment was fairly well-defined before I left - a word out of three word-sets, designated as “up”, “down” and “neutral”, was to flash in the middle of the screen, and then a circle would appear at the top or bottom. The user had to react to this circle as quickly as possible, and the idea was to test whether or not a word from the “up” category (such as “sky” or “cloud”) would correlate with better reaction time when the circle appeared at the top, and vice versa. There were some other details such as “catch trials” when no circle would show up at all, but it sounded fairly simple. (Keep reading for a demo!) ","date":"2015-05-30","objectID":"/posts/seaplane/:1:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"Getting started My experience had me worried, as no software project is ever as simple as it originally seems. Sharon and I agreed that, while this seems completely reasonable and quite thought-out, we would work in an iterative fashion, and have regular video-chats on what should be done next. Also, to simplify things, I asked to create the software as a web page intended for use on Chrome, rather than Matlab as suggested by her faculty programmer (who seemed convinced, for whatever reason, that Matlab could give better timing precision - this turned out to be false). She agreed, and within a few hours on a plane, I had a basic draft working. I emailed Sharon a copy of the draft; it was split into a simple index.html file, a style.css file, a seaplane.js code file, and a config.js code file. That last split was deliberate: Sharon, who has no experience in coding (and even claims to be a technophobe), could modify clearly defined configuration (including the sets of words and tuned delays) with no anxiety of “messing up” the more complex code. Soon enough, timezones flipped by, and Sharon was happy enough with the result to respond with a modified config.js file, and a list of changes she wanted - mostly present in the original requirements, but some which could only be understood while trying out the first draft. Naturally, some of the changes would require the syntax of config.js itself to change, and Sharon had more data to add to it. To avoid seaplane7-final-really.zip email attachments flying back and forth, version control would be required. Using Github would facilitate this, and also allow us to use its Issues mechanism for tracking remaining work. It took a few minutes over the phone to explain the basic concept of version control to Sharon, as well as how to create a Github account, modify files using the web-based interface, report and comment on issues. While I did mention Github for Windows as an option, I didn’t pressure Sharon into using it, especially as I wasn’t familiar enough with it myself. Over 10 days and 48 commits (27 mine, 20 Sharon’s) we got the code working well enough to run the experiment. There were a few reported bugs, but nothing substantial that skewed the results, as far as we can tell. You’re welcome to see a Demo of Seaplane, as well as browse the Seaplane source code. If you can read Hebrew, you can also read Sharon's paper. ","date":"2015-05-30","objectID":"/posts/seaplane/:2:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"What worked Issues worked quite well for tracking the work; Sharon and I found them more useful than emails for keeping state. Being a fully client-side web application, seaplane was (and still is) trivially hosted by Github Pages. This made deployment of new versions as easy as hitting F5. For changes that could be previewed in chrome using developer tools, Sharon got instant feedback on her changes without needing to commit anything. Sharon made 4 commits to change config.js, modifying the word sets according to discussions with her supervisor. Sharon also made 11 commits to change style.css, 2 commits to change index.html, and even 3 to change seaplane.js. ","date":"2015-05-30","objectID":"/posts/seaplane/:3:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"What didn’t work Github’s UI for submitting changes online has a default value for the commit message, and no recommendations against using it. As a result, there are 8 commits called “Update style.css”. Sharon didn’t have a working copy on her own machine, and not all changes could be easily previewed in chrome. As a result, there were some back-and-forth commits by Sharon and myself which weren’t necessary. (I could’ve avoided this by providing appropriate “refresh” functionality in the app) The format I chose for the word list made right-to-left issues rear their ugly head in the editor. All in all, the project went swimmingly. Using progamming-oriented version control software to collaborate with non-programmers may be less crazy than you think. I highly recommend giving it a try. Oh yeah, I’m a Site Reliability Engineer at Google Ireland now, which is too awesome to detail in this footnote. ↩︎ ","date":"2015-05-30","objectID":"/posts/seaplane/:4:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":" This is part of the “Git While You Sit” series, a play on Google’s Testing on the Toilet. It’s intended to fit on a printed page. Currently Chrome doesn’t seem to correctly print columns, but Firefox does. {: .no-print } Sometimes, git does something unexpected while merging or rebasing. It might seem like git misunderstood a rename, but it’s far more likely that git did the “right” thing after all. Here are a couple of examples I’ve seen recently. ","date":"2014-08-17","objectID":"/posts/git-rename-edge-cases/:0:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 3 - \"Rename\" edge cases","uri":"/posts/git-rename-edge-cases/"},{"categories":null,"content":"First case When rebasing, conflicts might occur before renames: o---o---E---F---G (master) \\ A---B---RENAME---C (feature *) When the current branch is feature, and running git rebase master, what happens is that the commits from feature will be cherry-picked onto G in order - A, B, RENAME, and C. If a conflict occurs in B, in a file that was later renamed (in RENAME), conflict resolution will have to happen using the original name. If there was a massive reworking, it might be simpler and more sensible to merge in this case. ","date":"2014-08-17","objectID":"/posts/git-rename-edge-cases/:1:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 3 - \"Rename\" edge cases","uri":"/posts/git-rename-edge-cases/"},{"categories":null,"content":"Second case It wasn’t a rename, it was a copy. --o---E----F [MODIFY]----G (master) \\ \\ A---B [COPY]---C---D---M (feature *) In this case, the user thought he renamed dir1/file.xml to dir2/file.xml in B [COPY]. Then, when he merged master into feature, he expected that the modifications in file.xml in F [MODIFY] would, as part of the merge in M, be applied to dir2/file.xml. This would indeed have happened if B had a move operation. However, it doesn’t make sense for git to merge the changes from a copy of a file, so it didn’t. The fix here was to undo the merge: git reset --hard D …and then edit the commit: git rebase -i A …and set B to edit instead of pick. Amend the commit for B so that it doesn’t just create dir2/file.xml, but also deletes dir1/file.xml. If it’s indeed the same file (or has very similar contents), this will be automatically detected as a rename during log and merge operations. It should be noted that git doesn’t track renames (or copies) at all during commits. It only figures out that they happened retroactively when it’s relevant (log, merge, cherry-pick, diff…), by comparing the contents. This is why those operations have options like rename-threshold, find-renames, find-copies and even find-copies-harder. ","date":"2014-08-17","objectID":"/posts/git-rename-edge-cases/:2:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 3 - \"Rename\" edge cases","uri":"/posts/git-rename-edge-cases/"},{"categories":null,"content":" This is part of the “Git While You Sit” series, a play on Google’s Testing on the Toilet. It’s intended to fit on a printed page. Currently Chrome doesn’t seem to correctly print columns, but Firefox does. {: .no-print } Your repository has files which are generated as part of your build process or as part of running your software, which you don’t want in source control. They keep showing up in git status. What to do? You can create a file called .gitignore - note that the filename starts with a ., which is standard for configuration files in Unix and causes them to be hidden from normal listing. Each .gitignore file affects the current directory and its subdirectories - you can have multiple .gitignore files to create more specific rules for subdirectories. Note: .gitignore can only be used for files which shouldn’t be in source code at all (those show up as “Untracked files”. Modified files can’t be ignored in this way. If you really want to, you can force git to ignore modifications with this command: git update-index --assume-unchanged FILE However, this is usually a bad idea and indicates you need to refactor your file handling - split files which get modified locally from files which contain information which should be source-controlled. Here is an annotated excerpt from a .gitignore file: # Extensions of compiled files *.a *.so *.o # ... # Files generated by build system build.ninja .ninja_deps # Ignore bin/ and obj/, as they contain # compiled files. This is ignored # recursively within the repository. bin/ obj/ # ...except (\"!\") for the scripts, which # are in the \"scripts\" dir in the same # one as this .gitignore file (hence the # leading \"/\") !/scripts/bin Addendum: A reader has mentioned gitignore.io, which auto-generates useful .gitignore files. ","date":"2014-08-15","objectID":"/posts/git-ignore/:0:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 2 - .gitignore","uri":"/posts/git-ignore/"},{"categories":null,"content":" This is part of the “Git While You Sit” series, a play on Google’s Testing on the Toilet. It’s intended to fit on a printed page. Currently Chrome doesn’t seem to correctly print columns, but Firefox does. {: .no-print } Ever find yourself printf-debugging? You found the bug, but now you have printf statements all over the place. Running git diff, you get: diff --git a/hello.c b/hello.c index 93ca08c..c7d354a 100644 --- a/hello.c +++ b/hello.c @@ -4,6 +4,7 @@ void b(); void a() { + printf(\"Bug is here?\\n\"); return; } @@ -13,9 +14,10 @@ int main() { printf(\"Hello, world!\\n\"); - return 1; + return 0; // Found it! } void b() { + printf(\"Bug is here?\\n\"); return; } It’s actually pretty easy to get rid of them. Run git add -p and you will be shown each patch “hunk” separately: diff --git a/hello.c b/hello.c index 93ca08c..c7d354a 100644 --- a/hello.c +++ b/hello.c @@ -4,6 +4,7 @@ void b(); void a() { + printf(\"Bug is here?\\n\"); return; } ### Stage this hunk [...]? n (No) ### @@ -13,9 +14,10 @@ int main() { printf(\"Hello, world!\\n\"); - return 1; + return 0; // Found it! } void b() { + printf(\"Bug is here?\\n\"); return; } ### Stage this hunk? [...] s (Split) ### @@ -13,7 +14,7 @@ int main() { printf(\"Hello, world!\\n\"); - return 1; + return 0; // Found it! ### Stage this hunk [...]? y (Yes) ### void b() { + printf(\"Bug is here?\\n\"); return; } ### Stage this hunk [...]? n (No) ### Now, only the return 0 line is stage for commit. To get rid of the rest of the changes, run git checkout -- hello.c. Now the printf statements have been removed! ","date":"2014-08-13","objectID":"/posts/git-add-patch/:0:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 1 - Add --patch","uri":"/posts/git-add-patch/"},{"categories":null,"content":" After 6 years with my previous employer, as a DevOps engineer and DevOps team leader, I’ve learned two important lessons. I wanted to get these in here before I start my new position (…as an SRE in Google Dublin, which I am very excited about!), as it’s always fun to look back after a few years and see if what I wrote is still relevant. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:0:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"Keep it tidy Working in a tidy manner is incredibly important. Tidy code is more important than fast code. It’s even more important than correct code! Tidy code is obvious about what it does, and the incorrectness will be apparent to anyone who reads it. However, correct messy code will be misleading about what it does, and what subtleties had to be dealt with in order for it to be correct. This will cause long hours and hair loss when refactoring or when tending to changing requirements. Requirements change. A good team leader will be able to predict how they’ll change, and direct his team around that. Incorrect predictions are inevitable and costly, but so is a complete lack of change prediction. Operations need to be just as tidy as code, if not tidier. Operations performed manually will inevitably be performed wrong, usually by the one person you’re sure can’t possibly get it wrong. As such, operations need to be as idiot-resistant as possible (nothing is completely idiot-proof). “Run this job in Jenkins, the rest is a script” is a good place to be, but you should make sure it’s really hard to run the wrong job, or get any parameters harmfully wrong. Any knowledge contained within one brain reduces your bus factor to 1. Use pair programming (or pair-ops) to increase your bus factor. Whenever possible, let someone from your team tackle a task he has no idea how to perform, but make sure both you and someone knowledgeable are available (and willing) to answer questions. However, containing knowledge within brains is fleeting - even with a high bus-factor, some areas will be left untouched for years, and subsequently re-touched when nobody remembers anything about them. When this happens, you’ll be much happier to find out your predecessor (or past-you) has left solid documentation and completely obvious code. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:1:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"Don’t write it yourself This is a special case of “keep it tidy”. Writing your own code should be your last resort: Someone else has already written, tested, fixed, debugged, documented, rewritten, and perfected a piece of code that does exactly what you need. They did this with the help of far better coders than you can afford and a QA team comprised of countless relentlessly nitpicking users. Your problem is not as unique as you think. You will ignore this advice. You’ll write your own “super efficient” database/JSON parser combo, and guard it as a trade/military secret. And it’ll even work for the first few years, and perform fantastically. But as requirements change (requirements change!), you’ll suddenly find out that you can’t push new features and bugfixes out as fast as your competition. This happens because your competition is using a widely-adopted database, and a (separate) widely-adopted JSON parser. These are both open-source, and you will see that some kid in a basement has stumbled onto your clever optimizations and suggested them - these have been merged in. And while you’re stuck debugging your code, with its sparse unit tests and misleading function names, your competition is looking up known issues and workarounds on Stack Overflow. Hiding within this advice is the one worse thing you can do than writing it yourself: Using unpopular closed-source software (especially if it’s hard/impossible to search for in Google). This has all the detriments of writing code yourself, with the added hell of being unable to read or modify the code yourself when something goes wrong. This advice is clearly quite extreme and is intended to be cautionary (and you will therefore, as mentioned, ignore it). You probably do have some business logic to implement. You probably do need to write glue code in order to connect your proprietary code with some external provider. You might be dealing with insane, Google-scale problems and have found (after checking!) that all existing solutions don’t meet your performance/capacity criteria. But this is no reason to implement your own version of ping. Or rsync. Or cron. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:2:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"Afterword That’s my 2 cents on how to do DevOps (for a rather narrow definition of DevOps). They’re the instructions I left my team. I wonder if they’ll stand the test of time. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:3:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":" I’ve recently been rewriting a mess of bash, tcsh and Python code as a Python script, and this has proven interesting to test. I’ve written a tiny Python library called fakefile to help out with it, so I can write code like this: import fakefile import unittest import mock def my_function(): with open(\"somefile\", \"w\") as f: f.write(\"correct output\") with open(\"existing_file\", \"w\") as f: return f.read() class TestMyCode(unittest.TestCase): def test_my_function(self): faker = fakefile.FakeFile() faker.set_contents(\"existing_file\", \"correct input\") with mock.patch('__builtin__.open', faker.open): result = my_function() # No file \"somefile\" will be created! # No file \"existing_file\" will be read! self.assertEquals(faker.files[\"somefile\"].file_contents, \"correct output\") The library is available on github as lutzky/fakefile. Naturally, however, it turns out I’ve been outdone by Google’s pyfakefs. They have some clever bast^H^H^H^Hgooglers working there! ","date":"2014-07-02","objectID":"/posts/fakefile/:0:0","tags":["software","python","testing"],"title":"FakeFile","uri":"/posts/fakefile/"},{"categories":null,"content":" Here’s a fun little bash script: #!/bin/bash ( sleep 20 \u0026 ) ps -f $(pidof sleep) echo \"Bye\" Run it, and you’ll notice a few things: Because the subshell running sleep dies immediately, sleep gets reparented to init. (Interestingly enough, on newer Ubuntu releases this isn’t PID 1…), so the script doesn’t have any child processes by the time it prints “Bye”. After “Bye” is shown, the script exits immediately, returning control to the shell. Now, call the script pied_piper.sh, and try the following: ./pied_piper.sh | cat ./pied_piper.sh | ts # Awesome timestamping utility, same problem though ssh localhost ./pied_piper.sh Annoying, isn’t it? These commands won’t finish for 20 seconds! The problem is that sleep is keeping its stdout open, which is the input pipe for cat, ts, ssh, or whatever else you’re piping to (this is very annoying on Jenkins jobs as well). If a third-party product is pissing you off this way - that is, it died, but somehow still keeps its pipe open, you can find the culprit like so: fuser -v /proc/$PID_OF_PROCESS_WITH_OPEN_PIPE/fd/0 This will usually yield a sleep process as the culprit, with the useless parent information of init (as per my example). The only information you have is the precise delay - in my experience, it helps to find all “sleep” commands lurking about, and tinker with the delay amounts: Found a sleep 30? Change it to sleep 29, see if that’s what shows up. Here’s how to actually fix the problem: #!/bin/bash ( sleep 20 \u003e\u0026- 2\u003e\u0026- \u003c\u0026- \u0026 ) ps -f $(pidof sleep) echo \"Bye\" This will close stdout, stderr and stdin. As a friend pointed out, it’s often safer to do \u003e /dev/null rather than \u003e\u0026-, as some processes will crap out if they don’t have some semblence of an stdout. However, \u003e\u0026- is shorter, faster, and perfectly safe for sleep. Of course, it’s better to save the PID for this sleep and kill it when appropriate from within the script - otherwise, you might be accumulating many useless sleep processes. ","date":"2014-06-22","objectID":"/posts/fun-with-file-descriptor-leaks/:0:0","tags":["software","linux"],"title":"Fun with file descriptor leaks","uri":"/posts/fun-with-file-descriptor-leaks/"},{"categories":null,"content":" There is a well-known problem on today’s social network platforms - spoilers. Anyone watching a show and failing to immediately catch up to the latest episode will see a lot of posts on their feed dancing around the spoiler, and finally revealing it completely. This makes sense - people like to talk about their favorite shows, and social networks are a great place to do it. What I’d like to suggest is a mechanism for mitigating the spoiler problem. This mechanism is optimized for Facebook, but could easily be applied to Google+, Twitter et cetera. The short version: Mark potential spoilers, keeping track of what exactly they might be spoiling Allow voluntary marking by the original poster Allow reporting of spoilers, similarly to spam reports Collapse spoiler materials, showing what is being spoiled Allow users to view spoilers When they do this, optionally “learn” that these spoilers can now safely be shown. For an example, consider the following scenario: I’m watching the fantastic show Game of Scones, and in the latest episode - season 4, episode 3 - Lord Muffin has been surprisingly murdered. I might want to post the following status: OMG can’t believe Lord Muffin was murdered no waayyyyyy Now, one of the following happens: Before posting, I check a box saying “this status contains spoilers”, clearly indicating Game of Scones S04E03. I post without checking the box, ticking off my spoiler-sensitive friends. Several unfriend me, but a few of them hit the “Spoiler alert” button adjacent to the post. Bonus points: The social network platform automatically recognizes the spoiler and asks me to mark it. Once the post was marked, it looks like this: Spoiler to Game of Scones S04E03 hidden. Click to unhide Clicking the “click to unhide” link should, naturally, show the status as it was originally posted. However, the social network can be smarter about this, and remember that as of now - spoilers to S04E03 are OK, and shouldn’t be hidden from the user. A few notes about this: This shouldn’t be done automatically, and a confirmation should be shown - at least at first (“Should spoilers for this episode still be hidden? Show Spoilers/Keep hiding spoilers”) Posts containing spoilers should have a small visual indicator of them being as such. This is a good hint for what other people are seeing, and assists helpful users in marking spoilers. It would be useful to allow searching for spoilers - for example, if I just saw the episode and want to see what people are saying about it. Finally, this is a neat signal that can be used by whatever social network implements it - imagine, a percentage graph of “how many people have already watched the latest episode”. Seeing as many people Tivo or torrent episodes, that kind of data has got to be worth some money to someone. Note that there are existing spoiler prevention mechanisms implemented as browser extensions, and what I’m suggesting is more complex and requires integration into the social network itself. This is important anyway, as you want the social network to work the same on any device or browser. Unfortunately, this also means that I am currently powerless to implement it. So if you think this is a good idea and know someone relevant, pass it along! ","date":"2014-04-26","objectID":"/posts/social-network-spoiler-prevention/:0:0","tags":null,"title":"Social network spoiler prevention","uri":"/posts/social-network-spoiler-prevention/"},{"categories":null,"content":" My show downloading stack lives on. I’m curious as to which will happen first: NetFlix hits Israel, or I switch over to Sick Beard. At any rate, nowadays I use flexget, transmission, tvnamer and xbmc, held together with some bash scripts. On debian- and ubuntu-based systems, the transmission daemon runs as a separate user (debian-transmission), so this requires a bit of care with file and group ownership. After rebuilding my system, I couldn’t get tvnamer to work right for some reason, no matter how careful I was. I’d keep getting this error: Loading config: config.json #################### # Starting tvnamer # Found 1 episode #################### # Processing file: Sherlock.S03E01.mkv # Detected series: Sherlock (season: 3, episode: 1) #################### Old filename: Sherlock.3x01.The.Empty.Hearse.720p.HDTV.x264-FoV.mkv New filename: Sherlock - [03x01] - The Empty Hearse.mkv New path: /home/debian-transmission/inbox/Sherlock - [03x01] - The Empty Hearse.mkv Creating directory /home/debian-transmission/inbox rename Sherlock.3x01.The.Empty.Hearse.720p.HDTV.x264-FoV.mkv to /home/debian-transmission/inbox/Sherlock - [03x01] - The Empty Hearse.mkv OSError(1, 'Operation not permitted') New path: /media/Store/shows/Sherlock/Season 3/Sherlock.3x01.The.Empty.Hearse.720p.HDTV.x264-FoV.mkv Creating directory /media/Store/Shows/Sherlock/Season 3 OSError(2, 'No such file or directory') For a few weeks I’d double-check the permissions, fail to understand what was going on, groan and copy the files manually. The new Sherlock episode had me in a bit of a more investigative mood. This turns out to be an exercise in confusing OS logic and logging. It looks like the rename operation failed, and somehow the directory creation failed as well. Neither is the case. A hint can be found in the precise error after the rename: “1 - Operation not permitted” (that’s EPERM). If that seems a bit off, that’s because it is: When renames fail because of inadequate permissions, they return EACCES “13 - Permission denied”. So what’s going on? It turns out that after renaming, tvnamer tries to preserve the access and modification times of renamed files. A noble cause, but it turns out that Linux won’t allow this unless you are the owner of the file - even if you do have write permissions. Therefore, this fails, which causes tvnamer to believe the rename failed - although it hasn’t. Afterwards, the directory is created (this succeeds), but since tvnamer tries to copy using the old filename (thinking the rename failed), we get an ENOENT “2 - No such file or directory” error about the source of the copy operation. The fix can be found in this pull request. Happy bug hunting! ","date":"2014-01-05","objectID":"/posts/investigate/:0:0","tags":["software","show downloading"],"title":"Weird permission issues with tvnamer","uri":"/posts/investigate/"},{"categories":null,"content":" Lately, a facebook comment of mine on the subject of Java’s slowness has proved quite popular, so here goes: Here’s a listing of a few Hello World programs and running times for them (including startup, which is a big deal in Java) on my laptop: $ grep '^model name' /proc/cpuinfo | head -1 model name: Intel(R) Core(TM) i5-3337U CPU @ 1.80GHz $ uname -a Linux orca 3.11.0-14-generic #21-Ubuntu SMP Tue Nov 12 17:04:55 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux The following script will be timed: #!/bin/bash n=$1 shift for ((i=0; i \u003c $n; i++)); do $@\" \u003e /dev/null done Times are for n=100. ","date":"2013-12-11","objectID":"/posts/startup-times/:0:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"C #include \u003cstdio.h\u003e int main(int argc, char * argv[]) { printf(\"Hello, world!\\n\"); return 0; } /* Result: 0.17s * ...unless you give it a .cc extension, and then it's 0.30s! * It turns out that gcc/g++ guess the language from the file extension. */ ","date":"2013-12-11","objectID":"/posts/startup-times/:1:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"C++ #include \u003ciostream\u003e int main(int argc, char * argv[]) { std::cout \u003c\u003c \"Hello, world!\" \u003c\u003c std::endl; return 0; } // Result: 0.30s ","date":"2013-12-11","objectID":"/posts/startup-times/:2:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"Python #!/usr/bin/python print \"Hello, world!\" # Result: 1.33s ","date":"2013-12-11","objectID":"/posts/startup-times/:3:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"Java public class Hello { public static void main(String args[]) { System.out.println(\"Hello, world!\"); } } // Result: 8.60s. No, I am not kidding. There you have it. Sun’s Java takes 28x-51x as much time to run “Hello World” (startup included) than native applications, and (shockingly, in my opinion) over 6x as much as non-precompiled Python. That’s meaningless for long-running applications, but is a very big deal for small, often-run ones. ","date":"2013-12-11","objectID":"/posts/startup-times/:4:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":" I’ve had several opportunities to write unit tests for code that outputs large strings. It’s important that your unit-testing framework handles this well. Here’s my example data: STRING_A = \"\"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. Suspendisse ut augue placerat, venenatis ante a, aliquam nibh. Sed vitae massa a nibh dignissim porta id rhoncus neque. Etiam commodo dapibus magna sit amet pellentesque. Aenean venenatis vulputate eros, sit amet sagittis ligula laoreet vel. Pellentesque consectetur viverra nunc, vel interdum turpis tempor nec. Quisque vel purus in quam facilisis gravida posuere in mi. Aenean ligula sem, mattis ut feugiat sit amet, lobortis ut sapien. Vestibulum laoreet aliquam lorem pulvinar lobortis. Mauris quis orci lorem. Mauris ut ante id nulla ultrices gravida vel et orci. Suspendisse potenti. \"\"\" STRING_B = \"\"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. Suspendisse ut augue placerat, venenatis ante a, aliquam nibh. Sed vitae massa a nibh dignissim porta id rhoncus neque. Etiam commodo dapibus magna sit amet pellentesque. Aenean venenatls vulputate eros, sit amet sagittis ligula laoreet vel. Pellentesque consectetur viverra nunc, vel interdum turpis tempor nec. Quisque vel purus in quam facilisis gravida posuere in mi. Aenean ligula sem, mattis ut feugiat sit amet, lobortis ut sapien. Vestibulum laoreet aliquam lorem pulvinar lobortis. Mauris quis orci lorem. Mauris ut ante id nulla ultrices gravida vel et orci. Suspendisse potenti. \"\"\" STRING_A and STRING_B are different, by one character. Can you tell which one? If you’d use your unit testing framework’s equivalent of assertEqual(STRING_A, STRING_B), it would correctly report that they are different. But would it help you identify the difference? C#, for example, is quite horrible with this. It outputs both strings in their entirety. In Visual Studio, it doesn’t even seem to be possible to copy the output into an external comparison tool. This has caused some developers (myself included) to implement an ad-hoc “character-by-character string equality tester”. For C++, if testing with Google’s gtest library, the result is the same - the entire strings are shown, and an external tool needs to be used to get a reasonable indication of what the difference is. Python 2.7’s assertMultiLineEqual gives a good solution to the problem (in Python 3, this becomes the default behavior for standard assertEqual). There are similar comparison methods for other large data types. Output: F ====================================================================== FAIL: testLongStringEquality (__main__.TestLongStrings) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/home/ohad/test/test_equal.py\", line 35, in testLongStringEquality self.assertMultiLineEqual(STRING_A, STRING_B) AssertionError: '\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. [truncated]... != '\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. [truncated]... Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. Suspendisse ut augue placerat, venenatis ante a, aliquam nibh. Sed vitae massa a nibh dignissim porta id rhoncus neque. Etiam commodo dapibus magna sit amet - pellentesque. Aenean venenatis vulputate eros, sit amet sagittis ligula laoreet ? ^ + pellentesque. Aenean venenatls vulputate eros, sit amet sagittis ligula laoreet ? ^ vel. Pellentesque consectetur viverra nunc, vel interdum turpis tempor nec. Quisque vel purus in quam facilisis gravida posuere in mi. Aenean ligula sem, mattis ut feugiat sit amet, lobortis ut sapien. Vestibulum laoreet aliquam lorem pulvinar lobortis. Mauris quis orci lorem. Mauris ut ante id nulla ultrices gravida vel et orci. Suspendisse potenti. ---------------------------------------------------------------------- Ran 1 test in 0.003s FAILED (failures=1) For J","date":"2013-12-02","objectID":"/posts/asserting-string-equality/:0:0","tags":["software","testing"],"title":"Asserting string equality","uri":"/posts/asserting-string-equality/"},{"categories":null,"content":" A conversation with a friend reminded me that, in fact, I’ve been doing test-driven development long before I knew it was called that. Back in Introduction to Systems Programming (a second-semester course revolving around abstract data types in C, introduction to C++, and hands-on experience building multi-module C programs), most homework exercises looked something along these lines: Write a program managing a store inventory, with a command-line client conforming to a given set of specifications. For an input file looking like this: addcategory Fruit addproduct Fruit Banana 2.30 addproduct Fruit Tomato 1.20 addproduct Fruit Apple 1.50 addproduct Fruit Apple 1.60 list Fruit The output file would be expected to look like this: OK OK OK OK ERROR Duplicate fruit Apple Fruit ----- Apple 1.50 Banana 2.30 Tomato 1.20 Of course, error messages, sorting and spacing for the output would be part of the spec. That provided an effective way of checking your program’s correctness: Run it on a given input, and compare its output - using diff - to expected output. Some TAs even provided simple test files (input + expected output) for this exact method (but not revealing the “real” test files which would they use while grading), but the “serious” tests happened in the student-run “homework help” forum (ah, phpbb…), where students would regularly place gargantuan test files to compare your program against (these were very helpful in finding memory handling errors). For an advanced technique, I wrote a “reference” implementation in Python (this is much shorter than the C version, and probably less bug-prone). I then generated random input files, fed them into both programs, and whenever the output would differ between the two - I’d found in a bug (in one of the versions). I recall a certain student festival, a friend ran up to me, and exclaimed: “I’m totally wasted. I’ve had no sleep for the past two days, but I’ve finally finished the exercise. diff [outputs] 0 [lines of difference]! Whoo!” He ran off at this point. What does all of this have to do with test-driven development? It became “known” that it’s better to start the exercises later, so that early-bird students will have test data up on the forum before you start. Then, just code until the tests pass. Ah, the excuses we students come up with for procrastination… I’ve been striving to do test-driven development ever since, with the help of proper unit testing frameworks, and it’s hard for me to think of having ever coded without it. There are plenty of resources online explaining why unit-testing is such a helpful idea… all I’m saying is that you might already be testing your code, not realizing that a nice framework can help. But more on that later… ","date":"2013-12-01","objectID":"/posts/test-driven-procrastination/:0:0","tags":["software","testing"],"title":"Test-driven procrastination","uri":"/posts/test-driven-procrastination/"},{"categories":null,"content":" Working with vendor code in C can get very tricky, especially when you except breaking changes to occur. Especially when you have multiple binaries depending on that vendor code, updating at different times, necessitating different live versions. Let’s explore. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:0:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Introduction Assume you’re working with an external vendor, who is providing you with code for a wonderful function getFoo: // foo.h version 1.2.3 int getFoo(); // foo.c version 1.2.3 int getFoo() { sleep(1000); // TODO improve performance return 42 } You use this function in many of your products - for example, in your best-selling barApp application: // barApp.c #include \u003cstdio.h\u003e int main() { printf(\"%d\\n\", getFoo()); return 0; } So barApp, and other applications, would want to use a foo library. It makes sense to provide this function in a shared library (libfoo.so). However, this library will change in the future, in several ways: Binary-compatible changes Performance improvements (sleep will be removed) Additional functionality will become available (new functions) Binary-incompatibile changes - at the very least, recompilation will be necessary For C, this is usually caused by changes to macros For C++, a plethora of reasons: Virtual function reimplementation, function inlining, new private data members… Source-incompatible changes - these will require you to change your source code (in barApp): Functions (which you use) being removed or renamed Semantic changes - getFoo could return 43 This gets even more complicated due to the fact that barApp is an operational, mission-critical application for your organization. Developers may need to hotfix older versions of barApp, which use older versions of libfoo. The build servers and developer boxes will need to be able to have multiple versions of libfoo installed simultaneously. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:1:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Compiling, installing, and using a shared library properly First, the upstream vendor should compile libfoo.so with an SONAME, like so: gcc -shared -Wl,-soname,libfoo.so.1 -o libfoo.so.1.2.3 foo.c objdump -x libfoo.so.1.2.3 | grep SONAME # SONAME libfoo.so.1 The guarantee the upstream vendor should give is this: As long as SONAME doesn’t change, binary compatibility will be retained. Now, you (or, preferably, your package manager) should install the package on your machine like so: mkdir -p /usr/include/foo1 cp foo.h /usr/include/foo1 cp libfoo.so.1.2.3 /usr/lib ldconfig -v | grep libfoo # libfoo.so.1 -\u003e libfoo.so.1.2.3 Now, traditionally another symlink libfoo.so -\u003e libfoo.so.1.2.3 would be created, so you could compile barApp with -lfoo. However, here’s an alternative: gcc -I/usr/include/foo1 -l:libfoo.so.1 barApp.c -o barApp ldd barApp # linux-vdso.so.1 =\u003e (0x00007fff8edfe000) # libfoo.so.1 =\u003e /usr/lib/libfoo.so.1 (0x00007fb367cce000) # libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007fb367906000) # /lib64/ld-linux-x86-64.so.2 (0x00007fb367ef2000) Now barApp is compiled, and looks for libfoo.so.1 - it will find it thanks to the symlink created by ldconfig, and use libfoo.so.1.2.3. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:2:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Aftermath ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:3:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Binary-compatible updates Suppose a new, compatible, faster version of libfoo is released - say version \\1.3.0, which has removed that pesky sleep. Well, just place it in /usr/lib and rerun ldconfig. cp libfoo.so.1.3.0 /usr/lib ldconfig -v | grep libfoo # -\u003e libfoo.so.1 -\u003e libfoo.so.1.3.0 The symlink has been updated, and now all applications (barApp, for example) which were linked against libfoo.so.1 will have improved performance. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:3:1","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Incompatible updates Suppose a new, incompatible version 2.0.0 of libfoo is released, which would force the newer barApp2.0 to be recompiled against the new, different headers. No problem: mkdir -p /usr/include/foo2 cp foo.h /usr/include/foo2 cp libfoo.so.2.0.0 /usr/lib ldconfig -v | grep libfoo # -\u003e libfoo.so.2 -\u003e libfoo.so.2.0.0 # -\u003e libfoo.so.1 -\u003e libfoo.so.1.3.0 gcc -I/usr/include/foo2 -l:libfoo.so.2 barApp2.0.c -o barApp2.0 Both versions of libfoo are installed simultaneously, and do not conflict. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:3:2","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Final thoughts The Debian policy guide states that -dev packages should include the libfoo.so symlink. However, this would cause a conflict between the -dev packages for two different generations of libfoo. I am curious as to how this problem is solved “in the wild”, as I’m sure Debian have good reasons for suggesting this. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:4:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Vacations are a great time for doing that problematic category of things every management course teaches you about: important, but not urgent. For some people, it’s housework or schoolwork which gets drowned out by day-to-day life. For others it’s keeping up with friends and family. Myself, I also like to read and write. Writing, for me, is usually about practical stuff. Sometimes it’s simply code (most of those projects were written on vacations). Other times, it’s writing to this blog (in one of its incarnations) - which usually has to do with technical tinkering of some sort or other. It’s not that I don’t do enough writing in my day job; but there does tend to be an accumulation of things to write: “I should blog about that”, “I should write that code”, “I should try and get my router to do that”, and so forth. When a few days off come by, and I feel that I have enough time to get more urgent stuff done - it’s quite satisfying to be able to dig into that write-queue. Reading is the same, but the other way around. I’m not talking about standard RSS feeds (Google Reader R.I.P.), which I usually only have time to skim through. I mean something pertaining to that: Once in a while, I come across an article (be it from an RSS feed, a social network, or a news site), which is too long to read immediately, but I’d really like to get into later on, when I have time. Usually it’s text, but sometimes it’s a long form video (usually from a technical conferences such as the recent C++ and Beyond or Google I/O). Either way, these past few days I’ve had the opportunity to take a nice bite out of my reading queue, with some entries being over a year old. To manage this queue I use Pocket (integrates well with Chrome, Android, Feedly and others), and I highly recommend it. If you have some time off, enjoy it. Read something. Write something as well. ","date":"2013-03-27","objectID":"/posts/reading-writing-and-vacation/:0:0","tags":["life"],"title":"Reading, writing and vacations","uri":"/posts/reading-writing-and-vacation/"},{"categories":null,"content":"As part of my M.Sc. studies, I’ve recently completed a small laboratory project in natural language processing. I’ve learned quite a bit from it, and had a chance to use a few of my favorite technologies. The project was coded in Python, which is not my favorite programming language - Ruby is. However, since Python is more popular at my workplace, and seems to have a richer ecosystem around it (sometimes, at any rate), I’ve grown to love it almost as much over the years. It’s quick, easy, and has fantastic libraries; specifically, for this project, we made heavy use of the Natural Language Toolkit. We used Git for source control and Github for hosting, Travis for continuous integration, and ReadTheDocs for documentation. All of these culminate in the project being handed in as a single link: http://github.com/lutzky/translationese. The translationese project is a re-implementation of the concepts presented in “On The Features Of Translationese”, an article describing an attempt to automatically distinguish between texts written in English originally, and texts translated to English from a different language. Since this turned to be an easy problem, the focus was to determine what specific features of a given text are better at distinguishing between the two categories. Why reproduce results from an existing article? Well, beyond academic points, we wanted to provide well-documented, easily-extensible, tested code. The article was not always clear on specific definitions of various features; Python code makes these completely explicit, in a relatively readable way (for code, at any rate). To keep code quality high, we used test-driven development: each feature was coded only after a (failing) unit test for it was written. This helped keep the code modular, and made refactoring (which happened quite a bit) easy and safe. The resulting design proved to be quite flexible, as I will shortly explain. SVM is a form of machine learning. Simply put, it’s a method of teaching a machine to distinguish between two categories of “points” (in our case, “translated” and “original”). The SVM is given two such sets, and tries to draw a “line” (or, generally, a hyperplane) separating them. Afterwards, it should be able to classify new points (without being told which set they belong to) by which side of the line they are. The following image (Wikipedia) shows a simple, two-dimensional case (the red line properly distinguishing the two sets): {: style=“max-width:350px”} For our case, each “property” took a block of text, and translated it to an n-dimensional point. For some properties, the dimension was quite extreme. For example, the property of character trigrams gives each coordinate the value of “how many times does each permutation of three consecutive letters appear in the text”. There are 17,576 such permutations, so each text became a point in a 17,576-dimensional space. These points were fed into an SVM algorithm implemented in Weka. During the final presentation of the project, we explained that the particularly high-dimensionality properties proved to be too much for Weka (it would use up all available RAM), so smaller sample sizes were used for those. However, we were told that using sparse vector representation as Weka’s input could allow it to be more efficient. Fortunately, our design proved to be robust enough that I could implement (and test) the change during the presentation (1278645). Indeed, we now had no problems with the high-dimensionality properties, and repeated our runs, updating the documentation (after we were given our grade…) There’s a somewhat eerie aspect to this project. Having used SVM, I have no idea how it works. While I know exactly how my Python code works, and exactly what the SVM algorithm does, I still don’t know how to tell a translated text from one written in English originally. Even looking at the SVM output, which details exactly what the resulting classifier does, the data is the result of analyzin","date":"2013-03-24","objectID":"/posts/translationese/:0:0","tags":["natural language processing","software","python"],"title":"Translationese","uri":"/posts/translationese/"},{"categories":null,"content":"Here is an assortment of Linux-related tips and tricks. If you’re tired of hitting your SSH password over and over again, you might want to take a look at this guide: SSH Public Key Authentication. If you’re a Technion student taking the Matam course, you should definitely check out the Matam Guide. Here is a list of lectures I’ve given in Haifux: Lightning Talks 2005 (w/Many others) LIRC - Infrared Remote Control (w/Alon Altman) WiFi in Linux The VIM Editor for beginners (Rerun of Shlomi’s lecture) FatNS - How to develop a DNS forensics tool (w/Boaz Goldstein) Linux for CS Students - a Primer Linux for CS Students - Debugging If you’re with a russian keyboard and need a stress sign, try /russian-stress. ","date":"2013-03-23","objectID":"/linux-stuff/:0:0","tags":null,"title":"Linux stuff","uri":"/linux-stuff/"},{"categories":null,"content":"If you find yourself logging into SSH servers a lot, you might find this tip useful - you’ll only need to type your password once per session. But first, let’s set the default username (so you don’t have to tell SSH what user you are every time): $ cd ~ $ mkdir .ssh $ chmod 700 .ssh $ cat \u003e\u003e .ssh/config Host t2.technion.ac.il User slutzky Ctrl-D $ Now, create a public/private key pair for SSH, like so: $ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/tactless/.ssh/id_rsa): Enter passphrase (empty for no passphrase): use_a_password Enter same passphrase again: use_a_password Your identification has been saved in /home/tactless/.ssh/id_rsa. Your public key has been saved in /home/tactless/.ssh/id_rsa.pub. The key fingerprint is: 5a:3a:e3:f4:6e:91:fe:3f:27:4e:f4:46:0d:5e:50:4f tactless@dolphin Now you have a public and private key: ~/.ssh/id_rsa is the private key (don’t give this to anyone!), and ~/.ssh/id_rsa.pub is the public key - give this to everyone. Specifically, put it on the SSH server you want to log into, making sure the permissions are correct. There’s a script which does this: ssh-copy-id t2.technion.ac.il It basically does the following for you: $ scp ~/.ssh/id_rsa.pub t2.technion.ac.il: password: $ ssh t2.technion.ac.il \u003e mkdir .ssh \u003e cat id_rsa.pub \u003e\u003e .ssh/authorized_keys \u003e chmod 700 .ssh .ssh/authorized_keys \u003e chmod 755 . \u003e logout Now, when you log in to your local account, before using SSH for the first time, type the following command: $ ssh-add Enter passphrase for /home/tactless/.ssh/id_rsa: your-password-here $ ssh t2.technion.ac.il \u003e # notice, didn't type a password \u003e logout $ ssh t2.technion.ac.il \u003e # no password this time either ","date":"2013-03-23","objectID":"/linux-stuff/ssh-public-key-authentication/:0:0","tags":null,"title":"SSH public key authentication","uri":"/linux-stuff/ssh-public-key-authentication/"},{"categories":null,"content":"I’ve already mentioned my show downloading stack on this blog. It’s changed a bit since - I now use Transmission rather than rtorrent, as it has the excellent transmission-daemon package which has it acting exactly the way I like (without using screen). Also, it now E-mails me when a torrent is done downloading. So while this may be how TV works for you: Notice that a new episode is out Torrent it Wait for the download to finish Watch it …this is how TV works for me now: Receive E-mail notification of a new downloaded episode Watch it Here’s how it’s done: First, write /usr/local/bin/notify_torrent_done: #!/bin/bash cat_the_message() { cat \u003c\u003cEOF Subject: Torrent done: $TR_TORRENT_NAME Hello from transmission $TR_APP_VERSION at $(hostname). The following torrent has completed: Name: $TR_TORRENT_NAME Finished at: $TR_TIME_LOCALTIME Downloaded to: $TR_TORRENT_DIR Hash: $TR_TORRENT_HASH Enjoy! EOF } RETVAL=1 while [[ $RETVAL != 0 ]]; do cat_the_message | msmtp -C /etc/msmtprc.transmission --from default -t your@email.address RETVAL=$? done The various environment variables will be set by transmission when it calls this script. We rerun msmtp until it succeeds because you will often get a “connection timed out” response from gmail (…at least on my ISP…). Here’s /etc/msmtprc.transmission which is relevant to gmail (this is a bit tricky and took a lot of fiddling around with): defaults tls on tls_starttls on tls_trust_file /etc/ssl/certs/ca-certificates.crt timeout 60 account default host smtp.gmail.com port 587 auth on user yourusername@gmail.com password yourpasswordhere from yourusername@gmail.com syslog LOG_MAIL As usual, caution is required when saving your password in plaintext. I highly recommend using Google’s two-step authentication, which will have you creating a one-time password for each application - use one of those one-time passwords here. Finally, in /etc/transmission-daemon/settings.json, add the following code: \"script-torrent-done-enabled\": true, \"script-torrent-done-filename\": \"/usr/local/bin/notify_torrent_done\", Important: You need to run /etc/init.d/transmission-daemon reload at this point, not restart - that would cause settings.json to be rewritten from runtime configuration. That’s it. Enjoy! ","date":"2011-12-15","objectID":"/posts/the-show-downloading-stack-part-n1/:0:0","tags":["show downloading"],"title":"The show downloading stack - part n+1","uri":"/posts/the-show-downloading-stack-part-n1/"},{"categories":null,"content":"Here are a few words on developing TransportDroidIL, a small utility to query Israeli public transportation sites more easily using an Android phone. Source control is super important. Mistakes will be made, other coders will want to join in, and experimental features will want to be in their own branches. Git is awesome; it does source control right, gives me powerful tools, and isn’t a hassle to set up - even for a small project like this. Github is also awesome; it makes collaboration with other coders - even just one, in my case - easy, organized, and fun. One of my favorite git features is revert. It allows you to automatically inverse a previous change. Here’s an example from TransportDroidIL: 0e194de. This commit reverts a previous “cleanup” commit in the autocompletion code - allegedly, I was keeping two copies of the autocompletion option list for no reason: One as a LinkedList\u003cstring\u003e, and one internal to the AutoCompleteTextView which I can access via an ArrayAdapter\u003cstring\u003e. Turns out that my LinkedList\u003cstring\u003e copy is necessary, because the ArrayAdapter\u003cstring\u003e always behaves as though it’s empty, so it cannot truly be read from. Despite having performed a few commits since that bad “fix”, git was very helpful in letting me revert that particular change, showing me the conflicts this operation causes, and allowing me to fix them. The lesson is an important one: Make small, manageable commits. Git is optimized for this, as commits are local (no need to contact the server until a push). Developing for Android makes a lot of sense when using Eclipse. I’m a VIM junkie, and generally dislike IDEs. Eclipse is slow and heavy - but it gets the job done, and it does it very well. It’s a bit weird that a plugin is required to manage color schemes - but it exists. It’s very weird (and quite annoying) that it doesn’t remove end-of-line white-space, and doesn’t have an option to do this. This makes git complain. There is an option to add “clean-up” settings which are activated on every save, but this is far too cumbersome and might change code I didn’t intend to change (which becomes confusing in the revision log). Still, the excellent debugging, JUnit and logcat support are worth it. Logcat is another awesome feature of Android. Every logged line has both a “Tag” (usually defined per-class) and a severity. Logs can be filtered with a different severity for each tag, and still - one can use the same logcat to show messages from anything running on the Android device at the moment. It’s basically Syslog done better. One last point is about Hebrew. This has been a problem with Android for quite a while; for example, in a stock Android 2.3.3, numbers embedded in Hebrew string appear backwards. Fixes exist, and are implemented in most Israeli ROMs, especially the ones distributed by phone carriers - but they’re different, and sometimes don’t work for all applications. This causes numbers to appear backwards in TransportDroidIL, which in turn caused me to implement an ugly hack. I hope the upcoming Ice Cream Sandwich release fixes this. ","date":"2011-10-08","objectID":"/posts/developing-transportdroidil-for-android/:0:0","tags":["android","TransportDroidIL"],"title":"Developing TransportDroidIL for Android","uri":"/posts/developing-transportdroidil-for-android/"},{"categories":null,"content":"I don’t like wireless connections; they’re always second-best, be it in terms of security, speed, or reliability. Here’s how my apartment looks (very approximately): .-P1----. .-------------------P4-,---------, | PC | | COMFY SOFA . | | | | . Closed | | .-, | | Living room . Porch | | |B| P2 | . | | |E| | . | | |D| | HUGE CUPBOARD TV . R PC | `-------' `-P3-------------------'--P5-----' My room The room on the left is mine, with my (constantly torrenting) PC in bed-viewing position. The router (R) is in the closed porch, connected to my roommate’s PC. Wifi doesn’t stand a chance through two walls and the porch’s glass screen. P1 through P5 are power outlets. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:0:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"First solution Put a reverse DD-WRT router at P2 (with a cable going across the room from the PC). Slow connection, not very reliable. This worked well enough for several months. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:1:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"Second solution Get a pair of homeplugs. Stick one at P1 (connected through a power strip shared by the PC, speakers, screen and guitar amp). Stick another at P5 (connected through a power strip shared by the other PC, router, modem, TV, fan, printer, speakers and a lamp). It shouldn’t work - but it does. It blinks red, is nowhere near the promised 200Mbps, but it’s still faster (and more reliable) than my internet connection. These homeplug devices are fantastic - they require literally no configuration (unless you want to reconfigure the encryption keys) and work very well, I highly recommend them. The problem was when I got an Xtreamer - a cute device to watch my shows on my living room TV (see: comfy sofa). Once I plug it in, the homeplug connection dies on me, proverbially the last straw. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:2:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"Third solution Thankfully, I have my Big Box of Electronic Junk, which contained a Super Long (read: haven’t measured it) network cable. Moved the homeplug to P3, hid the cable behind the Huge Cupboard. Problem solved. On a side note, I would have preferred a Boxee Box, but sadly it doesn’t support lame old RCA connections. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:3:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":" Hello everyone, TransportDroidIL 1.0 will be released this month. It has quite a few new features: Separate “Source”, “Destination” and “Time” fields. This is much better for auto-completion as well. Automatic location-based detection of “Source”. Hopefully you’ll find the interface for this unobtrusive. Quick reversal of “Source” and “Destination”, for your return trip. A new settings screen, with: Provider selection (currently Egged or MOT) A small attempt at right-to-left fixes for non-supporting devices. A “clear history” button Everyone loves screenshots: Separate source and destination fields Select data provider Automatic location detection, Egged provider For a sneak peek, go to http://github.com/lutzky/TransportDroidIL for the latest sources. You can also report issues there. ","date":"2011-09-02","objectID":"/posts/upcoming-features-in-transportdroidil/:0:0","tags":["TransportDroidIL","android"],"title":"Upcoming features in TransportDroidIL","uri":"/posts/upcoming-features-in-transportdroidil/"},{"categories":null,"content":"Don’t get me wrong. I love being able to communicate textually with friends, coworkers and family. It’s ideal for a noisy pub; a somewhat-private conversation on a crowded bus; telling something to someone who may be asleep, so they see it first thing when they wake up; making quick responses while in a meeting without being rude (well, at least at my workplace it’s considered perfectly acceptable). It’s also very handy when you want to tell someone something they ought to write down, such as a phone number or something they should remember to buy. My problem isn’t with the concept of mobile textual messaging - it’s with SMS, the “Short Message Service”, as provided by Israeli carriers (and possibly worldwide). The first problem I’d like to discuss is length. SMS messages are limited to 160 characters, or rather - 160 bytes. If your message includes any foreign characters, such as Hebrew letters, then UTF-16 mode takes effect, and your message is limited to 70 characters, which is ridiculously short. While the name of the service, SMS, implies that the messages should indeed be short, this is not the only common usage: If you want to have an actual conversation with someone (and this is a perfectly reasonable situation), messages will be longer than 160 characters, and certainly longer than 70. The problem becomes worse if u dont want to use shorthands n skip punctuations like many smsers do. (Ever found yourself about to send a 75-character message, going over it to find 5 characters to trim without looking like an idiot?) There have been several attempts to overcome the short-message problem, all of them implemented as workarounds in cellphone software. The initial, primitive approach was to simply split a message up into appropriately-sized chunks, and send out those chunks as separate messages: A 150-character Hebrew message would be sent out as 3 separate messages (70, 70, 10 characters respectively). Later on, a mechanism was invented for the phones to detect the split messages, stitch them back up on the recipient’s phone, and notify the recipient if the message is incomplete. Poor man’s TCP. The split-message solution is very problematic, especially when taking into account two other problems with SMS: Reliability and price. The reliability problem is subtle: SMS message usually make it across, but when they don’t (and sometimes, in fact, they don’t), no notification is given. Where E-mail servers notify you about delivery failure, where instant messaging services tell you that the other party has disconnected, SMS has… nothing. There’s no way to know that your message hasn’t been received, unless a little-known, not-supported-everywhere and highly annoying “read receipt” feature is enabled. The price problem is completely absurd: I have a small 1GB plan at Orange, which costs 70₪/month. That’s 70 NIS / 1GB, 1GB being 109 bytes. That comes to 7 \u0026times 10-6 Agorot per byte. Suppose that an SMS-style service would need a bloated 100-byte header, so an SMS message is 260 bytes. Therefore, an SMS message should cost 0.00182 Agorot. In reality, it costs 44 Agorot (inter-carrier average) without a plan, or 14 Agorot (at best, requiring a 1000-SMS plan) with a plan. That’s between 7692× and 24176× as much. One additional problem with SMS is the fact that they’re locked into your device. Got a new phone? You have to go through a very complicated process to transfer your SMS messages over, and this isn’t possible for every phone. Lost your old phone? Unless you were backing up manually, your messages are gone. Have a separate work-phone? You’ll need to use each phone to see messages sent specifically to it. None of these problems occur with an online E-mail provider, why should they happen with mobile texting? With modern phones, sending and receiving E-mail is just as easy as sending and receiving SMS messages. The main problem is that not everyone has a modern phone, and E-mail on older phones is quite cumbersome. Worse yet, ","date":"2011-04-25","objectID":"/posts/sms-and-why-it-annoys-me/:0:0","tags":["phones"],"title":"SMS and why it annoys me","uri":"/posts/sms-and-why-it-annoys-me/"},{"categories":null,"content":"Since I’ve last posted, I’ve moved to a new apartment. First order of business - get a working internet connection. This is extra-challenging when your primary machine doesn’t even have a wireless network card. My first hack used my trusty laptop - it has a properly working wireless card, and could connect to my roommate’s router quite easily. It runs Ubuntu, and as it turns out, that means sharing the connection was dead-simple: Right-click on the network manager icon, add a new wired connection called “Shared”, and under IPv4 settings, choose “Shared to other computers”. That’s it. Once I connected my desktop to my laptop, it automatically got all of its settings, and I was good to go. However, this was kind of annoying - I had to leave my laptop on, the reception in my room isn’t perfect so it would sometimes disconnect (requiring manual intervention), and my laptop wasn’t free for ordinary use (if I wanted my torrents to keep going). The solution: I grabbed my (horrible) old D-Link DIR-300 router, and installed DD-WRT on it. This gave it an awesome “client mode” feature, which allowed it to use it the same way I used my laptop to bridge my wireless connection. Flashing it worked quite well by following the guide (the updated version in the wiki, that is - it has proper instructions for connecting to RedBoot, the D-Link flashing interface, from Linux), and another guide helped me set up Client mode. All seems well, except for two issues: First, port forwarding doesn’t seem to work properly - it works well on the internal network (that is, I can SSH into my desktop using my laptop), but not on the internet (SSH port shows up as open, but I can’t connect). I’m also guessing that UPnP/NAT-PMP won’t work properly. Second, and this is an old problem - the router has a high-pitched whine. This may have something to do with the fact that the AC/DC adapter it came with is rated for 12V @ 1A, whereas the router is rated 5V @ 1.2A. Let’s hope it doesn’t fry (hasn’t for the 3 years I used it). ","date":"2010-11-20","objectID":"/posts/dd-wrt-awesomeness/:0:0","tags":["networking","hardware"],"title":"DD-WRT awesomeness","uri":"/posts/dd-wrt-awesomeness/"},{"categories":null,"content":"After a couple of days’ messing with it, I’m releasing it: Transport Droid IL! It’s a handy little app for querying Egged’s site, as well as the new Ministry of Transportation site, on transportation information. This is pretty beta, but seems to work well enough. More info, source code: http://lutzky.github.com/TransportDroidIL APK File: TransportDroidIL.APK ","date":"2010-09-04","objectID":"/posts/transport-droid-il/:0:0","tags":["TransportDroidIL","android"],"title":"Transport Droid IL","uri":"/posts/transport-droid-il/"},{"categories":null,"content":"There are several good guides for installing Gilad Ben-Yossef’s excellent Hebdroid fonts on physical Android devices, but those don’t really work with the Android SDK’s emulator - changes to the system directory aren’t persistent. Here’s how to get around that: First, a few downloads. You’ll need: The android emulator (presumably you already have this, if not, you can get it at developer.android.com) The hebdroid fonts unyaffs, which will extract the system.img file A snapshot of yaffs2, which will create our new system.img file. This is actually today’s snapshot from the git repository, which worked for me. For later versions, take a look at the git repository. Building unyaffs is simple enough, or you can use the prebuilt version from the site. Building mkyaffs2image is also quite easy - just untar the snapshot, and run make in the utils directory. Put both of these utilities somewhere in your $PATH for convenience. Now we can get to work. First, locate your system.img file. It should be within your Android SDK directory, under platforms/android-3/images (or whatever version you’re emulating). We’ll extract that - create a temporary directory, say /tmp/system.img.hebdroid, and cd to it. Then run: unyaffs /path/to/system.img The whole /system filesystem should be extracted. Now extract the ttf files from hebdroid.zip into the fonts directory, replacing the original font files. To pack everything back up, run: mkyaffs2image /tmp/system.img.hebdroid system.img.hebdroid Now, I recommend putting renaming your original system.img to system.img.orig, and using symlinking system.img.hebdroid as your new system.img (the emulator does indeed follow symlinks), but you can basically do whatever you like. You may have to recreate your AVD, but everything should work. Happy hacking! ","date":"2010-09-04","objectID":"/posts/setting-up-hebrew-android-fonts-on-your-avd-emulator/:0:0","tags":["android"],"title":"Setting up Hebrew Android fonts on your AVD emulator","uri":"/posts/setting-up-hebrew-android-fonts-on-your-avd-emulator/"},{"categories":null,"content":"I’ve finally gotten the chance to get one of those newfangled Android phones. I’ve recently “bought” a Samsung Galaxy Android phone (the older i7500, not the newer i9000 “S”) model. It’s a seriously serious upgrade from my old Nokia 6120 Classic, and as I broke the 6120’s screen and reverted back to my trusty old Nokia 6070 (which I couldn’t even get to run the GMail app), I was quite a happy camper switching to a modern phone. The whole idea of Android has always been very appealing to me - Nokia’s software has been declining in quality, and while Motorola and Samsung have always made excellent hardware, they could never get the knack of good software. Google has. Problem solved, right? The Android software is miles ahead of anything I’ve ever seen, including iPhone. I now have connectivity everywhere, and apps to sync all of my favorite things - GMail and Google Calendar are included, GTasks is great for tasks, Paperdroid is great for Read It Later, NewsRob is great for Google Reader. The Facebook and Twidroyd applications are also quite nice, and the convenience has me using those networks more. I even have nifty stuff like Transdroid, a Transmission web client which is actually very good at adding torrents while I’m away, so they’re done by the time I get home. I get my reading done with Aldiko and ACV (for comics). Even Israeli sites have some good applications up, such as YNet and Dapei Zahav have a nice Android app, though not as nice as their iPhone ones. And of course, there’s the wonderful Waze, which is the most Israeli solution to the road congestion problem I’ve ever seen. I’ve even had the chance to do some on-foot navigation with Google Maps, which is also handy. The phone itself has a beautiful AMOLED screen, great audio quality (comes with quite a good set of headphones as well), and looks sleek. The touchscreen is responsive enough (though not anywhere near new Android devices nor the iPhone/iPod touch), and it even comes with a free extra 8GB SD card, for a total of 16GB. And now, to rant. Battery life isn’t what is should be - the phone is awesome, I want to use it, and it can barely get through the day - especially if I’m doing heavy stuff like Waze (GPS + Data + screen is always on + voice), but even if I’m just surfing casually. The unlock button is located inconveniently on the bottom part of the right side, just above the camera button. The home button is located between the Back and Send buttons, meaning it’s very easy to hit by accident; it’s not even labeled. The CPU isn’t always fast enough to keep everything completely smooth, and while this is generally acceptable, it gets rather irksome in odd places: If you turn on screen auto-rotation (which uses more battery power), rotation takes a while and might be accidental. However, there is no manual screen rotation option as far as I can tell. As a music player (relating to my previous post), the device works well enough - but I couldn’t, for the life of me, get Hebrew support in ID3 tags (no matter what the encoding is), and only a limited subset of ID3 tag versions is supported, and everything works much better with Ogg files. The flaws I’ve mentioned are relatively minor and nitpicky - for Waze, you can use the car charger (which comes with the phone, thankfully). The buttons are OK after some getting used to (and installing the excellent AnySoftKeyboard), and operation is generally smooth. However, there is a major issue I can’t wrap my head around - the shipped firmware is 1.5 cupcake, and there are absolutely zero updates available from Samsung. There is a semi-official leaked 1.6 update which, as I’ve heard, is quite buggy. An awesome guy called drakaz has been working on a Froyo (2.2) port for the Galaxy, which I really should check out, but Samsung’s behavior on this topic is inexcusable in my opinion. All-in-all, however, I’m happy with my phone. It’s a joy to use, and the price is hard to beat - free with my phone plan, provided I can rake ","date":"2010-09-04","objectID":"/posts/android/:0:0","tags":["hardware","android","phones"],"title":"Android","uri":"/posts/android/"},{"categories":null,"content":"My Meizu Mini M6 has died a tragic death as a result of being left in my shirt pocket, which in turn was - with the rest of my shirt - in the laundry. I’ve had it for three years, so this would be a good time to review. My favorite thing about the Mini was the cost. When I bought it, it was far cheaper than comparable players, at ~400₪ for 8GB. For a player with good video support, it was a steal. Other pros it had include: Great screen. I used to watch TV shows on it quite a bit Great audio quality, especially in the lower range - very important for a bass guitarist Perfect OS compatibility - shows up as a Mass Storage device, just drag your files over. This is also how firmware upgrades are performed EBook reader, of sorts Quite small and very thin However, the player is full of quirks: Slow startup time. This is compounded by the fact that to turn it on, you have to press the “Play” button for about 3 seconds - too much less or too much more, and it won’t start up. This is even worse when unplugging it from USB - it would rebuild the library every time, even if you were just charging it. You can’t turn the player on when it’s connected to USB. When it’s off, connecting it to USB is for charging only - to access the filesystem, you have to disconnect it, turn it on, and connect it again. (…not that the player is functional when in it’s plugged in…) A few podcast niceties would be very easy to implement and extremely helpful. There’s no way to separate podcasts from the rest of the music, so you don’t get “This Week In Tech” when you put it on “All Music at random” mode. Also, the player doesn’t keep track of positions within audio streams, other than the last played one. There’s no way to delete a song from within the player. The interface is very inconsistent, with the video and audio sections having completely different key bindings. Long presses and short presses have very different meanings (but the length isn’t all that different), so you have to be very careful. Pressing various key during startup had interesting, non-obvious effects, such as rebuilding the music library or formatting the player without asking for confirmation. This isn’t in the official documentation, and even if it were - that’s a very bad misfeature. The newer version of the player, which I have, did away with the bottom “play” button, and moved it to the bottom of the 4-way D-pad, instead of the “Enter” key. The “Enter” key was replaced with a tap on the d-pad. Unfortunately, such a tap is very similar to a volume change drag, and even if it weren’t - is very easy to perform by accident. One more feature that I would have liked is one I’ve only seen in the iPod (which I despise for a variety of reasons) - the iPod keeps track of which songs you’ve played all the way through, and remembers that you “like” them - this information is later used when building playlists, and is integrated into iTunes playlists as well. Now, I might be going to a long course soon, one which will specifically mean plenty of bus time. So go ahead, guys - recommend a player. :) ","date":"2010-03-13","objectID":"/posts/my-music-player-has-sunk/:0:0","tags":["hardware"],"title":"My music player has sunk","uri":"/posts/my-music-player-has-sunk/"},{"categories":null,"content":"Last weekend I broke my Nokia 6120’s screen. I have a military phone, which is far cheaper, so I’ve decided to keep it offline. However, being the sentimental guy that I am, I did want to save all of my contacts and SMS messages (in addition to the photos, which presented less of a problem). This proved to be a bit of a challenge without the screen working. Usually, when you connect the phone via USB, it asks if you want “PC Suite mode” or “Data Transfer mode”. The “Data Transfer” mode has the phone show up as a standard USB storage device, which allows for easy transfer of MP3 files, photos and videos to and from the phone, without any nokia-specific software. However, it only works for the external SD card, so you can’t use that to access SMS messages or contacts. I usually only need “Data Transfer” mode, so I changed the default to that. Today I regret that decision, as it cost me a couple of hours’ work. I called the Orange hotline, and they did their best to help me, including trying to blind-guide me through the menus, which failed because the menus are actually dynamic and I didn’t have the default setup. They actually got me 90% of the way there - here’s the solution I found: Hit the red (disconnect) button, and type the Soft Reset GSM code: *#7780#. Now press the “left menu” key (not the left key, nor the menu key - the left of the two “dynamic” keys) - this part was what the Orange hotline missed, because it seemed so obvious. Then hit 12345 (this is the default “secret code”), and the left menu key again. I found this by watching a demo of the soft reset on YouTube. At this point I used VirtualBox and the Nokia PC suite (both are free-as-in-beer) to do the heavy lifting. I now have a text file with all of my contacts, a CSV file with all of my SMS messages, and all of my images saved both to my computer and a DR site. Now I just need to upgrade my military phone (Mirs)… ","date":"2009-10-31","objectID":"/posts/broken-phone-screen-data-rescue/:0:0","tags":["hardware","phones"],"title":"Broken phone screen - data rescue","uri":"/posts/broken-phone-screen-data-rescue/"},{"categories":null,"content":"Totem is Gnome’s built-in media player, and it really annoyed me in previous versions, and had me switching to VLC. However, the version included in the Ubuntu 9.10 release candidate has two features which are very important, in my opinion. The first feature is smooth graphical integration with compositing managers (such as compiz). In previous versions, as well as VLC, once you fullscreen the window, moving the mouse (which causes the cursor and the partial interface to appear) causes a very annoying flicker. This has been fixed (at least on my box, using an NVidia card). The second, more important feature, is the exact one I’ve been missing and talked about in the previous post - hit Edit -\u003e Preferences -\u003e Start playing files from last position, and Totem will keep track of your last playback position when you close the video. Reading the implementation patch shows that there is a certain threshold for this - the position won’t be saved if you’re too close to the beginning or end of the video. So there, my show downloading stack now has every feature I’d want from Miro, without the downsides I’ve mentioned. ","date":"2009-10-10","objectID":"/posts/loving-the-new-totem/:0:0","tags":["show downloading"],"title":"Loving the new Totem","uri":"/posts/loving-the-new-totem/"},{"categories":null,"content":"I love watching TV, and hate it. Regular show schedules are horrible, commercial breaks are annoying, and the ability to rewind is very important. I love Hot’s VOD service (and happily pay to watch the shows I enjoy), but my true favorite for getting my entertainment is everyone’s favorite not-a-dumptruck, the internet. In this post, I will describe how I do it. Everything I describe in this post can be done using miro. It’s a neat piece of software, which lacked polish in version 2.4 (2.5 is out now though), but there are a few things I don’t like about it: You have to be graphically logged in for it to run. Among other things, this means that if someone reboots your computer, there’s no way to get it to start automatically. (I’ll be very happy to know if I’m wrong about this) It doesn’t give you as much control as I’d like over torrents. Its BitTorrent client doesn’t perform as well as rtorrent. However, Miro does one thing which I haven’t figured out how to do myself yet: It keeps track of your position within watched shows. That is, stop watching a show -and next time playback will resume from the same place. The first thing you want to do is get a good RSS feed for your show. Unfortunately, Revision3’s shows (many of which are quite good), are direct HTTP download links, as per the advertiser’s request. For other shows, you can find torrent RSS feeds, which make much better use of everyone’s bandwidth. Also, downloading will be handled by our trusty rtorrent, which we can configure for bandwidth limiting. To download RSS feeds, I use flexget. It does its job well, but doesn’t support bandwidth limiting. It accepts a simple YAML configuration file, and has good logging. I run it as a cron job - its locking mechanism prevents multiple instances from running simultaneously. For non-torrents, I set the output directory to ~/torrents/inbox. For torrents, I set the output directory to ~/torrents/from_rss. For downloading torrents, I use rtorrent. It’s a curses-based client which performs very well. My .rtorrent.rc file looks like this: download_rate = 30 upload_rate = 2 directory = /home/ohad/torrents/in_progress on_finished = move_complete,\"execute=mv,-u,$d.get_base_path=,~/torrents/inbox/ ;d.set_directory=~/torrents/inbox/\" session = /home/ohad/torrents/.session schedule = watch_directory,5,5,load_start=/home/ohad/torrents/from_rss/*.torrent schedule = untied_directory,5,5,remove_untied= schedule = throttle_1,23:00:00,24:00:00,download_rate=0 schedule = throttle_2,05:00:00,24:00:00,download_rate=30 port_range = 6881-6889 encryption = allow_incoming,enable_retry,prefer_plaintext dht = auto peer_exchange = yes scgi_local = /tmp/rtorrent-scgi.socket Interesting things to note here are: Downloads live in one directory, but get moved to the inbox directory when they’re done. The session directory is important - this allows rtorrent to resume downloads if it’s shut down. The from_rss directory is watched for new torrent files. When the relevant downloads are stopped, remove_untied occurs and the torrent files are deleted. Throttling is fully customizable. The SCGI socket is useful for rtgui - we’ll get to that. I have a “watchdog”-style cron job which makes sure it’s running if the computer is up. This is not as elegant as starting it from an RC-script, but keeps the whole setup confined to the limits of my own user. Again, rtorrent has a lock-file which prevents multiple instances from running. #!/bin/bash # A simple script to make sure I am running rtorrent in a screen set -e SCGI_SOCKET=/tmp/rtorrent-scgi.socket SESSION_DIR=~/torrents/.session screen -d -m -fn -S rtorrent -s /bin/bash -t rtorrent -m nice rtorrent while [[ ! -S $SCGI_SOCKET ]]; do sleep 1; done if [[ -S $SCGI_SOCKET ]]; then chgrp www-data $SCGI_SOCKET chmod g+rwx $SCGI_SOCKET fi RTGUI provides a nice web-based interface. It’s a bit tricky to configure, and you’ll need to use an HTTP server - preferably lighttpd, as it has support for SCGI UNIX sockets (as oppose","date":"2009-09-05","objectID":"/posts/my-show-downloading-stack/:0:0","tags":["show downloading"],"title":"My show downloading stack","uri":"/posts/my-show-downloading-stack/"},{"categories":null,"content":"I’ve been trying to work out a system to be able to cleanly switch between IST (Israel Standard Time, GMT+2:00) and IDT (Israel Daylight savings Time, GMT+3:00) on command. The logical way to do this, in my opinion, is to have two separate files in /usr/share/zoneinfo, say IsraelIST and IsraelIDT, and copy (or link) the relevant one as /etc/localtime. The trick is creating the IsraelIDT file. My first guess was the following zic source-file: # Zone NAME GMTOFF RULES/SAVE FORMAT [UNTIL] Zone IsraelIDT 2:00 01:00 IDT Now, this almost works. The problem is that both is_dst is set and timezone = -10800 (3 hours - should be 2, as it should represent local standard time), so some software double-compensates here for a grand total of GMT+4:00. After some research (walking through __tzfile_read gave the biggest hint), it turns out that timezone is set according to the minimal local time type which is transitioned into. So I came up with this file: # Rule NAME FROM TO TYPE IN ON AT SAVE LETTER/S Rule ZionIDT min 1939 - Jan 1 00:00 1:00 D Rule ZionIDT 1939 only - Jan 1 00:00 0:00 S Rule ZionIDT 1940 max - Jan 1 00:00 1:00 D # Zone NAME GMTOFF RULES/SAVE FORMAT [UNTIL] Zone IsraelIDT 2:00 ZionIDT I%sT Sounds about right, nay? Even my handy little pyzdump confirms that it looks about how I want it to: $ ./pyzdump.py /usr/share/zoneinfo/IsraelIDT Transitions: ['At Sat Dec 31 23:00:00 1938, switch to IST', 'At Sun Dec 31 22:00:00 1939, switch to IDT'] Types: [\u003ctztype dst=\"True\" idt:=\"\" utc+10800=\"\"\u003e, \u003ctztype dst=\"False\" ist:=\"\" utc+7200=\"\"\u003e] However, it still doesn’t work. A test program: int main() { tzset(); time_t t = time(NULL); printf(\"Timezone name is %s, timezone=%ld\\n\", __tzname[1], timezone); printf(\"The time is %s\", ctime(\u0026t)); printf(\"Timezone name is %s, timezone=%ld\\n\", __tzname[1], timezone); return 0; } And its results, as run at 14:42:17 UTC, which is 19:42:17 IDT: Timezone name is IDT, timezone=-7200 The time is Sat Apr 18 14:42:17 2009 Timezone name is UTC, timezone=0 Or, as I described it to a friend: Me: Hi computer, do you know what timezone are we in? Computer: Yeah, it’s Israel Daylight Savings time, GMT+2:00 for standard time. Me: OK, and what time is it? Computer: 14:42 Me: No, that’s 3 hours late. What timezone are we in? Computer: Umm… UTC? Me: You just said IDT. Computer: Nuh-uh. I’ll get to the bottom of this eventually :/ Addendum: It seems that the problem is even more complicated. For the following timezone file, C programs seem to work fine: # Rule NAME FROM TO TYPE IN ON AT SAVE LETTER/S Rule ZionIDT min 1939 - Jan 1 00:00 1:00 D Rule ZionIDT 1939 only - Jan 1 00:00 0:00 S Rule ZionIDT 1940 2030 - Jan 1 00:00 1:00 D Rule ZionIDT 2030 max - Jan 1 00:00 0:00 S # Zone NAME GMTOFF RULES/SAVE FORMAT [UNTIL] Zone IsraelIDT 2:00 ZionIDT I%sT However, Python programs still show timezone = -10800. Examining Python’s code, I found this: if( janzone \u003c julyzone ) { /* DST is reversed in the southern hemisphere */ PyModule_AddIntConstant(m, \"timezone\", julyzone); PyModule_AddIntConstant(m, \"altzone\", janzone); PyModule_AddIntConstant(m, \"daylight\", janzone != julyzone); PyModule_AddObject(m, \"tzname\", Py_BuildValue(\"(zz)\", julyname, janname)); } else { PyModule_AddIntConstant(m, \"timezone\", janzone); PyModule_AddIntConstant(m, \"altzone\", julyzone); PyModule_AddIntConstant(m, \"daylight\", janzone != julyzone); PyModule_AddObject(m, \"tzname\", Py_BuildValue(\"(zz)\", janname, julyname)); } And since June and July have the same timezone in our case, there’s a good chance that this is what’s going wrong. The moral of the story seems to be this - I should go with the first, simplest “always-DST” solution. Programs should ignore the timezone variable, as in our context it isn’t reliable. In general, all internal time handling should be done in UTC; when reading times from the outside world, if they are in local time - use mktime. If they are in a specified timezone, use timegm and compensate manually. I’d love to hear better idea","date":"2009-04-18","objectID":"/posts/timezones-are-fickle/:0:0","tags":["linux"],"title":"Timezones are fickle","uri":"/posts/timezones-are-fickle/"},{"categories":null,"content":"At my workplace, I’ve recently been using git for code review purposes. I work on code in my own git clone, and ask a peer to review it. It works somewhat like this: master branch is same code as currently in upstream. Working to resolve issue #1234 pertaining to “Performance for gizmo”, I work on a branch 1234-gizmo-performance. I mail a peer, John, with this information, as well as my repository location. John adds my repository as a remote, lutzky. Then he branches review1 (or review2 if that is taken, and so on) at lutzky/1234-gizmo-performance. John adds comments with nice big FIXME tags, which are highlighted in any decent editor. He commits this, the commit-message stating that it was code review. John tags his final review commit (or, if he had no comments - lutzky/1234-gizmo-performance) with a reviewed1 (or reviewed2, etc.) annotated tag. Since the annotated tag includes all the necessary information (who tagged, when, and what), the number doesn’t really matter. I merge john/review1, incorporate the changes (or reject them) and remove the comments. If no further review is necessary, I submit this - and once submitted, I merge this back into master. It’s a nice system. I wonder what other methods there are of doing this. ","date":"2009-04-04","objectID":"/posts/using-git-for-code-review/:0:0","tags":["git"],"title":"Using git for code review","uri":"/posts/using-git-for-code-review/"},{"categories":null,"content":"I’m a software kind of guy. Here’s proof. Today I went to visit my grandparents, and it turned out their computer wouldn’t boot. BIOS would load up fine, and I could browse the menus fine - but once it tried to go on from there, it would simply blink what looked like half a cursor (that is, half of a _-style cursor). I figured it might be the HDD - so I took it home, and decided to connect it to my own box. Upon disconnecting my DVD drive, I destroyed the SATA cord - it had an annoying little metal tab which had to be pushed in before it would release, and it just wouldn’t give, and the connector just broke, exposing and bending the wires. Checking if the computer still boots, the BIOS took much longer to display hard drive status, and while Ubuntu would start booting, it would fail in the process and tell me that my root hard drive (by UUID) isn’t available. Looking at dmesg, the ata2 module was indeed reporting that the hard drive was too slow - but a few seconds later it would finally access the drive, and mount properly. This problem, however, disappeared once I connected my grandparents' drive! (Mounting it would fail, telling me that I either have a hardware error or need to connect it to a Windows machine, which I don’t have, and run some diagnostic commands). Sure enough, when the HDD is connected by itself, it gets quite flaky, but once I connect a second drive (back to the DVD, eventually), everything works properly. This probably has to do with the fact that both drives are connected on continuations of the same power cord - but I’ve never experienced such a problem, where you must connect devices to both connectors on the power cord. A hardware guy I know says he’s never heard of such a problem either. Naturally, these things never happen when I mess with hardware at work, where there are plenty of spare parts… ","date":"2009-02-26","objectID":"/posts/hardware-doesnt-like-me/:0:0","tags":["hardware"],"title":"Hardware doesn't like me","uri":"/posts/hardware-doesnt-like-me/"},{"categories":null,"content":"I had a Game Boy once. I could play it just about anywhere, and battery life - for the time - was great. I lost it at one point, and replaced it with a Game Gear, which sucked the life out of 6 AA batteries rather quickly. The Game Boy Color was actually decent on battery life, but since it didn’t have a backlight, you had to play it at very specific angles. For gaming, I can appreciate the need for a color screen. My point has to do with cellphones. True, most cellphones today come with cameras, are able to play video, and are rather capable mobile gaming platforms (when compared to the Game Boy, that is). All this does, in fact, require a color screen. However, I believe that there is a market for cellphones which do not support these features, but do support neat things like 3G internet connectivity (GMail and RSS on the phone is a major Win, in my opinion), and have a comfortable SMS interface. These features actually suffer from having a color screen: Battery life (for the powerful backlight), viewing angle, and screen resolution take a hit. While it’s true that color LCDs have come a long way since the Game Gear, so have black \u0026 white display technologies (E-Paper, anyone?). Of course, my wish for a modern B\u0026W-screen cellphone will likely never come true. The simple reason is that they would be totally unmarketable. Even business-types like color screens nowadays. So I’ll just keep holding out for a folding E-Paper mobile browser. ","date":"2008-11-22","objectID":"/posts/whatever-happened-to-black-white-lcds/:0:0","tags":["hardware","phones"],"title":"Whatever happened to black \u0026amp; white LCDs?","uri":"/posts/whatever-happened-to-black-white-lcds/"},{"categories":null,"content":"Ever have a machine you can only ssh into through another machine? It’s a very common situation in the Technion. Here’s one way to get around it: Assume you can directly ssh into alpha, and from alpha you can ssh into beta. Have the following code in your ~/.ssh/config: Host beta Hostname 1.2.3.4 # IP Address of beta ProxyCommand ssh alpha nc -w 1 %h %p This requires you to have nc (netcat) installed on alpha. Once you do that, you can run ssh beta directly from your own box. ","date":"2008-11-10","objectID":"/posts/another-ssh-trick/:0:0","tags":["networking"],"title":"Another SSH trick","uri":"/posts/another-ssh-trick/"},{"categories":null,"content":"These days I don’t stay at home often, but I do have an RSS/BitTorrent combo fetching me all kinds of neat stuff for me, so I can have it ready for me on the weekend. I love rtorrent, especially due to the fact that I can run it in screen, ssh home and see how things are doing (or add more torrent to the download). However, sometimes my net connection breaks down, computers gets shut off, or things like that. This week my router broke down, so I can’t even ssh home to manually start up rtorrent. My solution: A small script, which checks whether rtorrent is already running, and if not - runs it in a detached screen session. Run this with your favorite cron software. #!/bin/bash # A simple script to make sure I am running rtorrent in a screen if ! ps -o uname -C rtorrent | grep -q `whoami`; then screen -d -m rtorrent fi ","date":"2008-11-04","objectID":"/posts/automatically-starting-rtorrent-within-screen/:0:0","tags":["linux"],"title":"Automatically starting rtorrent within screen","uri":"/posts/automatically-starting-rtorrent-within-screen/"},{"categories":null,"content":"Gnome 2.24 adds a new Time Tracking feature, which I would have found useful. I don’t have Gnome 2.24 at work, but I do have a Unix-based operating system… Here’s my new ~/bin/track: #!/bin/bash date \u003e\u003e ~/time_tracking vim ~/time_tracking + Now, if I could only get vim to automatically hit “A” and space for me afterwards… (I’m betting there’s a way to do it, but AFAIK vim can only receive ex-mode commands as parameters). Edit: …and, of course it’s possible. Here’s the new version: #!/bin/bash echo \"`date` \" \u003e\u003e ~/time_tracking vim ~/time_tracking + -c 'startinsert!' ","date":"2008-10-26","objectID":"/posts/quick-time-tracking-hack/:0:0","tags":["linux"],"title":"Quick time tracking hack","uri":"/posts/quick-time-tracking-hack/"},{"categories":null,"content":"Sometimes, when constructing a compound object, we are interested in exporting functionality while retaining encapsulation. For example, suppose we have a Secretary class: class Secretary def send_fax(destination, fax_contents) puts 'Sending fax \"%s\" to %s' % [fax_contents, destination] end def answer_call(call) # ... end # ... end Our Secretary provides a lot of useful functionality, that our Boss class would like to have. Boss would like to be able to say that he can send a fax, without having the user explicitly request his Secretary beforehand. The same goes for a lot of other methods Secretary provides. Instead of writing a stub function for each of these methods, it would be nice to do the following: class Boss delegate_method :my_secretary, :send_fax, :answer_call def initialize @my_secretary = Secretary.new end end john = Boss.new john.send_fax(\"Donald Trump\", \"YOU'RE fired\") Here’s how we can get this to happen: class Class def delegate_method(instance_var_name, *method_names) method_names.each do |method_name| define_method(method_name) do |*args| instance_var = instance_variable_get(\"@%s\" % instance_var_name) instance_var.send(method_name, *args) end end end end This solution does have its drawbacks - it will not work for methods which are meant to accept blocks. I’m not sure how to get that to happen, short of using a string-based class_eval, which I’m not very fond of. (I find eval to be, well, evil…) ","date":"2008-10-18","objectID":"/posts/delegating-methods-in-ruby/:0:0","tags":["ruby"],"title":"Delegating methods in Ruby","uri":"/posts/delegating-methods-in-ruby/"},{"categories":null,"content":" Ditz was lost in the mists of time, and I guess if ttime were maintained, issues would be tracked using Github. I’ve added issue tracking for ttime using the fantastic ditz. I’ve also added ttime’s rdoc documentation. (Note: Version 0.8.5 is out) ","date":"2008-07-30","objectID":"/posts/tracking-ttime/:0:0","tags":["ttime"],"title":"Tracking TTime","uri":"/posts/tracking-ttime/"},{"categories":null,"content":"Edit: I was misled! Illustrated here. Hints below. \u003e\u003e def inspect_x_and_y(x,y); puts \"x: %p, y: %p\" % [x, y]; end =\u003e nil \u003e\u003e inspect_x_and_y(y={\"hello\" =\u003e \"world\"},x=[1,2,3]) x: {\"hello\"=\u003e\"world\"}, y: [1, 2, 3] The bits I didn’t know about: \"Format strings using a %% sign, %s, %s!\" % [ \"just like in python\", \"but with arrays\" ] The %p formatting character is the same as inspect. You can call methods with method_name(param2=val2, param1=val1), also like in python. No you can’t! This code sets external variables called y and x. How embarassing… :( ","date":"2008-07-25","objectID":"/posts/three-things-i-didnt-know-ruby-does/:0:0","tags":["software","ruby"],"title":"Three things I didn't know Ruby does","uri":"/posts/three-things-i-didnt-know-ruby-does/"},{"categories":null,"content":"This site gets indexed by the almighty google. This link is part of a security project I’m doing for my CS degree. The was part of project BadSense. See the BadSense report ","date":"2008-07-23","objectID":"/posts/security-project/:0:0","tags":["security"],"title":"Security project","uri":"/posts/security-project/"},{"categories":null,"content":"I was having a lot of trouble with gettext in Ruby, mostly due to lacking documentation. Here are some useful things I figured out while writing TTime. I ended up having a single gettext_settings.rb, included from every file which uses gettext. Here it is (with some extra notes) #!/usr/bin/ruby begin require 'gettext' require 'pathname' include GetText # This fixes a swarm of problems on Windows GetText.locale.charset = \"UTF-8\" # Ruby's gettext acts in a sane # method - add a path to the set of paths # scanned. locale_in_data_path = Pathname.new($0).dirname + \\ \"../data/locale/%{locale}/LC_MESSAGES/%{name}.mo\" add_default_locale_path(locale_in_data_path.to_s) bound_text_domain = bindtextdomain(\"ttime\") # For Glade, however, it only seems to # be possible to specify one path at a # time. Fortunately, gettext already # found it for us. my_current_mo = bound_text_domain.entries[0].current_mo if my_current_mo ENV[\"GETTEXT_PATH\"] = my_current_mo.filename.gsub( /locale\\/[^\\/]+\\/LC_MESSAGES.*/, \"locale/\") end rescue LoadError def _ s #:nodoc: # No gettext? No problem. s end end One note for context: I use setup.rb (and ruby-pkg-tools) to package TTime. So my localizations go in data/locale. ","date":"2008-07-20","objectID":"/posts/gettext-oddities-with-ruby/:0:0","tags":["ruby"],"title":"Gettext oddities with Ruby","uri":"/posts/gettext-oddities-with-ruby/"},{"categories":null,"content":"I has it. Sorta. A few weeks ago, the lovely NaNuchKa visited Israel for two and a half shows (the half-show was warming for Berry Sacharof). “Three shows in two weeks?”, people ask - well, yeah. They only come once a year. Their set is already too long to play all the songs I like, and that’s actually quite excellent - new EP and all. Great stuff :) Deep Purple should be coming to Israel this summer (holy crap!), and I need to see what I can do about getting tickets for that. This is my last semester at the Technion - then it’s off to the military for me. Courses for this semester are Electronic Switching Circuits (bleh…), Signals and Systems (which is actually turning out to be quite awesome!), and the neat Compilation Theory. After having thoroughly enjoyed Eli Biham’s excellent Modern Cryptology last semester, I’m visiting (but not taking) his advanced topics course this semester. I also have two projects: One in computer security, where we mess with Google, and another in EE, where we try using transactional memory in order to optimize Apache. And finally - next week on Thursday, Shlomi Shaban is doing a piano show in Haifa, just like the good old days. He was supposed to join NaNuchKa for one of their shows, but had to cancel, so my lovely lady (who introduced me to his work in the first place) and I haven’t been to his shows in quite a while. It seems that will be able to use the new 200 line - part of a long overdue project to have cheap public transportation available all night long. ","date":"2008-07-11","objectID":"/posts/that-life-category-there/:0:0","tags":["life","technion","music"],"title":"That \"Life\" category there","uri":"/posts/that-life-category-there/"},{"categories":null,"content":"I’ve found myself working on TTime, the Technion Timetable Scheduler, quite a bit lately. Lots of cool stuff went in: Boaz Goldstein’s TCal, a Cairo-based schedule renderer (could you believe the old version used MozEmbed?) Sports courses are now correctly parsed Ability to select specific lectures and groups for the automated scheduler A manual scheduler - given an existing schedule, you can ask to show all alternatives at once, and hand-pick them. Some people (Tom, for example) prefer this. Just for kicks - interoperability with Grandpa’s XML format I’ve also cleaned up the packaging quite a bit - it can now be installed using setup.rb, or the updated Debian package. I think it may soon be time to tag a release :) Sources at Github ","date":"2008-07-11","objectID":"/posts/been-working-on-ttime/:0:0","tags":["ttime"],"title":"Been working on TTime","uri":"/posts/been-working-on-ttime/"},{"categories":null,"content":"Today at the CS department of the Technion is a particularily Bad Network Day (TM) for laptop users; none of the wired connections at the farm work, and wireless doesn’t seem to working for HTTP at all. It does, however, work for SSH. Ka-ching! :) Tunneling your browser over SSH is a pretty simple affair - SSH into somewhere which has a decent connection, and use the -D9999 flag (9999 works, but it can be any 16-bit number over 1024). Then, configure your browser to work over a SOCKS proxy at 127.0.0.1:9999. How do you, however, get other things to work over that tunnel? There’s an excellent program called dante-client (that’s an apt package, folks. if you can’t apt-get due to your network situation, get it at packages.ubuntu.com or packages.debian.org). Install it, and make sure /etc/dante.conf has the following lines: route { from: 0.0.0.0/0 to: 0.0.0.0/0 via: 127.0.0.1 port = 9999 protocol: tcp proxyprotocol: socks_v4 socks_v5 } Then, run socksify whatever-you-want-to-do. For example, sudo socksify apt-get install something. Or perhaps socksify ssh somewhere. Or sudo wget something. Or socksify git do-something-awesome. (All of the above work for me) ","date":"2008-06-17","objectID":"/posts/tunelling-even-more-stuff-over-ssh/:0:0","tags":["networking"],"title":"Tunelling even more stuff over SSH","uri":"/posts/tunelling-even-more-stuff-over-ssh/"},{"categories":null,"content":"I neglected to post this here somehow, it’s about a month old by now… Screenshot lost in the mist of time… shows a program segfaulting, and then working properly when run within valgrind. The problem turned out to be an imprecise (false-positve) comparison operator implemented for a class used as a hash key. God, I hate C++. ","date":"2008-06-11","objectID":"/posts/valgrind-fail/:0:0","tags":["software"],"title":"Valgrind Fail","uri":"/posts/valgrind-fail/"},{"categories":null,"content":"So, I see I forgot to post my schedule for this semester… …ttime screenshot lost in the mists of time… As you can see, it’s TTime! With a shiny new Cairo interface. We’re back to the Ruby version, too - as we have another coder on board, which is using his compilation skills in order to write a new REPY parser. You can also see it’s only found one schedule. This is thanks to the group selection constraint which was finally coded. Yes, that’s a link to the Github repository for TTime. You’re welcome to help write some constraints :) ","date":"2008-06-02","objectID":"/posts/scheduling/:0:0","tags":["ttime"],"title":"Scheduling","uri":"/posts/scheduling/"},{"categories":null,"content":" You can use git on a VFAT disk (for example, a USB key) without all of the annoying mode issues, by using the following setting in .git/config: [core] filemode = false What I haven’t figured out is how to do force a chmod in this situation; for example, if I create a new script, I was hoping to be able to git chmod +x it. Cream is a very good editor if you’re used to Windows applications. It’s a set of plugins for VIM which make it modeless and (very) familiar to Windows users. However, Ctrl-O still has its usual job for us ordinary junkies :) Vertically, two cans of Pepsi fit very snugly into a Pringles can. ","date":"2008-04-28","objectID":"/posts/things-i-learned-today/:0:0","tags":["linux","git","asides"],"title":"Things I learned today","uri":"/posts/things-i-learned-today/"},{"categories":null,"content":"Deskbar has a really neat plugin which allows you to search your browsing history and bookmarks. Firefox 3 has switched the storage format to an sqlite-based one. I’ve been working on a new plugin to make use of that - so far it’s very enjoyable to use :) » Deskbar_FF3 ","date":"2008-04-28","objectID":"/posts/deskbar-and-firefox-3/:0:0","tags":["linux"],"title":"Deskbar and Firefox 3","uri":"/posts/deskbar-and-firefox-3/"},{"categories":null,"content":"This one took me a while to figure out, which is reason enough to post it here. First of all, you’ll need aspell-he, as pidgin uses gtkspell (which, in turn, uses aspell) rather than enchant (which supports hspell). There is a patch for gtkspell which gets it to use enchant, but I don’t know of a simple way to get it to work in my distribution of choice, Ubuntu. Now you need a neat little plugin from the Guifications plugin pack, called SwitchSpell. Unfortunately, it’s in version 2.3.0 of the pack, whereas the current Ubuntu version is 2.0.0. It’s not complicated to install this from source though: I’ve detailed the precise installation procedure below; the confusing thing is that if you forget to install libgtkspell-dev or libaspell-dev, SwitchSpell will not be built, but the configure script tells you that it will. sudo apt-get install build-essential gettext libgtkspell-dev libaspell-dev pidgin-dev wget http://downloads.guifications.org/plugins//Plugin%20Pack/purple-plugin_pack-2.3.0.tar.bz2 tar jxvf purple-plugin_pack-2.3.0.tar.bz2 cd purple-plugin_pack-2.3.0 ./configure --with-plugins=switchspell make sudo make install At this point, the Switch Spell plugin should show up in your Pidgin preferences. When you activate it, you should get a menu at the top of each conversation for choosing the dictionary in use. Enjoy! ","date":"2008-04-22","objectID":"/posts/hebrew-spell-checking-in-pidgin/:0:0","tags":["linux"],"title":"Hebrew spell-checking in Pidgin","uri":"/posts/hebrew-spell-checking-in-pidgin/"},{"categories":null,"content":"Due to an exercise in an AI course, I’m forced to confront an old nemesis - C++. Part of the reason is that the exercise contains a time-limited tournament, and the code needs to run very quickly. Another reason is, I guess, the fact that C++ serves as a sort of lowest common denominator in the course (which used, by the way, to be taught in LISP, along with the language). I never liked C++ language much. As a matter of fact, I prefer C. I’ve been going over some old code for a project, which needed to use DBus to talk to NetworkManager. Back then I wrote it using Python, embedded in C - it seemed easier at the time, due to lack of documentation. After hunting around, I figured out how to do most of the stuff I wanted in C, using DBus’s GLib API. In this process, the most helpful bit of documentation turned out to be GLib’s. GLib looks like a wonderful library to get big-program stuff done relatively nicely in C, without mucking about in C++. Exception handling (of sorts), object-oriented programming (of sorts) as well as garbage collection (of sorts) are implemented in a usable way, and extremely well-documented. At the end of the day, I was able to turn this Python gem: import dbus def _nm_device_interface(dev_object): \"\"\"Returns an interface to the device object dev_object\"\"\" return dbus.Interface(dev_object, NM_DEVICE_IFACE) def _nm_get_object(object_path): \"\"\"Returns an object with the given object path using the NM service\"\"\" return dbus.SystemBus().get_object(NM_SERVICE, object_path) def _nm(): return _nm_get_object(NM_OBJECT_PATH) def _nm_dbus_exception(e, guessed_exception): \"\"\"Checks if the DBus exception e is (exactly) of type guessed_exception\"\"\" try: return e.get_dbus_name().endswith(guessed_exception) except: # If it doesn't have a get_dbus_name, it probably isn't the DBus # exception we're looking for. return False def _nm_all_device_interfaces(): \"\"\"Return a list of interfaces to all devices NM sees\"\"\" try: return [ _nm_device_interface(_nm_get_object(devicename)) for devicename in _nm().getDevices() ] except dbus.DBusException, e: if _nm_dbus_exception(e, \"NoDevices\"): return [] # No devices means list of devices is empty else: raise …into this C gem: #define DBUS_SERVICE_NM \"org.freedesktop.NetworkManager\" #define DBUS_PATH_NM \"/org/freedesktop/NetworkManager\" #define DBUS_INTERFACE_NM \"org.freedesktop.NetworkManager\" #define NM_ERR_NODEVICES \"org.freedesktop.NetworkManager.NoDevices\" gboolean is_remote_dbus_exception(GError *error, char * exception_name) { g_assert(error); if (error-\u003edomain != DBUS_GERROR || error-\u003ecode != DBUS_GERROR_REMOTE_EXCEPTION) return FALSE; if (!exception_name) return TRUE; return strcmp(dbus_g_error_get_name(error), exception_name) == 0; } GPtrArray * get_nm_devices(DBusGConnection *connection, GError **err) { GError *tmp_error = NULL; DBusGProxy *proxy; GPtrArray *ptr_array; g_return_val_if_fail(connection != NULL, NULL); proxy = dbus_g_proxy_new_for_name( connection, DBUS_SERVICE_NM, DBUS_PATH_NM, DBUS_INTERFACE_NM); dbus_g_proxy_call(proxy, \"getDevices\", \u0026tmp_error, G_TYPE_INVALID, dbus_g_type_get_collection(\"GPtrArray\", DBUS_TYPE_G_PROXY), \u0026ptr_array, G_TYPE_INVALID); if (tmp_error != NULL) { if (is_remote_dbus_exception(tmp_error, NM_ERR_NODEVICES)) { g_error_free(tmp_error); return NULL; } else { g_propagate_error(err, tmp_error); return NULL; } } g_object_unref(proxy); return ptr_array; } The C code runs much faster, and I suspect is more maintainable then its original counterpart (which uses embedded python in C). ","date":"2008-04-16","objectID":"/posts/faster-languages/:0:0","tags":["software","c","python"],"title":"Faster Languages","uri":"/posts/faster-languages/"},{"categories":null,"content":"YNet was running a story on how to use your computer as an alarm clock. Here’s what I do, for our commandline junkies :) Here’s ~/bin/run_alarm.sh: #!/bin/bash find ~/music/ -name '*.mp3' -print0 | xargs -0 mplayer -shuffle \u0026 MAXVOL=31 TIME=900 for (( i = 0; i \u003c= $MAXVOL; i++ )); do amixer set Master $i \u003e /dev/null; sleep `echo $TIME / $MAXVOL | bc -l` done This basically plays all of my MP3 files, in random order. The -print0 and -0 arguments make it a null-terminated list, as some (most) files have spaces in their names. This process is backgrounded, and the script proceeds to gradually sweep the volume from 0 to the maximum, for a more gentle wakeup :) This script is basically intended for use with at. I made a little wrapper around it for my comfort: #!/bin/bash if [ -z \"$1\" ]; then echo \"Usage: $0 [time]\"; exit 1; fi echo /home/ohad/bin/run_alarm.sh | at $1 ","date":"2008-02-12","objectID":"/posts/my-alarm-clock/:0:0","tags":["linux"],"title":"My alarm clock","uri":"/posts/my-alarm-clock/"},{"categories":null,"content":"I’ve switched to a Nokia 6120 Classic, and I’ve switched my carrier over to Orange. I’m very happy with it: The price is right, at 0 NIS a month (if your monthly bill adds up to over 100 NIS without it, which it does). It’s very small, but has a nice screen and a respectable 2 megapixel camera. It’s “3.5G”, which means it has a very fast internet connection (I’ve clocked over 50kbyte/sec), and the Symbian S60 operating system lets me use it well - it comes with a very, very nice webkit-based browser and RSS reader, and a fast GMail client is a few clicks away. Another nice feature is the built-in MP3 player - which is actually made relevant due to the micro-SD support and included 1GB SD card. The device has a standard USB connection (cable included, but it’s an ordinary Mini-to-A cable), and has a Mass Storage Device mode, so it works well with any OS. It can also automatically text-to-speech the name of the caller (or dial by voice recognition, which works remarkably well), which is handy when listening to MP3s. I’ve only had two problems with it so far - first, when viewing a long web page (on wikipedia, specifically), it gave an “out of RAM” message and rebooted. I’m curious as to whether there’s a simpler, non-CSS version of Wikipedia, or a way to get the phone to ignore the CSS - this will probably save on RAM. Another problem I had was that the vibration feature didn’t work until I rebooted it - but this no longer seems to occur. I wonder how well puTTy would work on this… ","date":"2008-02-11","objectID":"/posts/nokia-6120-classic/:0:0","tags":["hardware"],"title":"Nokia 6120 Classic","uri":"/posts/nokia-6120-classic/"},{"categories":null,"content":" The Egged Getter has been lost in the mists of time. However, it’s code has largely been integrated into TransportDroidIL. An old version of the Python code has been pasted at the end of this post. Here’s a little something I’ve been messing with: A simple fetcher script for the Egged (Israeli bus company) site. I’ve made a deskbar applet which uses it, which was fun to do :) (I’m looking for other cool ideas to implement as deskbar applets) You can get it at http://lutzky.net/files/egged_getter. The readme file includes installation instructions (…which involve placing the two included scripts in ~/.gnome2/deskbar-plugin/modules-2.20-compatible/. There’s also a git repository here: http://git.lutzky.net/?p=ohad/egged_getter.git. I don’t think I’ve mentioned git on the blog before… It’s freaking awesome. It made me really despise subversion :). Besides the abundance of information on the main site, there’s an excellent (and very amusing) talk by Linus about it. Also, I’m giving a talk about it in Haifux - this coming Monday (February 4th), the Taub building of the Technion, room 6, at 18:30. #!/usr/bin/python # coding: utf-8 import socket try: from pyfribidi import log2vis except ImportError: def log2vis(s): return s # Original values which worked: # User agent (a sane browser agent): # USERAGENT=\"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9b2) Gecko/2007121016 Firefox/3.0b2\" # Session ID: Can be retrieved from the site, but seems to have a very long # keepalive, and isn't checked anyway. # SESSION_ID=\"thjbzmnrhrks3a55w1dymvnx\" BUF_LEN=2048 HOST='mslworld.egged.co.il' PORT=80 DOUBLE_NEWLINE=\"\\r\\n\\r\\n\" USER_AGENT=\"EggedGetter\" SESSION_ID=\"0\" JSON_DATA=\"\"\"{\"str1\":\"%(query)s\",\"strSession\":\"%(session_id)s\"}\"\"\" _payload=\"\"\"POST /eggedtimetable/WebForms/wsUnicell.asmx/getAnswer HTTP/1.1 Host: mslworld.egged.co.il User-Agent: %(user_agent)s Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-us,en;q=0.5 Accept-Charset: utf-8 Keep-Alive: 300 Connection: keep-alive Content-Type: application/json; charset=utf-8 Referer: http://mslworld.egged.co.il/eggedtimetable/WebForms/wfrmMain.aspx?width=1280\u0026state=3\u0026taavura=0\u0026language=he\u0026freelang= Content-Length: %(content_length)d Cookie: ASP.NET_SessionId=%(session_id)s Pragma: no-cache Cache-Control: no-cache %(json_data)s\"\"\".replace(\"\\n\",\"\\r\\n\") def build_json_data(query, session_id = SESSION_ID): \"\"\"Build a JSON-formatted query for the egged site.\"\"\" return JSON_DATA % { 'query':query.replace('\"','\\\\\"').encode(\"utf-8\"), 'session_id':session_id, } def build_request(query, session_id = SESSION_ID): \"\"\"Build an HTTP request for the egged site.\"\"\" json_data = build_json_data(query, session_id) return _payload % { 'user_agent':USER_AGENT, 'content_length':len(json_data), 'session_id':session_id, 'json_data':json_data, } def send_query(query, session_id = SESSION_ID): \"\"\"Prepare and send query to site. Returned data is raw.\"\"\" http_data = build_request(query) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((HOST,PORT)) s.send(http_data) data = s.recv(BUF_LEN) s.close() return data def clean_response_html(response,linebreak=\"\\n\",item=\"\\n * \"): if response[0] == response[-1] == '\"': response = response[1:-1] BR = \"\\u003cbr\\u003e\" LI = \"\\u003cli\\u003e\" NBSP = \"\u0026nbsp\" return response.replace(BR,linebreak) \\ .replace(LI,item) \\ .replace(NBSP,\" \") \\ .replace(\"\\\\\",\"\") def query_site(query): \"\"\"Query the egged site with query\"\"\" site_response = send_query(query) returned_data = site_response.split(DOUBLE_NEWLINE)[1] try: cleaned_data = clean_response_html(returned_data) except: print \"Error occured when trying to clean up the following response:\" print \"site_response:\" print site_response print \"returned_data:\" print returned_data raise return unicode(cleaned_data, \"utf-8\") if __name__ == '__main__': query = unicode(raw_input(\"Enter query for Egged site: \"),\"utf-8\") result = query_site(query) print \"\" try: print log2vis(result) except UnicodeEncodeEr","date":"2008-02-01","objectID":"/posts/egged-getter-0-1/:0:0","tags":["software"],"title":"Egged Getter 0.1","uri":"/posts/egged-getter-0-1/"},{"categories":null,"content":"On an online board, friends posted a photo from a party a while back, as I’m chewing some extra-sour chewing gum: חמוצקי נולד I find this suitable for use in macro form. For example, in the Computer Security course, we’re going to compromise a windows-based server using a buffer overflow vulnerability. Unfortunately, this means we’re going to have to use (as per the course’s demands) Visual Studio 2003. My response (now known as חמוצקי): ","date":"2007-12-19","objectID":"/posts/sour-chewing-gum/:0:0","tags":["asides"],"title":"Sour chewing gum","uri":"/posts/sour-chewing-gum/"},{"categories":null,"content":"New URL - not interesting. You’d notice by now, as you’ve been redirected. Guess my new E-mail. OpenID - interesting, but I don’t have anything particularily interesting to say about it right now. This, however, is interesting: “10 things christians and atheists can (and must) agree on”, a nicely written piece over at cracked.com. But this isn’t blogspam, I’ll actually share my two cents. (or shnekel, if you like) I have a serious problem with religion; It is my opinion that it is an overly powerful means of control. Whether it has evolved as such or not is hard to tell. But today it seems to pose a very serious threat to the world. Now, don’t get me wrong - control of this type is very important and useful. Specifically, it manifests itself in a basic moral system which, many believe, has served mankind well. You know, “thou shalt not murder”, stuff like that. Some may even say that it was a central factor in overcoming our primal urges, and development into the ever-so-slightly more sophisticated society we are today. However, there are other, more dangerous manifestations of this control. Specifically, it seems all-too-easy nowadays to get up and say “This-and-that god has spoken to me - we must kill those-and-them”. “God has spoken to me, we must, uh, enlighten these our-religious-character-rejecting other-religion-followers. There’s some oil in it for us, too”. “This land has been promised to us this-and-that years ago, we must kill all other-religion-dwellers”. Of course, the link here is politics. When used as a series of anecdotes, morals, stories, hell - even as a way of life - religious is mostly harmless. However, when a religious leader becomes a political figure, the temptation is simply too great, and religion becomes used as a tool of the agenda. It doesn’t take a whole staff of advisors and a big media budget to convince the public now - it only takes a proper connection with arbitrary dogma to do that. Throughout the years, the secular public has wished for separation of church and state. But noone has yet stated it better than George Carlin - “Keep thy religion (or, in accordance with the linked post, thy lack thereof) to thyself.” ","date":"2007-12-17","objectID":"/posts/means-of-control/:0:0","tags":["life"],"title":"Means of control","uri":"/posts/means-of-control/"},{"categories":null,"content":"The most recent events in my life which I would consider to be vacations would be the second Lebanon war and my basic training. I love the Technion, but I think it’s high time for some R\u0026R. With no upcoming tests hovering over my head, homework pressure low-to-nonexistent, and my girlfriend’s birthday Murphy’s-law-bendingly coinciding with her getting some leave, this is a perfect opportunity to try my hand at a real vacation. Okay, so it’s just two days, but I could hardly ask for anything better. The location is a Tzimmer recommended by friends and family. My parents have graciously lent me the car for the purpose. Last but not least, I’ve gotten my hands on some massage oil. :-) Studying at the Technion can get rather hectic. But hell, I have just one more year to go, after which I undergo lime-tinted metamorphosis. Perhaps low-key, nearby, short-term vacations are all I can afford. But with good friends, a wonderful girlfriend, and a geeky way of getting excited at seemingly mundane things, I can’t complain. Even with EE atrocities in my recent past and, in all likelihood, my near future, I can’t help but wear an annoying smile on my face. ","date":"2007-11-04","objectID":"/posts/vacation/:0:0","tags":["life"],"title":"Vacation","uri":"/posts/vacation/"},{"categories":null,"content":" All links in this post have been lost to the mists of time. I’ve kept it here out of pure nostalgia. I’m typing the lectures of the course 236343 Computability Theory this semester. Attached are my lectures notes in PDF form: Computability Lecture Notes Computability Tutorial Notes If you also type the notes and would like to collaborate with me, I use a git repository stored here: http://yasmin.technion.ac.il/ohad/git/computability.git To use it, install git-core and curl, and run git clone http://yasmin.technion.ac.il/ohad/git/computability.git Any changes you have - send to me as patches, or push to your own repository and send me a link. (Drawings would be most welcome, and you’re obviously welcome to add your name to the list of typers) If you need git storage, try repo.or.cz, or ask the T2 admins to install git :) ","date":"2007-10-31","objectID":"/posts/computability-typed-lectures-and-tutorials/:0:0","tags":["technion"],"title":"Computability - Typed Lectures and Tutorials","uri":"/posts/computability-typed-lectures-and-tutorials/"},{"categories":null,"content":"Reading some backlog on this blog, I found the following gem: It’s a sad state of affairs that people go ahead and limit access to their wireless network. I keep mine wide open - מי שאוכל לבד, מת לבד. Yeah… not so anymore. For about four weeks (just a bit before the semester started), my net connection was working excrutiatingly slow. Now, we’re four roommates here, so we started blaming each other. But then I had a guess - I encrypted my connection with WPA/TKIP, and presto; the connection is now once again too fast for my browser to handle (…which sent me back to Epiphany). Guys, if you mooch wi-fi, please… be nice about it :( ","date":"2007-10-28","objectID":"/posts/encrypted-my-wi-fi/:0:0","tags":["networking"],"title":"Encrypted my Wi-fi","uri":"/posts/encrypted-my-wi-fi/"},{"categories":null,"content":"Writing multi-threaded applications in Python is often a headache because of the Global Interpreter Lock - only one Python thread can run at any given moment, which makes multi-threading useful only in the case where all modules but one actually run C code. However, thanks to the impressive new Python Magazine, I’ve stumbled across a package called processing, paraphrasing python’s built-in threading package. Essentially, the package provides an API identical to Python’s threading, but uses processes and pipes (or other mechanisms on non-posix operating systems) instead. What the magazine does not cover is the fact that this can also benefit GUI applications; updating a progressbar in the application doesn’t need to slow down heavy computations being done in a separate thread. To show how easy the integration is, take the following example which shows usage of either threads or processes at the user’s choice: import processing import threading import Queue import time import gtk import gobject gtk.gdk.threads_init() USE_PROCESSING = False WORKER_DELAY = 1.0 GUI_DELAY = 0.5 def f(q, sq): print \"Init other thread\" i = 0 while sq.empty(): time.sleep(WORKER_DELAY) q.put(i) print \"Other thread: %d\" % i i += 1 def update_label((l, q, sq)): print \"Updating label\" try: i = q.get_nowait() l.set_text(\"Number in thread: %d\" % i) except Queue.Empty: l.set_text(\"Queue is empty!\") except processing.Queue.Empty: l.set_text(\"Queue is empty!\") return sq.empty() def close(window, sq): sq.put(True) gtk.main_quit() if __name__ == '__main__': if USE_PROCESSING: q = processing.Queue() sq = processing.Queue() p = processing.Process(target = f, args = [q, sq]) else: q = Queue.Queue() sq = Queue.Queue() p = threading.Thread(target = f, args = [q, sq]) p.start() w = gtk.Window() l = gtk.Label() gobject.timeout_add(int(1000*GUI_DELAY), update_label, (l,q,sq)) w.add(l) w.connect('destroy', close, sq) w.show_all() print \"Mainloop!\" gtk.main() ","date":"2007-10-13","objectID":"/posts/on-threading-vs-processing/:0:0","tags":["software","python"],"title":"On Threading vs. Processing","uri":"/posts/on-threading-vs-processing/"},{"categories":null,"content":"My girlfriend just asked me what just might be the hardest question I’ve heard all semester; What do I like better, The Simpsons or beer? ","date":"2007-09-25","objectID":"/posts/tough-question/:0:0","tags":["life"],"title":"Tough Question","uri":"/posts/tough-question/"},{"categories":null,"content":"I’ve been a very big proponent of Subversion so far, especially as a tool for collaborating on coding homework. However, I’ve recently been trying out Linus’s git. It’s very nice so far, and really seems to be catching on. Some good points: Fast as all hell (much faster than Bazaar, although I haven’t given that the proper attention) No need for a central server; hell, no need for an internet connection at all, everything can be done over USB keys or whatnot No real need to configure any special server; just install git on it Very nice alternative to configuring write-control for all of the users Very easy branching and merging, finally! SVN really shows its weakness here One thing I couldn’t find out how to do is limiting read-access to git repositories without special server configuration. It would be nice if git had support for .htpasswd-compatible authentication, those are pretty easy to use. ","date":"2007-09-18","objectID":"/posts/really-liking-this-git-thing/:0:0","tags":["git"],"title":"Really liking this git thing","uri":"/posts/really-liking-this-git-thing/"},{"categories":null,"content":"Lately I’ve been working on a project that has me using DBus a lot. After trying to figure out how to work DBus with C, and seeing how easy it is to do in Python, we figured we’d try to use embedded Python to do this. Fortunately, it’s very simple to use - especially thanks to this guide. It later turned out to be much easier to do in C, as described in Faster Languages. Now, we couldn’t have the Python code throwing exceptions outwards, so we had each function return, along with its actual return value (if any), a numeric code identifying the error. Unfortunately, this made the code get really big, really fast - especially once DBus exceptions are thrown into the mix. But once I learned how to use decorators, I accomplished something like this diff: +@wrap_exceptions((False,)) def checkSomething(): - global error_string - - error_string = \"\" - - try: - return (try_doing_something_over_dbus(), RET_OK) - except dbus.DBusException, e: - error_string = str(e) - if _nm_dbus_exception(e, \"ServiceUnknown\"): - return (False, RET_SERVICE_NOT_RUNNING) - return (False, RET_ERROR) - except Exception, e: - error_string = str(e) - return (False, RET_ERROR) - + return (try_doing_something_over_dbus(), RET_OK) Now, the duplicate DBus/non-DBus exception handling, global error_string, etc. - that happened in a lot of functions. Unfortunately, they didn’t all return their values in the same way. Some just returned a RET_VALUE, but most had other values before it in the tuple (not the ideal design, come to think of it…). Here’s the decorator I wrote: class wrap_exceptions: def __init__(self, prepend_tuple=None): self.prepend_tuple = prepend_tuple def tuplize(self, retval): # Change retval into a default tuple form, if necessary if not self.prepend_tuple: return retval return tuple(list(self.prepend_tuple) + [retval]) def __call__(self, f): def exception_wrapped(*args, **kargs): global error_string error_string = \"\" try: return f(*args, **kargs) except dbus.DBusException, e: # Check known DBus Exceptions first if _nm_dbus_exception(e, \"ServiceUnknown\"): return self.tuplize(RET_SERVICE_NOT_RUNNING) # Unknown exceptions (DBus) error_string = str(e) # Includes get_dbus_name return self.tuplize(RET_ERROR) except Exception, e: # Unknown exceptions (non-DBus) error_string = repr(e) return self.tuplize(RET_ERROR) return exception_wrapped ","date":"2007-09-16","objectID":"/posts/exception-handling-decorators-and-python/:0:0","tags":["software","python"],"title":"Exception handling, decorators, and python","uri":"/posts/exception-handling-decorators-and-python/"},{"categories":null,"content":"First of all, new iPods won’t work on Linux. Now, while it’s very obvious that the idea is to block competition against other music vendors, that makes it even less legitimate. Good thing we’re starting to see some very nice cheap players out there - I’ve been rather impressed with the Meizu M6 MiniPlayer. Secondly, they didn’t think of this: Indexed search within the “Open” dialog. It’s in Ubuntu Gutsy, and really makes desktop search (implemented with Tracker in gutsy) worthwhile. Especially when attaching files in GMail :) ","date":"2007-09-16","objectID":"/posts/two-reasons-apple-suck/:0:0","tags":["software"],"title":"Two reasons Apple suck","uri":"/posts/two-reasons-apple-suck/"},{"categories":null,"content":"Despite having a critical midterm Sunday, as well as being sick, I could not, and should not have, give up on the NaNuchKa show. Some of the best music I’ve ever heard, no doubt, and with the unexpectedly intimate setting, I had the opportunity to get to know the truly incredible Yula after the show. They’re playing in Tel-Aviv today, at the Koltura, where I was supposed to… Fantastic music, at any rate. Keep your ears open! ","date":"2007-07-27","objectID":"/posts/nanuchka/:0:0","tags":["music"],"title":"NaNuchKa","uri":"/posts/nanuchka/"},{"categories":null,"content":"Some things renew your faith in people, in the time you spend with them. Amazingly small things, considering their grand scope. Making things worse is known to be easy, and rebuilding is one of the hardest things we have to do in life. But sometimes, when things turn out to be completely different than they seem - new perspective is gained, old perspective is found again, and like something out of an old Disney cartoon, kitschy clouds of gloom make way for kitschy rays of sunshine. Complete with the smiling sun and everything. Like freakin’ Roger Rabbit :) Finally, the story gets the ending it deserves. ","date":"2007-07-23","objectID":"/posts/some-things-make-you-feel-good/:0:0","tags":["life"],"title":"Some things make you feel good","uri":"/posts/some-things-make-you-feel-good/"},{"categories":null,"content":" Paradox the cow Another action shot with Paradox I present to you, the only creature which is more of a celebrity in the undergrad CS world than I am… The Cow. (Paradox) Edit: Yes, that’s me. No, that’s not my bass. That’s a very good friend’s Fender Fat Stratocaster. So smooooth… Edit: Photo by some chum ;) ","date":"2007-06-07","objectID":"/posts/all-hail-the-cow/:0:0","tags":["asides","technion"],"title":"All hail the cow!","uri":"/posts/all-hail-the-cow/"},{"categories":null,"content":"Recording this morning was excellent! Awesome studio, not expensive at all, and a whole lot of fun. We’ve posted one song at our myspace page, and it seems that Lior has found an apt name for the CD (hint) ;) For those of you who don’t want to visit Myspace (can’t blame you), here’s the song we posted, as well as an extra track (my personal favorite), Falsely Accused. The deal Falsely Accused I really want to point out the incredible recording studio we used - it’s a place called MIXסולידי in Tel Hanania. The man charged us very little, and the equipment and space are excellent. As you can probably tell, those are just demo recordings - recorded “live”, with plenty of mistakes, and with very minimal balance and sound tweaking. We’ll definitely be going back there to record a more serious version. ","date":"2007-06-02","objectID":"/posts/some-music-posted-to-myspace/:0:0","tags":["music"],"title":"Some music posted to myspace","uri":"/posts/some-music-posted-to-myspace/"},{"categories":null,"content":"This Saturday we’re going to record our material, and hopefully a cover we’ve been working on - Venom’s excellent “School Daze”. We took some photos yesterday, visible here: http://www.myspace.com/switchblade777/photos/albums/my-photos/8265381 We have a show at the Koltura Club on July 12th.2 Link modified to accomodate mists of time. ↩︎ Poster lost in the mists of time, show ended up being cancelled at the last moment. ↩︎ ","date":"2007-05-31","objectID":"/posts/some-band-stuff/:0:0","tags":["music"],"title":"Some band stuff","uri":"/posts/some-band-stuff/"},{"categories":null,"content":"Life is good, for the most part. And as a technology enthusiast, there are many new and cool things to see online. For example, there’s the new Schools site, part of the Vaya project which helps Israeli schools use Linux; this site uses the up-and-coming Lahak CMS, built on the Django framework, and looks very promising to the eyes of the bidi-lingual webmaster. However, some things just plain suck. One of them is myspace; today, in an attempt to make it more legible, I found that My Band’s Page implements all of its styling changes by a “style” tag hidden within the “Members” text block. Myspace doesn’t filter this out - nor does it provide any other means of changing the styling. This, combined with myspace’s horrid administration interface, makes editing incredible unwieldy. I’m considering opening another Wordpress site for the band here on this server… And on that topic - Wordpress 2.2 is out. Shinier. Faster. Built-in support for sidebar modules. And K2 broke :(. I love K2… Even though now that sidebars are implemented, the only thing I really need is a very simple template that allows me an ordinary, rectangular logo. Update: I didn’t even notice, but the excellent K2 guys released a fix. However, it seems that when you copy the plugin they created directly, it inadvertantly adds a space to the end of the file - and PHP proceeds to barf. Hard to believe people still use this junk to develop websites… They should use other junk. ","date":"2007-05-17","objectID":"/posts/myspace-sucks/:0:0","tags":["music","software"],"title":"Myspace sucks","uri":"/posts/myspace-sucks/"},{"categories":null,"content":"By now I’ve lost count of how long ago my last class was. The strike has begun immediately after passover, and is certainly beginning to take its toll. For one thing, I have no homework deadlines - a rare situation indeed for the Technion student. Furthermore, contemplations are rising about whether or not this coming summer semester will be held, as the current semester will most likely leak into it. This is of special interest to me, as I’m behind on my degree, which is problematic because of my military scholarship. This is shaping up to be the second time in which, while I’ve been authorized by the military to take a summer semester for completion, I am not able to. However, one cannot trivially dismiss this strike; in a country which is known worldwide mostly for its technological exports and frequent bloodbaths, one shouldn’t take the matter of tuition lightly. The vacation was not, however, boring - I got to spend a lot of time with my lovely girlfriend, a chance to see friends I have not seen in a long time, and a lot of posts racked up in various forums. The vacation actually expanded far enough to contain independence day, so I managed to experience the closest thing to a hangover I’d ever had (But that was some great scotch). Actually, independence day could have been truly superb; the whole thing got me thinking about what the perfect night out would be: It’s obviously best with my girlfriend. It would probably start with a rock show of sorts, continue with food and beer, and end in my girlfriend’s bed. Better yet - if I’m in the show. Better still - if there’s no reason to get up early the following day. Another item of interest is that I’ve joined a band. Hopefully I’ll be able to keep up the 3-hours-on-Saturday rehearsals. It’s a “Trash Metal” band which has evidently had really bad experience with bass players. Unfortunately, we seem to have a myspace page. It looks… myspaceish. However, I really think the group has potential, as well as excellent influences. Furthermore, I’m an attention whore :D. Hopefully I’ll be able to help influence the band into more of a heavy-metal direction by harassing them with melodic basslines. Very little geek news this time, other than the fact that Feisty Fawn is out. My verdict - get it. It’s awesome. Period. Suspend works much better, NetworkManager is now installed by default, a lot of things have really been polished, and - can you believe it - Sudoku :)! If you already run Ubuntu, I’d advise against using the update manager - it works, but it takes a long time, and cannot run unattended. Also, a word of caution to server admins though - sqlite3 is the new default, so if you have sqlite2 databases you’ll need to convert them (use the sqlite and sqlite3 binaries to do this) - otherwise you’ll get “file is not a database, or is encrypted” errors. Whew - that’s much better. My thoughts have been depleted into the bits and bytes before you. I’ll just plug a friend’s blog and hit the publish button now ;) ","date":"2007-04-24","objectID":"/posts/on-the-matter-of-a-really-long-vacation/:0:0","tags":["music","technion","life"],"title":"On the matter of a really long vacation","uri":"/posts/on-the-matter-of-a-really-long-vacation/"},{"categories":null,"content":"A lot of people ask me how to change the default operating system booted after installing Linux. The answer they get in Ubuntu’s case, “Edit /boot/grub/menu.lst, it’s self-explanatory”, is often unsatisfactory. Attached is the solution :) Actual script lost in the mists of time… Download the file, open a terminal, and run gksudo python grubmenu.py I’ll try and make a package of this soon, so it becomes a menu entry and that much easier to use. ","date":"2007-04-19","objectID":"/posts/grub-menu-lst-editor/:0:0","tags":["linux"],"title":"Grub menu.lst editor","uri":"/posts/grub-menu-lst-editor/"},{"categories":null,"content":"Why was it down, you ask? Well, it was out here in the lab, because of a shortage of network ports in the server room. From the acpid log: [Sun Apr 15 18:53:07 2007] received event \"button/power PWRF 00000080 00000001\" That is, at 18:53, someone simply pushed the power button. The server promptly closed all processes and properly shut itself down. I’ve moved it into the server room now… ","date":"2007-04-16","objectID":"/posts/yasmin-back-up/:0:0","tags":["linux"],"title":"Yasmin back up","uri":"/posts/yasmin-back-up/"},{"categories":null,"content":"The more I use Python, the nicer it becomes. I’m currently working on a project for a course, which involves somewhat heavy-duty database and algorithm work. Python is my language of choice for it - let’s hope it works out well. In the meantime, I’ve found a really nice python shell called iPython (available in apt) - it adds a bunch of stuff to the python shell which I sorely missed from irb - autocompletion, auto-indentation, and - it seems - adds a whole lot more. Looks like I’ll have to check django out as well. I’ve been working with Ruby on Rails for quite a while now (and that’s how I got introduced to Ruby in the first place). Odd as it may be… do I have a new favorite language? ","date":"2007-03-04","objectID":"/posts/ipython/:0:0","tags":["software","python"],"title":"IPython","uri":"/posts/ipython/"},{"categories":null,"content":"A very neat find for those of you who want to use Jabber from within the Technion, but with your client of choice rather than a web-based one: Many Jabber servers, including Google Talk, support using Port 443 over SSL. Since the Technion does not block outbound SSL connections, this will work there as well. Be sure to mark the appropriate ‘Use old SSL protocol’ option in your jabber client (that’s what it’s called in gaim and pidgin, at any rate). ","date":"2007-02-27","objectID":"/posts/using-jabber-from-within-the-technion/:0:0","tags":["networking","technion"],"title":"Using Jabber from within the Technion","uri":"/posts/using-jabber-from-within-the-technion/"},{"categories":null,"content":"Check that the RAID it supports is actual Raid. My experience today: Decide that secondary server should gradually become more and more primary Decide that since it has two 160GB hard drives and built-in RAID, we should use that for mirroring Mail (both!) users of the secondary server that it’ll be down for rebuilding Set up RAID array from BIOS, clearing all old information Insert installation CD Notice that installation still sees two hard drives Discover that built-in NVRaid is actually software RAID Disable built in RAID in favor of LVM, proceed to reinstall :( ","date":"2007-02-26","objectID":"/posts/before-reinstalling-your-server-for-raid/:0:0","tags":["hardware"],"title":"Before reinstalling your server for RAID","uri":"/posts/before-reinstalling-your-server-for-raid/"},{"categories":null,"content":"I brought my Fender Squier Jazz Bass up to my Technion apartment. I hope it won’t have too much of an adverse effect on my studying… playing it (loud) is great for stress, and I’m taking a jazz improvisation course next semester. By the way - if any of you record with one of these, I highly recommend Arour, using a low-pass LADSPA filter. Also, activating both pickups on about 80% does wonders against hum if you connect directly. ","date":"2007-02-25","objectID":"/posts/bass-guitar/:0:0","tags":["music"],"title":"Bass guitar","uri":"/posts/bass-guitar/"},{"categories":null,"content":"I’ve converted my Antigibberish script1 (converts “broken hebrew” into proper hebrew, useful for sent-offline ICQ messages) to Python… it’s quite a nice language, and the interpreter is FAST! I’m really torn between it and Ruby :( Used to have a copy of antigibberish.py, but it’s been lost in the mists of time. It used to do the equivalent of this: iconv -f utf-8 -t iso8859-1 | iconv -f iso8859-8 -t utf-8  ↩︎ ","date":"2007-02-25","objectID":"/posts/really-liking-the-whole-python-thing/:0:0","tags":["software","python"],"title":"Really liking the whole Python thing","uri":"/posts/really-liking-the-whole-python-thing/"},{"categories":null,"content":" def factor(grade, params = {}) return 100 if params.empty? # Optimistic, eh? case params[:type] when :pass return 55 when :fail return 54 when :root params[:gamma] = 0.5 end grade = grade.to_f return params[:proc].call(grade) if params[:proc] grade *= params[:coefficient] if params[:coefficient] if params[:gamma] grade /= 100 grade **= params[:gamma] grade *= 100 end if params[:offset] grade += params[:offset] end return grade if params[:idnoclip] [ grade, 100 ].min end ","date":"2007-02-14","objectID":"/posts/heres-hoping/:0:0","tags":["technion"],"title":"Here's hoping","uri":"/posts/heres-hoping/"},{"categories":null,"content":"In the Haifa Bay Central bus station (מרכזית המפרץ), it’s possible to get an internet connection. HTTPS works automatically, and setting the proxy to proxy.technion.ac.il:8080 works for HTTP. I was unsuccessful in using corkscrew to get SSH connections to tunnel over it as well, but perhaps there is still a way. ","date":"2007-02-10","objectID":"/posts/internet-in-haifa-bay-central/:0:0","tags":["networking"],"title":"Internet in Haifa Bay Central","uri":"/posts/internet-in-haifa-bay-central/"},{"categories":null,"content":"This man has some beautiful design ideas for the Linux desktop. ","date":"2007-02-08","objectID":"/posts/beautiful-ideas/:0:0","tags":["software","linux"],"title":"Beautiful ideas","uri":"/posts/beautiful-ideas/"},{"categories":null,"content":"I’ve heard the latest Security Now, regarding the debate between Dave Marsh and Peter Guttman on DRM in Windows Vista. While a few good points were made, the major one - in my opinion - was not. DRM, in a practical sense, is deeply flawed: The idea is to give you your media - say, a WMA piece of music - and a program to play it with - say, Windows Media Player - but encrypt the media. Now, naturally, Media Player will need the decryption key for the media, and the idea is that Media Player will verify that you are allowed to listen to the song, and only then decrypt it - as it is played. However, something is clearly wrong here - both the encrypted media and the decryption key are sitting locally on your computer. It’s like giving you a locked box, as well as a butler (which will live in your house, where you presumably have a shotgun) with the key, and telling the butler not to open the box for anyone unauthorized. That is, you can open the Windows Media Player executable with your favorite hex editor, and dig away for the key. This is, of course, very complicated to do - but there are advanced ways of finding these keys, and once they’re found - they’re out. That’s why we keep hearing about WMA and iTunes’ equivalent format being cracked every once in a while, when they change it. No matter how sophisticated the DRM, you still get both the locked box and the key. They might build bigger butlers, but we can build deadlier shotguns. (Sorry for the violent analogy, but DRM kinda does that to me ;)) So, what can the *AA/Microsoft/Apple/DRM scapegoats inc. do about this? Well, they could supposedly have Windows recognize that you are trying to view the Windows Media Player executable, and stop you (I’d be surprised if they haven’t done this yet). However, currently you can still, for example, run Linux on the computer, and use that to view the executable. And if, by some crazy coincidence, all variants of Linux stop you from viewing the executable - you can pick your favorite, change the source code so it doesn’t, and use that. To stop you from running whatever unprotected operating system you want, changes to the hardware must be made. This is exactly what worries me about Vista. For the first time, we are seeing major effects like HDMI/HDCP, where the operating system interacts with the hardware directly to figure out exactly what the user is or isn’t allowed to do. Also, Vista boasts the “Trustworthy Computing” project, which is all too reminiscent of “Trusted Computing” - a project in which, through integrating protection from the bottom of the hardware (with a TPM, Trusted Platform Module chip) to the top of the software, the computer verifies that it is only running authorized operating systems, which run only authorized programs. Now, the media companies would love this. Say HD-DVD’s been completely cracked, and an alternative, open-source, unprotected player has been released. If your system is TPM-protected, it simply won’t allow this software to run. Your own compiled applications can be forbidden from running as well, seeing as their source code just might be the HD-DVD cracking code. Unauthorized operating systems would, naturally, not be allowed to run. Now, I’m not explicitly blaming Microsoft for this. Fact of the matter is, the protection they’ve built into Vista, although probably (for the reasons I’ve mentioned) insufficient, was required by the media companies in order for HD-DVD support to be (legally/technically) possible in Vista. Would Microsoft go so far as to enable the horror scenario I’ve pictured above? Probably not. But I do believe we all need to be aware of the risks, just to be on the safe side. ","date":"2007-02-07","objectID":"/posts/why-vista-worries-me/:0:0","tags":["software","security"],"title":"Why Vista worries me","uri":"/posts/why-vista-worries-me/"},{"categories":null,"content":"Well, penny knows. But I have proof she knows… http://www.wisdom.weizmann.ac.il/~naor/PUZZLES/waldo.html ","date":"2007-02-05","objectID":"/posts/i-know-where-waldo-is/:0:0","tags":["security"],"title":"I know where waldo is","uri":"/posts/i-know-where-waldo-is/"},{"categories":null,"content":"Everyone knew this was going to be an interesting one to watch. Die-hard Microsoft fans were sure Vista would be the final nail in the Open Source coffin, die-hard Linux fans were sure that the release would be Microsoft’s demise. Myself - I’m sitting and enjoying the show. It’s always very interesting to show Beryl to non-Linux users. They are almost always highly impressed, and are often completely in shock that Linux is a graphical system - many people still believe Linux is command-line only. But the funniest thing is that they always seem to care more about useless, spinning, transparent desktop cubes than, say, security. This holds for Vista’s flashy new graphics, as well - mainstream media seems to be focusing on Vista’s GUI a lot more than they are about its controversial new security features. Very interesting, keeping in mind that Windows has never been “not pretty enough” in consumer’s eyes, but rather too unstable or virus-prone. Controversial security? Yup. And I’m not even talking about the actually controversy-worth topics, like DRM… I’m talking about the system asking if you’re sure you want to set the clock. I’ve heard more noise about this than the fact that all of Vista’s new features pale in comparison to 7-year-old OS X which, incidentally, also “asks if you’re sure” that you want to set the clock. Nobody complains about that however. Why? In my opinion - it’s the password prompt. Just as people complained about Windows XP’s “Fisher-Price” theme, they’re now complaining about being treated like little kids. “Are you sure you want to set your clock?” - how condescending of the operating system. The reason it works well in Linux and OS X is that the system phrases the exact same question completely differently - “You are attempting to run “system-config-date” which requires administrative privileges”. Cryptic, right? I think they changed that for Ubuntu, too (I’m writing this off a Fedora box). But most users won’t have a hard time understanding that this, coupled with the password entry box, means that the system wants to make sure you are indeed someone allowed to set the clock. Hell, I believe that most people won’t have a problem making the logical leap from there to “hmm, perhaps setting the clock (im)properly can really mess up my system”. Either way, it’s much more pleasing than Vista’s seemingly endless, senseless sequences of “Are you sure?” dialog boxes. A password prompt like this tells the user - “You’re opening the hood here, watch your step”, the idea being that the user takes a hint and, realizing he has arrived at a password-protected part of his system, will indeed watch his proverbial step. But nobody is going to ditch windows over a couple of dialog boxes. There are much more interesting reasons to do that - I’ve heard of much instability, inavailability of drivers, confusions in the user interface… all of the things that Microsoft worked very hard to get rid of when XP was released, making Vista look like a step back. But most of all - it’s the timing. Vista’s 2007 release has given the world time to hear about shiny new Linux distributions, macs that run all of their old software, indexing services at least as powerful as Vista’s (now that WinFS has gone down the drain), more advanced graphical “shinyness” which works on older systems, and the horrors of DRM (thanks for that one, Sony). With nothing really new to give them, a high price tag (because it often includes a new computer), and several years of not being in the habit of buying a new OS, people have very little motivation to upgrade to Vista. But I don’t think that Microsoft and Windows are going anywhere, anytime soon. I do think Vista’s lost the battle - but to XP. Vista’s launch made people realize how successful XP was as an operating system, and the sheer momentum will keep people there. If Microsoft locks people out of technologies like DirectX 10 by making them Vista-only, this will keep people leaking away to OS X and Li","date":"2007-02-04","objectID":"/posts/on-vista/:0:0","tags":["software"],"title":"On Vista","uri":"/posts/on-vista/"},{"categories":null,"content":"This is absolutely antique (2000), but it’s good to hear an artist with a clue. http://archive.salon.com/tech/feature/2000/06/14/love/print.html ","date":"2007-02-02","objectID":"/posts/courtney-love-on-piracy/:0:0","tags":["life"],"title":"Courtney Love on Piracy","uri":"/posts/courtney-love-on-piracy/"},{"categories":null,"content":"If you’re like me, and don’t use Gnome or KDE, then you probably use the pmount or pmount-hal applications to mount removable media. Here’s a neat thing to add to your .bash_aliases: function pmh { pmount-hal $1 UDI=`hal-find-by-property --key block.device --string $1` cd \"`hal-get-property --udi $UDI --key volume.mount_point`\" } ","date":"2007-02-01","objectID":"/posts/pmount-hal-cd/:0:0","tags":["linux"],"title":"Pmount-hal + cd","uri":"/posts/pmount-hal-cd/"},{"categories":null,"content":"I do type mesmerizingly fast, though… :) Wanted poster I am told these were scattered around Taub… I haven’t been there to day, but it feels good to be infamous. ","date":"2007-01-31","objectID":"/posts/i-do-not-kick-puppies/:0:0","tags":["asides"],"title":"I do NOT kick puppies!","uri":"/posts/i-do-not-kick-puppies/"},{"categories":null,"content":"My lecture slides. Have a peek if you like :) sybilproof Reputation Mechanisms - Seminar ","date":"2007-01-30","objectID":"/posts/i-might-need-these-tomorrow/:0:0","tags":["technion"],"title":"I might need these tomorrow...","uri":"/posts/i-might-need-these-tomorrow/"},{"categories":null,"content":"When approaching a port, the Scotsman: You will never find a more wretched hive of scum and villany. And the crab cakes ain’t too bad, either! Later on: Is it fast? It sure is. But it’s gonna cost ya - 10,000 up-front. 10,000? We could buy our own ship for that! But who’s gonna sail it? I can. I piloted (some smaller kind of ship) back when I was a kid. (and if you haven’t seen Star Wars, you’re just not gonna get it) ","date":"2007-01-30","objectID":"/posts/samurai-jack-ingenious/:0:0","tags":["asides"],"title":"Samurai Jack - Ingenious!","uri":"/posts/samurai-jack-ingenious/"},{"categories":null,"content":"I’m going home for the weekend, as usual. Unfortunately, the first bus of my route comes by at highly unpredictable times - I’ve had it be an hour late on me once. There are plenty of Wi-fi networks around the station - either WPA, WEP or MAC-whitelisted… fortunately, someone was using the latter long enough for me to catch him with Kismet. Thank you, stranger! :) It’s a sad state of affairs that people go ahead and limit access to their wireless network. I keep mine wide open - מי שאוכל לבד, מת לבד. ","date":"2007-01-25","objectID":"/posts/waiting-for-the-bus/:0:0","tags":["networking"],"title":"Waiting for the bus","uri":"/posts/waiting-for-the-bus/"},{"categories":null,"content":"My new work desktop has a GeForce 4 MX, so I naturally installed Beryl on it. The graphics card has relatively little RAM, so it finds handling my 1280x1024 resolution difficult when additional texture memory is needed - so using something like Firefox really slows it down when Beryl is activated, making me keep it off most of the time. However, for coding, I’m finding that Beryl is very useful - it actually helps me that the code windows are transparent, so that I can see what’s underneath them, and the “Expose” effect still leaves text legible, which is great for reading off a lot of terminals at once. So is Beryl… a programmer’s tool? ","date":"2007-01-25","objectID":"/posts/3d-effects-for-coders/:0:0","tags":["software"],"title":"3D effects for coders?","uri":"/posts/3d-effects-for-coders/"},{"categories":null,"content":"Sometimes imperfections in Software drive me nuts. It’s what drove me away from Windows. It’s what keeps me switching back and forth between desktop environments. It’s what has me wasting a lot of time getting the software to do what I want, instead of getting anything done. I even have two particularily good examples. Firefox and Opera are my two favorite browsers. Opera is actually not as good, in my taste, as Firefox. Firefox’s slew of extensions (especially my latest favorites - Del.icio.us bookmarks and Firebug), better font handling (on Linux) and Open-Source nature keep it ahead, if all things were equal. However, Opera is much faster on my laptop. Way faster. And with the kind of browsing I usually do - zillions of tabs open and all, that difference counts. My other good example is LaTeX. I have the Beamer package, which makes absolutely stunning presentations in my favorite style of document creation - writing and compiling source code. However, one little thing drives me nuts about it - the symbols in math mode, even if I set it to Serif (Beamer uses sans-serif fonts by default), are not the default ones, which I prefer. For example, the symbol for “\\in” (a member of a set) looks horrible in my opinion. This tiny little thing had me chasing font preferences around for half an hour, to no avail. Graphviz. Ruby on Rails. Networkmanager. Openbox. IVMan. The list goes on… almost every piece of software I use has a little imperfection - not necessarily a bug, usually a missing features - that drives me crazy. Maybe I should quit my degree so I have time to fix all of those? ","date":"2007-01-25","objectID":"/posts/software-perfection-lost-in-the-details/:0:0","tags":["software"],"title":"Software Perfection - Lost in the details","uri":"/posts/software-perfection-lost-in-the-details/"},{"categories":null,"content":"Just finished downloading an episode of American Dad off Bittorrent. TV has ancient episodes of Family Guy. Took about an hour though… I tells ya, I’d pay for this kind of service if it were faster… ;) ","date":"2007-01-23","objectID":"/posts/alright-american-dad/:0:0","tags":["show downloading"],"title":"Alright, American Dad!","uri":"/posts/alright-american-dad/"},{"categories":null,"content":"Myself, I’m a Ruby hacker. I send everyone within earshot to TryRuby, code my sites using Rails, am surprised that I’m using a php-based blog… you get the picture. Ruby is sometimes called the Japanese Python, and comparisons are inevitable. I know very little about Python, but I do know that… It has a larger community More GUI applications are written in it More bindings are available for it Its interpreter is much faster Not a far inferior language Ruby certainly does have its advantages over it - trivial class expansion, extremely concise syntax, seemingly better-suited for heavy usage of closures, and Matz. Ya gotta love Matz. I will be giving Python a try soon… I love learning new programming languages. That’s why I’m taking Programming Languages this coming semester. ","date":"2007-01-23","objectID":"/posts/as-for-python/:0:0","tags":["software","technion"],"title":"As for Python","uri":"/posts/as-for-python/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. קצת גיקיות יתרה, ברשותכם 😉 התקנתי את הגירסה מ-CVS של מנהל החלונות האהוב עליי, Openbox, לקראת הגרסה המתעתדת לצאת 3.3, ומאוד התרשמתי לטובה: נוספה תמיכה ב-Pango, אז עברית סוף-סוף עובדת כמו שצריך (יש לקמפל עם הדגל with-pango הפאץ’ ל-Split gradients נכנס, מה שנותן ל-Themes ממש יפים לעבוד. מה שכן, הם שינו את שם ההגדרה מ-“split” ל-“splitvertical”, אז צריך לשנות את זה בקובץ themerc של כל theme רלוונטי מצ\"ב תמונת-מסך. שמייח ☺️ (תמונת-המסך נשמרה ב-Imageshack, ומאז נמחקה) עריכה: אני רוצה גם לציין לשבח את Obmenu, תוכנה שמאוד מקלה על עריכת התפריטים של Openbox. ","date":"2006-08-26","objectID":"/posts/openbox-cvs/:0:0","tags":["hebrew"],"title":"Openbox CVS","uri":"/posts/openbox-cvs/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. Context: 2006 Lebanon War החבר’ה הטובים ב-lgf מראים - הפלא ופלא - איך בהשוואה בין נזק פגיעות ישירות של קטיושות וטילי אוויר-קרקע ישראליים, הקטיושה עושה הרבה יותר נזק. בנוסף, אל תכנסו לבלוג של אחמדיניג’אד עם אקספלורר. זה מסוכן. מוות לקיצונים 😉 ","date":"2006-08-15","objectID":"/posts/katyusha-damage/:0:0","tags":["hebrew"],"title":"אהבתי את שני אלה","uri":"/posts/katyusha-damage/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. מרצ מציעה: להוציא את שיתוף הקבצים אל מחוץ לחוק. הכותרת אולי נשמעת מטעה, יחשוב לו הקורא התמים - הרי וודאי וּוודאי שלמרץ אין בעיה עם שיתוף קבצים באופן כללי, וכמובן שהמאבק שלהם מרוסן לעניין עבירות בנושא קניין רוחני. אך לא ולא - הסעיף הרביעי בהצעת החוק שלהם מוציא מחוץ לחוק תוכנות ושירותים לשיתוף קבצים. בכלל. זה שמאל זה? זו פרימיטיוויוּת מחשבתית חמורה ממה שאנחנו רואים מה-RIAA. לזכותם יאמר כי הם תומכים בפתרון בדמות מיסוי של הגולשים - אבל עושה רושם שהם ממהרים לוותר בחזית זו. אכזבה עמוקה ממפלגה שראיתי בה סיכוי לרפורמה ב\"קניין רוחני\" ותמיכה בתוכנה חופשית. ","date":"2006-08-15","objectID":"/posts/shame-on-meretz/:0:0","tags":["hebrew"],"title":"בושה וחרפה למרצ","uri":"/posts/shame-on-meretz/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. בהתחלה פלאש היה משהו קטן וחמוד. השתמשתי בו בכיתה ו’ בשביל “פרוייקט סיום” על גלגולי אנרגייה, בעוד שאחרים הכינו מכשירים שלא היו מביישים את The Incredible Machine. זה המשיך בכל מיני משחקים קטנים באתר של Shockwave. לאט לאט זה הפך למעצבן, כשאנשים החליטו ש-HTML זה סתם כמה טאגים ששמים כדי שהדפדפן יציג את הפלאש שהוא בעצם האתר. או לחילופין, החליטו שפלאש זה אחלה מדיום לפרסומות, מה שהוביל להופעת AdBlock. אבל בזמן האחרון עושה רושם שסוף-סוף מצאו את הייעוד האמיתי של פלאש - סרטוני ווידאו היתוליים. והגרסה האחרונה של פלאש עושה את זה נהדר - באמצעות Codec קנייני חדש ומתוחכם, הסרטים יורדים חיש-קל. הביצועים טובים, העומס על המערכת מינימלי… בקיצור - כולם נהנים. אבל לא לכולם יש את הגרסא האחרונה הזו. לא לכולם אפילו יש את גרסה 8. משתמשי לינוקס תקועים עם גרסה 7 - וגרסה גרועה של גרסה 7. כל אובייקט פלאש תופס ה-מ-ו-ן משאבי מערכת. הם עובדים לאט, הסאונד לא מסונכרן (אלא אם משתמשים ב-aoss, מה שמוסיף לפגוע ביציבות), וה-Codec החדש והנפלא הזה - שכחו ממנו. באתרי הווידאו שבכל זאת דואגים לתמוך בפלאש 7 אפשר לראות את הסרטים יורדים לאט-לאט. ב-Youtube, למעשה, אפילו את זה אי אפשר לראות - צריך לנחש מתי הסרט סיים לרדת. גרוע מכך, Adobe (הבעלים החדשים של פלאש) כל פעם אומרים ש\"הגרסה החדשה ללינוקס יוצאת בקרוב\". כך הם אמרו בפלאש 8. כשלא יצא, אמרו שיהיה 8.5. עכשיו הם אומרים את אותו הדבר ב-9. כרגע תאריך היעד המפורסם הוא “מוקדם ב-2007”, והם אפילו טרחו להעלות בלוג של אחד מהמפתחים. מעניין מאוד מה שהולך בבלוג הזה, אגב - הם אומרים שהם עובדים נורא קשה על לגרום לתאימות עם מצלמות ווידאו בלינוקס, ולוודא שכמה שיותר מצלמות עובדות. עכשיו, תגידו לי - מישהו כאן אי פעם ראה סרטון פלאש שאשכרה משתמש במצלמת ווידאו? איפהשהו? שימו לינק בתגובות. גרוע מכך - הם אומרים שכרגע הם לא משחררים גרסת בטא כי למרות שהסאונד מסונכרן פרפקט ו-Youtube עובד די טוב, עדיין יש הרבה בעיות יציבות. אז יש לי חדשות בשבילכם חברים - גם בגירסה הנוכחית יש המון בעיות יציבות! שחררו את זה מצידי בגירסת “סופר-היפר-אלפה-אל-תגעו-יא-חארות”! ורק עוד נקודה אחת. אומרים בפורומים אחרים שזה בעיה של קהילת הקוד הפתוח שלא פיתחנו גרסה משלנו לפלאש. למרבה הצער, פלאש משתמש במספר אלמנטים קנייניים - החשוב ביניהם הוא הקודק החדש של הווידאו. מה לעשות, כאן אנחנו תלויים ב-Adobe. זהו, יצא הקיטור. בחזרה ל-Youtube. 🙂 ","date":"2006-08-14","objectID":"/posts/flash-in-linux/:0:0","tags":["hebrew"],"title":"המצב של פלאש בלינוקס","uri":"/posts/flash-in-linux/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. Context: 2006 Lebanon War ממש שקט. לא שמתי שעון מעורר, כי סמכתי על הנסראללה המעורר. בכלל, הישוב שלי מחובר לאזעקות של כל הארץ (כי הוא באמצע שום מקום) אז אנחנו מקבלים גם אזעקות של קרית שמונה. כבר היה כל כך שקט, שאבא שלי קצת הלך לישון… ואז אני שומע דרך המזגן אזעקה, צועק “אזעקה”, ואמא שלי אומרת להיות בשקט כי אבא ישן… ","date":"2006-08-12","objectID":"/posts/nice-and-quiet/:0:0","tags":["hebrew"],"title":"דווקא היה נחמד, שקט וכאלה","uri":"/posts/nice-and-quiet/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. Context: 2006 Lebanon War כולנו ראינו אותו בטלוויזיה ובתמונות. קראנו את הכתבות, ראינו את הצילומים של איך שהוא מוריד את הגופות מהאמבולנס כדי שיצלמו שוב, עם פוקוס יותר טוב ובלי שאנשים יסתירו. איך במשך שעות הוא סוחב אותה גופה הלוך ושוב בשביל המצלמות. ושאיכשהו הוא תמיד מצליח להגיע לכל זירה מצולמת. ועכשיו יש לו בלוג משלו! 🙂 ","date":"2006-08-11","objectID":"/posts/green-helmet-guy/:0:0","tags":["hebrew"],"title":"החבוב עם הקסדה הירוקה - עכשיו הבלוג","uri":"/posts/green-helmet-guy/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog’s language at the time. Context: 2006 Lebanon War מלחמה. נסראללה שולח עלינו בומים. אנחנו שולחים עליו בומים (כל 10 שניות יציאה שלנו אתמול בלילה, והתריסים רועדים). ואני בבית, עושה בומים משלי. זה לא כמו לנגן עם חברים, זה לא כמו להופיע, אבל לפחות סוף סוף גיליתי איך לגרום לזה להישמע נורמאלי. הציוד - בס ג’אז של סקוייר. אדום. כבל LP - גם אדום. מקטין LP ולפטופ. התוכנה - Ardour, יחד עם כמה פלאגינים של LADSPA. אז מה שגיליתי זה ככה - להפעיל את שני הפיקאפים על אותו ווליום, ושלא יהיה עד הסוף. ככה הם מבטלים את ההמהום. להשתמש ב-lowpass filter כדי לבטל את הרחשים הגבוהים להשתמש ב-compressor, ולבחור אותו בקפידה. ככה ישמעו את ה-hammer-ons/pull-offs הרבה יותר טוב, ואפשר לנגן חלש או חזק בלי שזה ירד מהסקאלה במסע להוציא את האינפורמציה הזו עליתי על אחלה להקה מאיטליה. שווה האזנה. ","date":"2006-08-11","objectID":"/posts/recording-booms/:0:0","tags":["hebrew"],"title":"מקליטים בומים","uri":"/posts/recording-booms/"},{"categories":null,"content":" This is a handy little page for copying the stress mark (acute mark) to clipboard. Useful if your Russian keyboard doesn't support it. ́ Copy","date":"0001-01-01","objectID":"/russian-stress/:0:0","tags":null,"title":"Russian stress mark","uri":"/russian-stress/"}]