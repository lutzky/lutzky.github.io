[{"categories":null,"content":"Hebrew resources Wikipedia Gvura (◊¢◊ô◊ò◊ï◊® ◊î◊û◊§◊ï◊™) ","date":"2025-12-18","objectID":"/dov/:1:0","tags":null,"title":"Dov Lutzky","uri":"/dov/"},{"categories":null,"content":"English resources The role of pro-active community policing; December 2007 OSCE talk; ‚ÄúThe role of pro-active community policing in promoting tolerance in diverse communities‚Äù ","date":"2025-12-18","objectID":"/dov/:2:0","tags":null,"title":"Dov Lutzky","uri":"/dov/"},{"categories":["Newborn parenting software"],"content":"About 4 years later, we‚Äôve done it again! With kid #2, we‚Äôre older, wiser, more tired, and have a slightly different strategy. We still love tracking stuff, and BabyBuddy (a self-hosted baby tracking application) is still the best option. However, a couple of things have changed: First, the poo buttons have largely been replaced with a wall-mounted tablet displaying our HomeAssistant UI (which, indeed, has buttons for nappy recording). Secondly, and more significantly - kid #2 is breastfed. One of the advantages of breastfeeding is that some moms can, in the middle of the night, feed a hungry baby while barely waking up themselves. Unfortunately, if mom is interested in tracking the breastfeeding, and needs to unlock the phone (multiple times) and perform additional taps, this doesn‚Äôt work, and she wakes up. Most interactive software is, perhaps unsurprisingly, designed for people who are wide awake. So - home automation to the rescue! I already have a bunch of IKEA shortcut buttons which work nicely with HomeAssistant through a my ConnBee 2, and IKEA‚Äôs newer SOMRIG shortcut buttons provide 2-buttons-in-1. All I need is 3 options (provided by 2 such SOMRIG units) - ‚Äústart timer‚Äù, ‚Äústop timer and mark that as a left-breast feeding‚Äù, and ‚Äústop timer and mark that as right-breast‚Äù. These button devices are wonderfully compact and their batteries last pretty long. This has to do with the fact that they have no screen, so unfortunately no way of indicating whether they worked or not; and they don‚Äôt always work on the first click. Fortunately, I had an old IKEA desk-lamp with a Zigbee RGB lightbulb I hadn‚Äôt really found use for. This lamp has now become a floor-based night-light to indicate the status: Dim blue when the timer is on (during feeding) When feeding is done, green or orange for a few seconds (depending on the side) ‚Ä¶and back off. Indeed, a few smart buttons and a literal lightbulb-moment of an idea are allowing my wife to go back to sleep much more quickly, without giving up on our shared tracking obsession. It‚Äôs amazing how much of a quality-of-life difference you can make with some straightforward home automation. ","date":"2025-07-10","objectID":"/posts/software-parenting-4/:0:0","tags":["software","life","hardware"],"title":"Newborn parenting software - part 4","uri":"/posts/software-parenting-4/"},{"categories":null,"content":"Copy-on-write makes snapshots fast and accessible, but deleting them to reclaim disk space can be a bit confusing. Let‚Äôs have a quick primer on how those work, and look at a small utility to help reason about it. zsnapfree is a TUI for showing how much space can be reclaimed by freeing zfs snapshots. It is a TUI wrapper over the standard zfs tool. If you just want to see zsnapfree in action, skip to the screencast. ","date":"2024-08-23","objectID":"/posts/zsnapfree/:0:0","tags":["software"],"title":"zsnapfree","uri":"/posts/zsnapfree/"},{"categories":null,"content":"What are COW snapshots? üêÆ We all have little accidents with our files. Although the ‚ÄúRecycle bin‚Äù protects you against accidentally deleting files, most filesystems don‚Äôt protect against accidentally modifying them. To change files back, you want a filesystems with snapshots. A snapshot is extremely fast to make, and lets you access the contents of the file as it was when the snapshot was taken. In ZFS, with zfs-auto-snapshot installed, the experience might look like this: A ZFS filesystem called /tank/videos exists. A file /tank/videos/renders/my_video.mp4 exists, but I accidentally overwrite it. The file has existed for a while, so zfs-auto-snapshot has already created a snapshot of the good version at 14:17; specifically, it‚Äôs called zfs-auto-snap_hourly-2024-08-20-1417. The good version is therefore available at (takes a breath) /tank/videos/.zfs/snapshot/zfs-auto-snap_hourly-2024-08-20-1417/renders/my_video.mp4. We‚Äôll get back to those long snapshot names later. For now, it‚Äôs worth sketching out how this works. The actual ZFS implementation is more complex, but roughly speaking, you can imagine that the videos ‚Äúcurrent-state‚Äù is represented by a table that includes rows describing what 128KB blocks make up each file. If our file renders/my_video.mp4 is 128MB, it will be made up of 1024 blocks, and the table might have a section like this: File renders/my_video is represented by virtual blocks 1000 through 2023. Virtual block 1000 is in physical location 5001 Virtual block 1001 is in physical location 6713 ‚Ä¶ To create a snapshot, we only need to duplicate the information above, which is roughly 8KB, so this can be done quickly and for very little extra space. However, what happens when the data changes? Snapshots should remain immutable even if the ‚Äúcurrent-state‚Äù changes. Suppose for instance we change the very first block in the file - virtual block 1000. What happens now is the titular ‚Äúcopy-on-write‚Äù - the block which needs to be rewritten will first be copied. Physical location 5001 would be duplicated to a new location, say 7001, and this version of the block will be modified. The current-state table would be updated to say that virtual block 1000 is in physical location 7001 (but the snapshot would still have it listed as physical location 5001). Importantly, physical location 5001 is still in use, and cannot be freed. There would likely be a table keeping reference counts for each physical location; after the last snapshot referencing it would be deleted, this space can be reclaimed. ","date":"2024-08-23","objectID":"/posts/zsnapfree/:1:0","tags":["software"],"title":"zsnapfree","uri":"/posts/zsnapfree/"},{"categories":null,"content":"Accidentally storing big files Suppose you accidentally store useless_data.zip, a 100GB file, in a filesystem that takes snapshots. You find yourself running out of space, and decide to delete that file‚Ä¶ but no space is recovered. The reason is that snapshots still hold this data, and you would need to delete all of those snapshots in order to reclaim it. The question is‚Ä¶ which ones? Although you can run zfs list -t snapshot -o space, the USED column there only counts space used by files which are unique to that snapshot. That is, if another snapshot has been created (e.g. by zfs-auto-snapshot), the USED column will count that file as zero. Fortunately, ZFS has a great utility for previewing this. If we believe that the file was created just before snapshot1, and deleted just after snapshot3, then we can do this: $ zfs destroy -nv tank/video@snapshot1,snapshot2,snapshot3 would destroy tank/video@snapshot1 would destroy tank/video@snapshot2 would destroy tank/video@snapshot3 would reclaim 100GB This command actually does nothing (-n) except show information. Critically, running it with just one or two of the snapshots would reclaim 0GB, so this is great for harmless reasoning about what snapshots we‚Äôd need to sacrifice to reclaim space. There‚Äôs even a handy % ‚Äúrange‚Äù operator, so we could rewrite the above as tank/videos@snapshot1%snapshot3. ","date":"2024-08-23","objectID":"/posts/zsnapfree/:2:0","tags":["software"],"title":"zsnapfree","uri":"/posts/zsnapfree/"},{"categories":null,"content":"Dealing with long snapshot names The unrealistic thing about the previous example is the short and convenient snapshot names. zfs-auto-snapshot is great, but the snapshot names are more like zfs-auto-snap_hourly-2024-08-20-1417. This makes trying different snapshot selections cumbersome, and prompted me to write my very first TUI app in Rust. It‚Äôs a simple wrapper around the zfs command, and, well, a video is worth several words: When selecting snapshots, the tool runs (after a short delay) zfs destroy -n to show how much space would be reclaimed. On exit, it shows the appropriate commandline to check its findings and, if removing -n, actually perform the deletion. Hopefully this is of some use for ZFS users, and I would love any patches to add support for other filesystems that have snapshot support! ","date":"2024-08-23","objectID":"/posts/zsnapfree/:3:0","tags":["software"],"title":"zsnapfree","uri":"/posts/zsnapfree/"},{"categories":null,"content":"Rebooting a modern desktop computer really shouldn‚Äôt take very long, so when it was somewhat-regularly taking well over 10 minutes just to shut down, I got curious, and ended up looking at netdata, jitter, anacron, and even ansible. By default in Ubuntu, the shutdown process is hidden, but pressing ESC showed that anacron was waiting on something indefinitely‚Ä¶ and indeed, given a few dozen minutes, it would complete. Sure, Raising Small Elephants Is Utterly Boring1 can fix that, but something seemed wrong. Adding some logging to anacron, it turned out that the bit which was taking so long was something called netdata-updater. ","date":"2024-06-23","objectID":"/posts/slow-boot/:0:0","tags":["software"],"title":"Adventures with slow boot","uri":"/posts/slow-boot/"},{"categories":null,"content":"Netdata There‚Äôs lots of ways to get information about your various networked machines, but my favorite for works-out-of-the-box laziness is netdata. I like to run this on my desktop as well, so I can retroactively diagnose issues or obsess over the specific fan speeds that led to a mildly annoying hum in the quiet evening. Netdata installs a self-update cron job, which is sensible. It‚Äôs installed in /etc/cron.daily, which by default is launched every day at 6:25 AM. This would cause all machines it‚Äôs installed on, within a timezone, to hit the servers simultaneously; to avoid this, they added jitter - the update script randomly waits between 0 and NETDATA_UPDATER_JITTER, the default being 60 minutes. So, if you‚Äôre trying to reboot just after 06:25 AM, you‚Äôre probably going to wait an extra 30-ish minutes. Although adding jitter arguably makes sense on systems running cron, it makes far less sense on ones running Anacron. ","date":"2024-06-23","objectID":"/posts/slow-boot/:1:0","tags":["software"],"title":"Adventures with slow boot","uri":"/posts/slow-boot/"},{"categories":null,"content":"Anacron Cron works well for machines that stay on all the time, e.g. servers. However, machines that are often off or suspended would likely miss the specific timing of the scheduled tasks. For such machines, anacron is used instead, and tries to make sure that daily tasks still occur daily: Once an hour, anacron will wake up (if the machine is on) and check whether any daily tasks still need to be run that day. That means that if I first turn on my computer in the evening, it has updates and wants to reboot, and I let it - I have a really high chance of netdata-updater being called, and of this little maneuver costing me 30-ish minute of precious gaming time. Anacron naturally introduces jitter, and anacron has additional jitter-introducing mechanisms2. Indeed, there‚Äôs no need to add jitter to netdata-updater running under anacron, so I changed NETDATA_UPDATER_JITTER to 0, and indeed my suggestion to make this the default under anacron was accepted. That being said, it still seemed there‚Äôs no good reason for shutdown to wait over 10 minutes for anacron to shutdown. The shutdown screen showed that the timeout was infinite, although the systemd default3 is 90 seconds. That‚Äôs because anacron.service has this line: TimeoutStopSec=infinity This was added in this commit, to resolve this bug. A more elegant solution is possible, but discouraged because anacron is meant to be replaced by something called ‚Äúcronie‚Äù; I am familiar with this pain. One way or another, I disagree with the reasoning, at least in my own particular case, and have decided to comment out the infinite timeout line. ","date":"2024-06-23","objectID":"/posts/slow-boot/:2:0","tags":["software"],"title":"Adventures with slow boot","uri":"/posts/slow-boot/"},{"categories":null,"content":"Remembering this config I like to version-control and automate my configuration. I‚Äôve been doing this for my dotfiles for quite a while, but not for my overall machine config. Tweaks like this, to my system config, are something I‚Äôd rather have a script to do rather than writing it down in a checklist. As it turns out, Ansible is considered to be a good tool for this. I thought it‚Äôs only useful for ‚Äúapply some settings to a large set of servers‚Äù, but apparently ‚Äúmaintain config for my one server‚Äù is not such a strange use-case. I‚Äôm completely unfamiliar with Ansible; a coworker tells me that‚Äôs because I‚Äôve worked at Google4 for almost 10 years, and that‚Äôs roughly as long as Ansible‚Äôs been well-known. After a bit of futzing around, I‚Äôve come up with this playbook.yml: - name: Fix slow shutdown hosts: all tasks: - name: Finite timeout for anacron become: true lineinfile: path: /usr/lib/systemd/system/anacron.service regexp: 'TimeoutStopSec=infinity' line: '# TimeoutStopSec=infinity # Causes slow shutdown' - name: Force netdata jitter to 0 become: true lineinfile: path: /etc/netdata/netdata-updater.conf regexp: '^NETDATA_UPDATER_JITTER=.*' line: 'NETDATA_UPDATER_JITTER=\"0\"' Then, to get everything to play nice with the local config, I have this ansible.cfg: [defaults] inventory = inventory And this inventory: localhost ansible_connection=local Sure, this could‚Äôve been a shell script, but this seems easier to extend and maintain. One thing I like about this is that I can run ansible-playbook --check --diff playbook.yml, and get a preview of what it‚Äôll do. I‚Äôll likely be looking deeper into ansible and seeing whether it‚Äôs worthwhile getting it to maintain some of my server configs. This has been a fun dive into a slight annoyance with my system, and as always I ended up learning a few interesting things. Please do jitter your clients, but please don‚Äôt leave users hanging. Also, feel free to let me know in the comments that I‚Äôm holding Ansible wrong üòÑ. This is a mnemonic for Alt+SysRq+{r,s,e,i,u,b}, a somewhat aggressive mechanism to reboot a linux system.¬†‚Ü©Ô∏é In Ubuntu 24.04, this is accomplished by the anacron.timer systemd unit having RandomizedDelaySec=5m configured.¬†‚Ü©Ô∏é DefaultTimeoutStopSec under man 5 systemd-system.conf¬†‚Ü©Ô∏é Google is known for having a ‚Äútech island‚Äù, and specifically the type of problems which Ansible deals with, at least in my line of work, have preexisting in-house solutions, so I never had the chance to learn Ansible.¬†‚Ü©Ô∏é ","date":"2024-06-23","objectID":"/posts/slow-boot/:3:0","tags":["software"],"title":"Adventures with slow boot","uri":"/posts/slow-boot/"},{"categories":null,"content":"Figuring out what‚Äôs taking up space is a well-known issue, with a variety of great tools for it‚Ä¶ if we‚Äôre talking about files on a local hard drive. Tools like the textual ncdu and the graphical baobab let you start with a high-level summary, and dive into specific directories to find out what‚Äôs taking up all of the space. Screenshot of ncdu However, sometimes what you have is on a cloud storage system, which is happy to bill you for space your files take, but the UI doesn‚Äôt make it super-easy to figure out which directories take up that storage. For example, with Google Cloud Storage, you can use rclone ncdu, but my modest backup bucket had it consistently timing out. For this purpose, the recommended path appears to be Storage Inventory, which will provide you with a CSV listing of all of the files in your bucket. The apparent recommendation is to analyze it using a custom-crafted BigQuery query, which is nowhere near as handy as ncdu. $ cat inventory-reports_VERY_LONG_ID.csv | cut -f3,10 -d, name,size esphome/config/esphome-tester.yaml,5254 esphome/config/esphome-tester2.yaml,1049 meta/esphome/docker-compose.yml,308 misc_backed_up/ohad/3dprint/light_switch_covers/Part Studio 1 - Part 1.stl,1484 misc_backed_up/ohad/3dprint/light_switch_covers/Part Studio 1 - Part 2.stl,1033884 misc_backed_up/ohad/3dprint/light_switch_covers/Part Studio 1 - Part 3.stl,1591184 misc_backed_up/ohad/3dprint/light_switch_covers/light_switch_covers.gcode,919652 misc_backed_up/ohad/3dprint/light_switch_covers/old_too_small/Part Studio 1 - Part 2.stl,1033884 misc_backed_up/ohad/3dprint/light_switch_covers/old_too_small/Part Studio 1 - Part 3.stl,1603784 misc_backed_up/ohad/3dprint/light_switch_covers/old_too_small/light_switch_covers.ufp,142725 misc_backed_up/ohad/3dprint/light_switch_covers/old_too_small/light_switch_covers_gcode.ufp,627744 ... Fortunately, ncdu has an import/export feature, for those slow scans. ncdu -o foo.json will save such a report (slowly), and ncdu -f foo.json will display it (quickly). So, how about if we cheat, and convert our CSV of files-in-the-cloud to ncdu-compatible JSON? That‚Äôs where ncdu-import comes in. Bring it a CSV file which has a ‚Äúpath‚Äù column and a ‚Äúsize‚Äù column (tell it what the columns are), and it‚Äôll spit out a JSON file loadable by ncdu for quick and convenient analysis. You can look at the testdata dir to get a few examples of what it‚Äôs doing. ncdu showing output ncdu-import on the sample CSV above ","date":"2024-01-28","objectID":"/posts/ncdu-import/:0:0","tags":["software"],"title":"ncdu-import","uri":"/posts/ncdu-import/"},{"categories":null,"content":"Let‚Äôs make a tiny display for stuff you check right before leaving home! I keep forgetting to turn off my alarm as I leave home, and then scrambling to turn it off1. Even if I do remember to turn it off, I‚Äôm never quite sure that I did, so I take my phone out, open the appropriate app, and check. It would be super convenient if I had a little indicator near the door, so I (or anyone else leaving) could check more quickly. A single red LED would technically do the job‚Ä¶ but wouldn‚Äôt be wife-approved. I love tiny OLED displays. Let‚Äôs use one of those! I got an ESP8266 with an onboard OLED display, and thanks to ESPhome, having a display of the alarm status is easy enough. There‚Äôs still plenty of room on the display, so I figured I can add a couple of other things I quickly check before leaving home: Weather and tram times. I used the Edit Undo font and some Material Icons for a bit of styling. I ended up having to mess with exact spacing a lot until I was happy with it; it would be super helpful if there were a simulator like wokwi for ESPHome to iterate on this more quickly! The resulting device without a case Next step is to create a case for it. This is necessary both for wife-approval and for cleaner mounting to the wall. I use Onshape for this, as it‚Äôs both free and parametric - that is, I can change numbers later to adjust the design without fully re-doing it; and if there‚Äôs one thing I‚Äôve learned about designing for 3D printing, is that it takes a few iterations to get it right: Print, learn that it almost works, adjust, repeat. Iterating on the case design in Onshape With this design, I got some nice shadow lines. I had originally planned to use screws, but it turned out to be fairly annoying: While the PCB does have holes for mounting screws, there isn‚Äôt a lot of room for nuts; it ended up being simpler to make a fully plastic snap-fit design. Snap-fit, especially with 3D printing, is an even worse source of trial-and-error iterations, as there seems to be a fine line between ‚Äúdoesn‚Äôt snap‚Äù and ‚Äúsnaps off altogether‚Äù, especially with smaller designs. It doesn‚Äôt help that I‚Äôm using a somewhat older Ultimaker 5 printer with PLA material; I know there are more modern and robust printers, but the Ultimaker 5 is maintained by experts at our maker room, which only allows PLA, and I figured it should be doable. Thankfully, I was right! I‚Äôm really happy with the final result, and it‚Äôs proving to be at-a-glance useful every day. Final result The alarm app has added a feature, after I created the device described in this post, to turn it off if any indoors motion is detected at the appropriate time, mostly solving this issue.¬†‚Ü©Ô∏é ","date":"2023-12-29","objectID":"/posts/front-door-display/:0:0","tags":["hardware"],"title":"Front Door Display","uri":"/posts/front-door-display/"},{"categories":null,"content":"In October 2023, two weeks before daylight savings time (‚Äúsummer time‚Äù) was set to end, Israel briefly considered delaying this. That would‚Äôve been a terrible idea, even if it weren‚Äôt at war at the time. ","date":"2023-10-16","objectID":"/posts/timezone-changes/:0:0","tags":["software"],"title":"Timezone Changes","uri":"/posts/timezone-changes/"},{"categories":null,"content":"A hacked toll tunnel? Through the northern city of Haifa, the Carmel Tunnels are a toll bypass of the city. About 10 years ago, on September 8-9, 2013 (yes that date will be relevant), the tunnels were shut down due to a ‚Äúcyber attack‚Äù; rumor is that the toll system didn‚Äôt function, and rather than take the loss, the tunnels stayed closed for many hours, causing traffic chaos. I don‚Äôt think it was a cyber attack. ","date":"2023-10-16","objectID":"/posts/timezone-changes/:1:0","tags":["software"],"title":"Timezone Changes","uri":"/posts/timezone-changes/"},{"categories":null,"content":"Timezones in Israel Timezone legislation in Israel is complicated (this sometimes saves lives). Between 2005 and 2012, DST was set to end on the Last Sunday before the 10th of Tishrei. Tishrei is a month in the traditional Jewish calendar, which is less common in day-to-day use in Israel, but does determine holidays (similar to Easter). However, legislation managed to change - twice - between 2012 and 2013. The first change (November 2012) had DST ending on the first Sunday after October 1st, and the second (2013) had DST ending on the last Sunday of October. Note Until 2013, the Israeli law for daylight savings time relied on the lunar calendar, so the rule couldn‚Äôt be represented easily using the Gregorian calendar. If you look at the timezone database source data, you can see things suddenly got very efficient: # Rule\u003e NAME\u003e FROM\u003e TO\u003e -\u003e IN\u003e ON\u003e AT\u003e SAVE\u003e LETTER/S # ...explicit lines for every year since 1940... Rule\u003e Zion\u003e 2010\u003e only\u003e -\u003e Sep\u003e 12\u003e 2:00\u003e 0\u003e S Rule\u003e Zion\u003e 2011\u003e only\u003e -\u003e Oct\u003e 2\u003e 2:00\u003e 0\u003e S Rule\u003e Zion\u003e 2012\u003e only\u003e -\u003e Sep\u003e 23\u003e 2:00\u003e 0\u003e S Rule\u003e Zion\u003e 2013\u003e max\u003e -\u003e Mar\u003e Fri\u003e=23\u003e2:00\u003e 1:00\u003e D Rule\u003e Zion\u003e 2013\u003e max\u003e -\u003e Oct\u003e lastSun\u003e2:00\u003e 0\u003e S # ...and that's it. Anyway, if one were to go by the pre-2012 law but apply it 2013, daylight savings time should have ended on - you guessed it - September 8th. So, in my opinion, a much likelier scenario than a ‚Äúcyber attack‚Äù is simply that some of the systems suddenly found themselves one hour out of sync with the rest, and things got pretty confused. Wikipedia notes that, on this day (as well as October 6th, due to the 2012 law), many smartphones showed an incorrect time because they hadn‚Äôt been updated with the latest legislation. And that‚Äôs despite having, for September 8th, almost a year‚Äôs notice; expecting everyone‚Äôs personal devices to be updated in two weeks is pure fantasy. ","date":"2023-10-16","objectID":"/posts/timezone-changes/:2:0","tags":["software"],"title":"Timezone Changes","uri":"/posts/timezone-changes/"},{"categories":null,"content":"Nobody‚Äôs up changing the clocks at 2AM It‚Äôs important to understand that this is how it all works; computer-based systems have a file somewhere that says ‚Äúthis is when the daylight savings change will happen‚Äù, and things happen automatically on that basis; they have to, for a simultaneous transition of all computing systems. Any change to that timezone file takes time and effort to create, test, and distribute, for each different type of computing system. This is not something to be done under time pressure as a ‚Äúwould-be-nice‚Äù1. Not unless you want to have ‚Äúcyber attacks‚Äù. Many years ago, I described an effort to coerce the timezone system into a ‚Äúchange on demand‚Äù mode; see post Timezones are fickle.¬†‚Ü©Ô∏é ","date":"2023-10-16","objectID":"/posts/timezone-changes/:3:0","tags":["software"],"title":"Timezone Changes","uri":"/posts/timezone-changes/"},{"categories":null,"content":"For as long as I‚Äôve been interested in software development, I‚Äôve been interested in how software makes it onto a computer. ‚ÄúWorks on my machine‚Äù was never quite enough‚Ä¶ how would it work on someone else‚Äôs computer? Here‚Äôs a stroll down memory lane, starting from the 90s. ","date":"2023-04-23","objectID":"/posts/software-distribution/:0:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"QBasic (early 90s) In the early 90s, when I was about 8 years old, someone showed me that my computer came with a piece of software called QBasic - it came with the MS-DOS operating system. Although nobody in my family knew how to use it, and this was long before I had access to the internet, it came with an impressive set of examples as well as an interactive reference manual that I recall as being very thorough. Having messed around with it and made a few animations and utilities, I thought it would be cool to give copies to my classmates to play around with; y‚Äôknow, like a professional software developer would. QBasic‚Äôs opening screen The software, as I wrote it, was a collection of source code files - just text files with a .BAS extension. For anyone to run those programs, they‚Äôd have to open QBasic themselves, select ‚ÄúFile‚ÜíOpen‚Äù, navigate to my file, then use the ‚ÄúRun‚Äù menu to actually run the program. And presumably figure out how to exit QBasic when they‚Äôre done. Now, 8-year-olds in the 90s were used to computers being slightly harder to operate, e.g. typing out a command or two to open a game; indeed, friends did figure this out. But this still felt like a super janky way to distribute software. What I actually wanted to do was provide a ‚Äúself-contained‚Äù program, one where you simply enter its name and it starts up, like any other DOS program I‚Äôd seen. Ideally, it would have the fashionable .EXE extension (the term ‚ÄúEXE file‚Äù seemed pretty much synonymous with ‚Äúprogram‚Äù). Note - Batch files What I wanted to do was allow people to run LUTZKY1.BAS with one command. This could‚Äôve been accomplished by adding a file LUTZKY1.BAT (BAT for MS-DOS Batch, not BAS) with these contents: @REM Turn off janky \"print each command\" behavior @REM Mind the load-bearing @ at the start of each line... @ECHO OFF QBASIC /RUN LUTZKY1.BAS I would‚Äôve needed to terminate the program using the SYSTEM command rather than END. This way, indeed typing LUTZKY1 into the prompt would‚Äôve run my program and exit normally. However: I don‚Äôt think I knew how to do that It still flashes the QBasic IDE on startup I was still relying on QBasic being installed on the destination machine, and I knew (though?) older versions of MS-DOS didn‚Äôt include it. Having things in multiple files still seemed ‚Äúoff‚Äù. I now wonder if I could‚Äôve designed a file to work both as the batch file and as the BASIC file. I had heard rumor of the ‚Äúprofessional, expensive‚Äù bit of software I needed - a compiler, which would perform the right magic to me a shiny, self-contained LUTZKY1.EXE. But this sounded like an expensive thing to even ask my parents for, never mind the fact I had no idea where one buys software - the local shops only seemed to stock games and office productivity software. Note In 2023, I found out that this software was called QuickBASIC‚Ä¶ not confusing at all, surely the Q in QBasic didn‚Äôt stand for ‚ÄúQuick‚Äù and they weren‚Äôt both abbreviated ‚ÄúQB‚Äù. For whatever reason, this was important enough to me to try some truly wacky stuff. I vaguely remember messing around blindly with files on my computer, trying to generate an EXE file complete with an icon - efforts included taking something called the ‚ÄúPIF Editor‚Äù, which creates shortcuts to files and ostensibly adds icons to them‚Ä¶ and replacing one of the system EXE files with it, in case the filename was ‚Äúmagical‚Äù. The real magic was young me learning the valuable lesson that I should‚Äôve made a backup of this file before replacing it. ","date":"2023-04-23","objectID":"/posts/software-distribution/:1:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"Visual Basic (late 90s) By the late 90s, Windows 9x came around along with Microsoft Office, which had a wonderful capability: Visual Basic for Applications. this gave me my first experience writing actual GUI applications, strangely embedded within an Excel spreadsheet. Most memorably, Pok√©mon was a huge deal at the time, and I had created ‚ÄúAPCO - A Pok√©mon Card Organizer‚Äù - a trivial deck building app. Note - Pok√©mon On April 1st, 1997, the very first episode of the Pok√©mon anime was shown on Israel, on channel 6; I was the official ‚Äúhero of the day‚Äù guest, as a Pok√©mon expert. I got to this position by nitpicking on some ‚Äúkids‚Äô portal‚Äù website that their Pok√©mon page contained inaccuracies, which landed me a job as their Pok√©mon card strategy reviewer; I was 11, so they paid me in Pok√©mon cards. For the anime premiere I was interviewed by Dana Dvorin; I have sadly been unable to find any footage of this hilariously awkward interview. Once again, I wanted to distribute this software - perhaps using this magical thing I now had access to called The Internet. And, once again, sending an excel XLS file around with a big ‚Äúclick me to start the actual program button‚Äù seemed, well, janky. Amazingly, a friend had a copy of ‚Äúreally real Visual Basic‚Äù (the coveted compiler I had heard of), and was able to convert my janky app-in-XLS to a proper shiny EXE file. Slight caveat - there was a runtime library that had to be distributed alongside it, or it wouldn‚Äôt work. This got me looking at installers. All ‚Äúserious‚Äù software was proudly using InstallShield (this was before these newfangled .MSI files - even the installer was a shiny .EXE!), but looking at a trial version left me scratching my head at how things should be organized. Finally, a self-extracting RAR file (yay shareware WinRAR) did the trick. I vaguely recall successfully uploading the finished product to some download site of the era, probably Tucows. If your software didn‚Äôt come this way in the 90s, was it even real software? ","date":"2023-04-23","objectID":"/posts/software-distribution/:2:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"Linux (early 2000s) In high school, I was first introduced to Linux. It (Mandrake 8.1) came in 3 CDs burned by a guy who couldn‚Äôt have seemed shadier if he had pulled them out of a trench-coat. Regardless, it was enlightening: How can this possibly be legally free? Wait, it just comes with a compiler? What do you mean the compiler doesn‚Äôt contain a GUI? It was a fascinating dive into understanding what my computer even is; while I was old enough to remember pre-Windows days, I had switched to Linux from Windows 981, so all of my experience with Windows was as a graphical wrapper running inside DOS. For instance, not having drive letters (A, B nor C) was wild. Note: Gentoo I didn‚Äôt spend long with Mandrake before switching to Gentoo Linux, where installing software is accomplished with the emerge command. The emerge command magically (to me, at the time) gets the software from the internet and compiles it. In my mind, I was Hackerman. In reality, it was more often ‚Äúsorry dad, you can‚Äôt use the computer today, a new version of KDE just came out and the build will take a few hours‚Äù. I stuck with Gentoo until college1, when a stack of remarkably slick-looking envelopes with Ubuntu CDs showed up. At this point Linux started seeming serious, and the ‚Äúyear of the linux desktop‚Äù meme started to get to me. Ubuntu also killed off install-fests2, as installing it was too easy to justify getting friends and pizza together. My grandma got my old PC with it, so I can proudly say my grandma is a former Gentoo user. She exclusively used the browser, but whenever she needed support I was the only one who could provide it, as any other support people invariably tried to get her to find the ‚Äústart‚Äù menu, even when the problem was entirely within gmail.¬†‚Ü©Ô∏é If anyone has footage of the install-fest I was forced to trick Moshik Afia to go to, as part of ◊§◊¢◊ù ◊ë◊ó◊ô◊ô◊ù on Yes, please send it my way!¬†‚Ü©Ô∏é As I dove deeper into Linux, I realized I‚Äôm seeing some of the older jank once again. Lots of software came as shell scripts that ran java, meaning you had to have the Java Runtime Environment installed. Python software came as scripts, which needed not only Python itself installed, but usually some additional python libraries. At this point I noticed the following: This only seems less janky in Linux because executables usually don‚Äôt have filename extensions; the difference between a ‚Äúclean .EXE‚Äù and a ‚Äújanky .BAT‚Äù is tucked away in the file contents. ‚ÄúProper‚Äù C programs also need a bunch of stuff installed along with them. The Linux ecosystem has a dizzying array of solutions to this problem. From meticulously2 packaging DEB files through FlatPak/Snap/whatever through Docker3. I‚Äôm the kind of nerd who‚Äôs excitedly following FasterThanLime‚Äôs series about how Nix presumably does this better than anything else. ","date":"2023-04-23","objectID":"/posts/software-distribution/:3:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"Afterword - the web At some point, probably too gradually for me to notice, web apps became actual apps. XMLHttpRequest is horribly named, but pretty transformative when used by sites to dynamically fetch more information; Javascript had gradually transformed to ‚Äúthe Assembly language of the web‚Äù (i.e. it‚Äôs the thing stuff compiles to4); but the really cool thing about web apps remains distribution: Just give people the URL. Yes, there‚Äôs work to do. You need a server, you need to handle its uptime and connectivity (cloud has made this effectively trivial, even more so for quick demos with things like ngrok). The app itself also needs to be written differently: updates are nontrivial, if any state is saved then backwards-compatibility becomes difficult, you need to handle different browsers (and different device types); it‚Äôs not easy. But a giant ecosystem has developed around solving these problems, and the infrastructure to use the web has become, by comparison, effectively ubiquitous. And to my 8-year-old self, there‚Äôd be nothing cooler than that: ‚ÄúForget the floppies, just give a note with your address to your classmates; it‚Äôs basically guaranteed to work on their computer‚Äù. Windows 2000 had pretty much skipped home PCs around me, and XP was new and untrustworthy.¬†‚Ü©Ô∏é The Debian New Maintainers‚Äô Guide, which explains how to do this, starts off with ‚Äúsocial dynamics of Debian‚Äù before getting into the details of actually packaging anything.¬†‚Ü©Ô∏é Sometimes described as ‚ÄúIt works on your machine? Then we‚Äôll ship your machine.‚Äù credit¬†‚Ü©Ô∏é I think compiling stuff to WASM is becoming more popular nowadays.¬†‚Ü©Ô∏é ","date":"2023-04-23","objectID":"/posts/software-distribution/:4:0","tags":["software"],"title":"Getting your code to your friends","uri":"/posts/software-distribution/"},{"categories":null,"content":"The blog has accumulated a few unrelated bits and bobs, linked here: Russian stress mark Linux stuff TTime3 ","date":"2023-01-18","objectID":"/stuff/:0:0","tags":null,"title":"Stuff","uri":"/stuff/"},{"categories":null,"content":"It‚Äôs December 2022, let‚Äôs try Rust ü¶Ä As you can tell by previous posts on this blog, I used to be quite a fan of Go; I use it at work often, and some features about it are legitimately great: Package management, ‚Äústatic duck typing‚Äù (structural typing), providing interfaces while stepping away from inheritance, all quite nice (and present in Rust). I wasn‚Äôt too unhappy with the repetitive error handling, generics are finally coming into play, and nothing I write is anywhere near performance-critical enough for me to care about GC overhead (though I did glance firmly at the binary size once in a while). But come December, as I decided to give Advent of Code a go this year, I figured I‚Äôd try to use it to learn a new language: Rust. Now, Rust has been steadily gaining popularity for a while, but two recent events caused me to pay attention: In September, a CTO from Microsoft gave Rust a significant endorsement. In that same month, Linus Torvalds effectively announced that Rust was coming to the Linux kernel. When those two agree on something, I figured, it‚Äôs probably worth paying attention. To my delight, someone else ‚Äî fasterthanlime ‚Äî was doing Advent of Code in Rust. In fact, he was doing a day-by-day ‚Äúlet‚Äôs learn rust while solving Advent of Code‚Äù series. Part 1 includes everything you need to get started, tooling and all, and a delightfully unusual introduction to file I/O which I won‚Äôt spoil. Other ways of getting started with Rust When getting started with Rust, I tried a few things out from https://www.rust-lang.org/learn, but my recommendation is this: Before installing it, before going to the book, before any of that ‚Äî go do rustlings, specifically use their Gitpod link. This will set up a free gitpod ‚Äúcloud IDE‚Äù (VSCode-based), reasonably configured for Rust, and you can get right to live exercises. Having spent some time with Rust, I now see more and more faults with other programming languages. Others have written many words about this; fasterthanlime has a couple of very detailed posts in this direction; the folks at Discord wrote a great post about switching from go to rust to eliminate GC latency. But I‚Äôd like to talk about something far, far simpler. Let‚Äôs talk about null checks. ","date":"2023-01-16","objectID":"/posts/rust/:1:0","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Things that may or may not be there My initial sense of Rust is that it involves a lot of fighting with the compiler‚Ä¶ and the compiler being right. Getting code to build is much more difficult than I‚Äôm used to, but when it builds ‚Äî it works. Not always, but with a much higher likelihood than I‚Äôve seen elsewhere. To explain this phenomenon, let‚Äôs take a look at cases when data is allowed to be absent. It is often useful, in code, to deal with something that may or may not be present. I‚Äôve recently had the unpleasant experience of dealing with soccer1 for work2; I still don‚Äôt quite get it, so this example might not make any sense, but bear with me: Let‚Äôs imagine that a soccer Team has several players (each of which is a Person with a name and age), and may or may not have a coach, who is also a Person. In JSON, that would look like this: { \"players\": [ {\"name\": \"John Doe\", \"age\": 24}, {\"name\": \"Richard Roe\", \"age\": 25} ], // Might be absent: \"coach\": {\"name\": \"Mark Moe\", \"age\": 53} } Suppose you write some code to handle such a Team, and, say, return whether or not any of the players are older than the coach. ","date":"2023-01-16","objectID":"/posts/rust/:2:0","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Go In Go, you‚Äôd probably end up doing something like this: struct Team { Players []Person Coach *Person } func (t * Team) anyPlayersOlderThanCoach() bool { if t.Coach == nil { // YOU WILL FORGET return false // TO DO THIS PART, } // I ASSURE YOU. for _, p in t.Players { if p.Age \u003e t.Coach.Age { // ...so ^^^^^^^ will sometimes crash. return true } } return false } At some point you will encounter a team without a coach, and your code will panic and exit with an error. It won‚Äôt even be a useful error message ‚Äî it‚Äôll be something like this (but probably with many more goroutines). panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x480c76] goroutine 1 [running]: main.main() /tmp/sandbox3217875017/prog.go:17 +0x16 Program exited./Op The issue is that the null (well, nil) pointer is used as a way to indicate ‚Äúsomething that is not there‚Äù, and Go ‚Äî just like C ‚Äî uses pointers both to indicate ‚Äúwe‚Äôre dealing with pointing at memory addresses‚Äù and to indicate ‚Äúwe‚Äôre dealing with something that may be absent‚Äù. Worse yet, because most teams do have coaches, this will be a rare case. It‚Äôll likely be shuffled off into the back of the bug queue as a ‚Äúrare crash‚Äù, waiting to jump on you when somehow a coach-free team makes it to the world cup finals. ","date":"2023-01-16","objectID":"/posts/rust/:2:1","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Rust Although rust does support pointers (null and otherwise), those are usually relegated to unsafe code. In day-to-day rust, indicating that a value might be absent is done using std::Option. If you were recreating the same naive approach as Go, you‚Äôd end up writing something like this: struct Team { players: Vec\u003cPerson\u003e, coach: Option\u003cPerson\u003e, } impl Team { fn any_players_older_than_coach(\u0026self) -\u003e bool { // Don't code like this, but... if self.coach.as_ref().is_none() { // This is the return false // part you will } // forget to do. let coach_age = self.coach.as_ref().unwrap().age; // ...so this part will crash: ^^^^^^^^ self.players.iter().any(|p| p.age \u003e coach_age) } } Note Yes, Rust‚Äôs support for functional-style programming blows Go‚Äôs out of the water. Yes, I‚Äôm salty. The error you‚Äôd get for forgetting to check whether coach.as_ref().is_none() is actually a bit better: thread 'main' panicked at 'called `Option::unwrap()` on a `None` value', src/main.rs:13:45 However, there‚Äôs an extremely handy smoking gun here ‚Äî unwrap itself. That‚Äôs not a function that usually gets used in production3 code. A reviewer or linter should be able to catch it. The function should actually be written like this: impl Team { fn any_players_older_than_coach(\u0026self) -\u003e bool { match \u0026self.coach { None =\u003e false, Some(definitely_a_coach) =\u003e self.players.iter().any(|p| p.age \u003e definitely_a_coach.age), // definitely_a_coach can be called \"coach\" as well, // and usually would - but it's a different variable // with a different type. } } } Importantly, the type of definitely_a_coach is not Option\u003cPerson\u003e ‚Äî it‚Äôs Person. That is, when using match (which is fairly standard), the guarantee that ‚Äúyou made sure the thing is actually there‚Äù happens at compile time. Omitting the None case is a compilation error. Note This is a great example of how Rust moves head-scratches from runtime to compile-time. It‚Äôs a big part of why it‚Äôs harder to get Rust code to build. In fact, there‚Äôs an equivalent way to write this, shorter, but providing the same safety guarantees: impl Team { fn any_players_older_than_coach(\u0026self) -\u003e bool { if let Some(definitely_a_coach) = \u0026self.coach { return self.players.iter().any(|p| p.age \u003e definitely_a_coach.age) } false // Omitting this is also a compilation error; // it won't let you forget the \"else\" case. } } Importantly, the syntax that might panic (unwrap) is quite different, easy to pick out, and does not have to be used at all. In contrast, in other languages, like Go, we don‚Äôt get the opportunity to notice that it‚Äôs happening. The coach pointer gets dereferenced using the same syntax, whether or not it‚Äôs guaranteed to not be nil. ","date":"2023-01-16","objectID":"/posts/rust/:2:2","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Other languages Haskell This seems to be equivalent to the Haskell Maybe type. If I were smart enough to code in Haskell, I‚Äôd be sure. One of the nice things about Rust is that it allows writing code in imperative style without understanding monads. Java Java 8 introduced java.util.Optional, which does the same thing as Rust‚Äôs Option. However, the safety guarantees are more limited: You can check ifPresent() and use get(), but this is no better than checking if a standard reference would be null (that is ‚Äî nothing makes sure that you did so, and if nothing is there ‚Äî get() throws an exception). Note Apparently some external inspectors do check for this, e.g. https://rules.sonarsource.com/java/RSPEC-3655 You can use orElse(defaultValue), which makes sense in some cases, but not always (what if it‚Äôs a temperature-in-celsius that might be absent? You can‚Äôt use 0¬∞ as a default value). You can use various other methods like filter and map, but that requires callback-style programming (which I don‚Äôt think is the norm for Java). At the end of the day, Java‚Äôs legacy is probably a limiting factor here ‚Äî your code likely needs to interoperate with a pile of code that simply uses null the traditional way for ‚Äúthing that is not there‚Äù. Finally, researching for this post showed at least one guide claiming the following as Misuse of Optional: Passing an Optional parameter to a method Having an Optional field (also discussed here), exactly as we‚Äôre doing here. ‚Ä¶so I guess you‚Äôre stuck null-checking for those cases. C++ C++17 adds std::optional. I haven‚Äôt tried it out, but judging from a quick read, it appears to be more robust than Java‚Äôs, but still far less safe than Rust‚Äôs: You‚Äôre still checking has_value() and risking an exception when calling value() (‚Ä¶does your codebase even allow for exceptions?), or using value_or if a sentinel value is acceptable. ","date":"2023-01-16","objectID":"/posts/rust/:2:3","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"Why does this matter? Go is often regarded as a memory-safe4 language. And that‚Äôs technically correct in this case ‚Äî if you get a null dereference, your code will simply crash, as opposed to some crazy Undefined Behavior. Presumably your production setup is resilient to crashes, and you‚Äôll catch these crashes in pre-production anyway. ‚Ä¶except, it‚Äôll take you a while to do that. And the crash will seem quite esoteric, and might not even happen in pre-production (does your test data contain teams without coaches?)‚Ä¶ and, once again, if a coach-free team suddenly plays a very popular match, are you really set up to deal with such consistent crashes? It‚Äôs possible to build automatic tooling for detecting these cases, and people far smarter than myself are already doing so. Unfortunately, applying them to legacy code is an even harder. I‚Äôve seen such a ‚Äúyou did not check for null‚Äù static analyzer completely miss a case quite similar to the above; and while we did catch it in pre-production, a lot of people wasted a lot of needless time on it. This is also only one (relatively-simple) example of what Rust does about safety. A more elaborate example is mutexes: A rust mutex ‚Äúholds‚Äù the protected data, requiring you to lock() it to even access the data. This means that the type-system guarantees that the mutex protects whatever it‚Äôs meant to protect. In Go, however, the protected value just wears the mutex as a hat ‚Äî so the compiler has no clue. (There‚Äôs at least one person porting this idea into C++) So examine your programming language; see what safety guarantees you‚Äôd like it to have (try to use the ones it already does!); and perhaps look at Rust for a bit of inspiration. Short for ‚Äî did you know? ‚Äî Association Football. I live in Ireland, which plays multiple kinds of football, so I find ‚Äúsoccer‚Äù to be the more specific term.¬†‚Ü©Ô∏é I really don‚Äôt like watching any kind of sportsball, but there was a fair bit of excitement around the recent FIFA World Cup, and my involvement extended to having to watch some of those matches. Live üôÑ. In contrast, to relax in the evenings, I did AoC ‚Äî so I effectively watch soccer for a living and code for fun.¬†‚Ü©Ô∏é Rust actually has many useful-while-prototyping functions, like todo!().¬†‚Ü©Ô∏é And people use that reasoning to build some pretty cool stuff, like https://gokrazy.org.¬†‚Ü©Ô∏é ","date":"2023-01-16","objectID":"/posts/rust/:3:0","tags":["software","go","rust"],"title":"I tried Rust","uri":"/posts/rust/"},{"categories":null,"content":"One young-child-parenting trick that has worked well for us is white noise. It might be because it emulates in-the-womb-noises, drowns out other noises, or gives baby something to fixate on - but it often does a great job of calming him to sleep. Nearly a year old now, he thankfully doesn‚Äôt usually need it for night sleeps, but it‚Äôs helpful for a ‚Äúcranky-because-tired‚Äù nap or getting him to sleep for another half-hour when he decides to wake up very early. There are quite a few ways to play white noise, and many cheap mobile battery-powered devices will do the trick just fine. However, I wanted a bit more control, at least for when we‚Äôre at home: It‚Äôd be useful to turn on the noise remotely, as entering a cranky baby‚Äôs room sometimes riles him up. It‚Äôd be useful to (gradually!) turn off the noise remotely, especially as my wife doesn‚Äôt like the sound and it can be made worse with a baby monitor. I‚Äôd like to customize the sound itself (we‚Äôre actually going for more of a pink/brown noise) After trying out several options, I went for using a Google Home Mini; we have several of those lying around (they used to come as free gifts with various purchases), the audio quality is reasonable, and it‚Äôs compact and clean-looking. Although it does respond to a ‚Äúplay white noise‚Äù command, that plays this 1-hour-long segment, which is too short. Instead, I created a 10 hour version with customized parameters like so (mostly inspired here): sox -c1 -n result.ogg \\ synth 36000 brownnoise synth pinknoise \\ mix synth sine amod 0.1 90 ffmpeg -i result.ogg result.mp3 Why is the conversion to MP3 important? See quirks. The rest is a matter of hooking it up to homeassistant. The media_player.play_media service gets it to play just fine. To make it easy to toggle, I created an input boolean and automation to start or stop media when it changes. Because the google home can also be stopped directly, I added a second automation which sets the input boolean off when that happens. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:0:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Main dashboard toggle Having the white-noise-toggle on the main dashboard (an old chromebook in kiosk mode) is quite useful, especially when babysitters are involved. (There‚Äôs also a physical button, driven by ESPHome, in the nursery - but that‚Äôs not quite remote). My wife had a great idea for styling this toggle - showing a picture of the baby awake when the white noise is off, and asleep when it‚Äôs on: type: picture-entity show_state: true show_name: true entity: input_boolean.white_noise_toggle state_image: \"off\": local/awake.jpg \"on\": local/sleeping.jpg name: White Noise tap_action: action: toggle hold_action: action: more-info The hold_action: more-info thing is quite useful, as it can quickly indicate how long the white noise was on, approximating how long the nap has been so far (assuming the white noise does its job). ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:1:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Secondary controls For additional control, in a separate tab of the dashboard, I have the following: type: vertical-stack cards: - type: entities entities: - entity: media_player.googlehome1234 type: custom:slider-entity-row icon: mdi:volume-high name: White noise volume - entity: input_boolean.white_noise_toggle secondary_info: last-changed - type: markdown content: \"Note: White noise volume is usually 40%. If it's off, it shows as 0%.\" This allows easily controlling the volume (when it‚Äôs on!), reminds us of what the ‚Äúusual‚Äù volume setting is, and also quickly displays how long ago it was last toggled. slider-entity-row is an extension, which can be obtained here. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:2:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Quirks While this setup works quite well, it has a couple of annoying quirks. Firstly, the Google Home plays a fairly loud chime before starting to play the white noise. Secondly, this involves the Google Home loading a ~300MB file. Originally I used ogg, and although it‚Äôs usually cached, in some cases this could be a ~30-second process, with no user feedback visible. I‚Äôve considered having the script play a shorter clip multiple times over, but the playback has unpleasant gaps in that case (and risks repeating that loud chime). However, it seems that when pointing to an mp3 file, audio starts playing immediately, without having to first finish downloading the whole file. The Google Home is pretty opaque about this, but experimentation seems to show this is consistent. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:3:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"Afterword Overall, this process of getting familiar with HomeAssistant and its various integrations has been delightful, with great community support and debuggability. My first thoughts were ‚ÄúI don‚Äôt need this - my projects are simple and I can code them myself‚Äù - but the plethora of readily available integrations and the polished UI has made it well worth my time learning, and making changes is a breeze. And if my child sleeps better for it, that‚Äôs a win in my book. ","date":"2022-05-21","objectID":"/posts/remote-white-noise/:4:0","tags":["software"],"title":"Remote White Noise","uri":"/posts/remote-white-noise/"},{"categories":null,"content":"I run a small home server, which - among other things - has backups of data from cloud providers, in case I lose access to them; this data is sensitive and should therefore be encrypted. However, disk encryption requires a secret, and there are - generally speaking - four ways to go about that: Store the key on the same server as the encrypted disk Store the key on detachable media, attached to the same server as the encrypted disk Store the key on a different server Store the key in your brain (this is known as a ‚Äúpassphrase‚Äù or ‚Äúpassword‚Äù) Using a separate server is a bit more complicated than I‚Äôd like to go (and is not always supported, e.g. in the free version of TrueNAS Core), and storing the key on the same server won‚Äôt protect me in case the server is stolen. For my usecase, it‚Äôs an easily burgler-accessible NUC. Detchable media will have to remain attached, as I want to be able to reboot remotely (I‚Äôve heard some interesting suggestions, e.g. ‚Äústore the key in a USB key glued to your desk so the burgler will probably just disconnect it from the server‚Äù). The last option is the simplest and most convenient, except when rebooting. When rebooting an encrypted system that uses a passphrase, you essentially have to do the following: Learn that a reboot is required (about once every 12 days on my server, for a kernel security update) Connect to the server to reboot it Wait for it to reboot Connect to the server again to input the passphrases I always hate actions with a ‚Äúwait‚Äù part to them, so I figured - wouldn‚Äôt it be nice to input the passphrases as part of the reboot process? That way I essentially shave off steps 3 and 4. The idea is to allow just the next boot to load the encrypted bits without entering any passwords, authorized by, well, someone who knows the relevant passwords. Hopefully burglars aren‚Äôt sophisticated enough to target my machine on kernel patch days. My particular system uses ZFS-on-linux with a couple of encrypted filesystems, and the following is an implementation using systemd and Go. I do think the idea is useful enough for other passphrase-encrypted systems (e.g. LUKS). The overall design is: Before rebooting, you run the go binary on the server as root. It will: Figure out which ZFS filesystems currently have a loaded key Ask for the password for those (and check that it‚Äôs correct) Create /zfs-reboot-passphrase.sh with the passphrases embedded shellescape turns out to be useful, as fmt.Sprintf(\"%q\", password) insists on using double quotes, which doesn‚Äôt prevent bash from interpreting strings. On boot, the zfs-reboot-passphrase systemd service will check if /zfs-reboot-passphrase.sh exists and run it. It will: Load the embedded passphrases and mount the relevant filesystems shred -u itself - rewrite itself with random data to prevent undeletion, and then delete itself. The specific implementation isn‚Äôt super-clean nor important, but I‚Äôm attaching it as-is (buyer beware) for completeness. Hopefully it serves as inspiration for something useful. /lib/systemd/system/zfs-reboot-passphrase.service: [Unit] Description=Mount remaining ZFS filesystems with passphrase After=zfs.service ConditionPathExists=/zfs-reboot-passphrase.sh [Service] Type=oneshot ExecStart=/zfs-reboot-passphrase.sh [Install] WantedBy=multi-user.target load_keys.tmpl: #!/bin/bash {{ range $path, $password := .}} echo {{ $password }} | zfs load-key {{ $path }} {{ end }} {{ range $path, $password := . }} zfs mount {{ $path }} {{ end }} exec shred -u $0 main.go: package main import ( \"embed\" \"flag\" \"fmt\" \"io\" \"os\" \"os/exec\" \"os/user\" \"strings\" \"text/template\" \"golang.org/x/term\" \"gopkg.in/alessio/shellescape.v1\" ) var ( //go:embed *.tmpl templatesFS embed.FS templates = template.Must(template.ParseFS(templatesFS, \"*.tmpl\")) skipPasswordCheck = flag.Bool(\"skip_password_check\", false, \"Do not check entered passwords\") outputFile = flag.String(\"output_file\", \"/zfs-reboot-passphrase.sh\", \"Write output to this file (blank is stdout)\") ) fu","date":"2022-01-26","objectID":"/posts/preload-key/:0:0","tags":["software"],"title":"Preloading disk encryption keys","uri":"/posts/preload-key/"},{"categories":["Newborn parenting software"],"content":"As noted in the previous post, I decided that the implementation is more appropriate for a microcontroller than a full-fledged computer. While the Arduino is probably the best-known microcontroller, the standard one doesn‚Äôt have wifi (the one with wifi is ~$50). The ESP8266, on the other hand, is a microcontroller chip with wifi capabilities, available1 on dev boards like the NodeMCU for about $2 apiece - so I bought a few of them. The ESP8266 is sometimes used as a wifi add-on for Arduino, but it‚Äôs quite capable as a microcontroller on its own (and the newer ESP32 is faster). So what‚Äôs the difference between a (very small) computer and a microcontroller? A Raspberry Pi boots off an SD card, usually to a full-fledged Linux operating system; you‚Äôd operate it either directly with a monitor and keyboard, or connect remotely using SSH. You can install/create software on it as you would on a ‚Äúfull-size‚Äù computer, and I usually do this in Go (although Python is more popular). Conversely, a microcontroller will usually run only one program, which you need to build on a separate computer, connect it over USB to the microcontroller board, and flash it. This has a number of advantages, including simplicity and pretty-much-instant boot. Coding for the ESP8266 can be done using the same tooling as Arduino - namely, in C++2, on the Arduino IDE. However, during this project I learned of PlatformIO, which is far more comfortable to work with: It‚Äôs integrated into VSCode, and git, auto-formatting, autocomplete and VIM keybindings all work nicely. It also provides a more organized approach to unit testing (practically absent in Arduino IDE) and per-project dependency management (you can list what each project needs and have it auto-install). This made the project fun enough for a few iterations. One quirk of working with the BabyBuddy API is that reporting a diaper change requires supplying the time of change, even if our intention is ‚Äúright now‚Äù. That‚Äôs easy enough on a Linux system, but microcontrollers don‚Äôt generally have clocks. Thankfully, libraries such as ESPDateTime provide NTP support baked right into your program. At this point, the NodeMCU version worked, and replaced the previous implementation: Poobuttons v2 - nodeMCU on breadboard Indeed, this version fits neatly onto a single (full-sized) breadboard. It‚Äôs not quite Ben Eater grade, but the NodeMCU is pretty good for breadboard mounting, and using solid-core jumpers let me make it much neater than the previous iteration. However, at this point we realized there was a missing feature: We were never quite sure if we had pressed the button, especially if we were performing a diaper change together3 . A couple of LEDs can only convey so much information. I decided to repurpose my shitty cardboard LCD case for this project. These tactile buttons have quite short feet - they don‚Äôt make it through the cardboard, and I insisted on avoiding using a perfboard and soldering iron - as, at the time, I had neither. I ultimately decided to reuse the mini-breadboard from the previous version; like many (all?) breadboards, its bottom is an adhesive pad; I didn‚Äôt even bother to remove the resistors from V1, they add a certain design flare to it. With a few iterations on the UI, it was wife-approved: Custom characters are fully supported in C++ (though, not in Go), so I got nice labels for the tactile buttons, as well as a heartbeat4 to indicate that NTP is still working. Poobuttons v3 - nodeMCU with LCD in cardboard Overall, the project has been a blast, and the result is everyday-useful. Working on it has made me realize how much I need my own space for late-night electronics projects, but that‚Äôs a project for another day. Actually available - as in, as opposed to Raspberry Pi 0w, they‚Äôre in stock in many places at the moment.¬†‚Ü©Ô∏é Unfortunately, TinyGo does not yet support wifi.¬†‚Ü©Ô∏é We call this procedure Formula 1.¬†‚Ü©Ô∏é 2nd row from the bottom, rightmost column; you can see it fading out in this sh","date":"2021-10-10","objectID":"/posts/software-parenting-3/:0:0","tags":["software","life","hardware"],"title":"Newborn parenting software - part 3","uri":"/posts/software-parenting-3/"},{"categories":["Newborn parenting software"],"content":"With BabyBuddy now installed and running properly (see previous post), and an always-on display showing the latest information, we now got into the swing of using it. We loved the timeline for ‚Äúwhat happened while I as sleeping‚Äù; we loved the food amount reports; and because we had a consistent ‚Äúfeed, then change, then wait 15 minutes with baby upright to reduce spit-up‚Äù system, the display‚Äôs ‚Äútime since last change‚Äù box was super useful as well. However, as you might imagine, we did not love handling a freshly-re-diapered baby with one hand while using the other to unlock the phone and navigate to the ‚Äúyes he pooped now‚Äù page in a web app. My first idea was to create voice commands for the Nest Home Mini in the room. However, it‚Äôs prone to misunderstanding us; you have to enunciate, and even then the speech recognition is mostly tuned to preexisting Google Assistant commands, and tends to guess that we aren‚Äôt really saying words like ‚Äúpee‚Äù or ‚Äúpoo‚Äù. Furthermore, the baby might be crying, or worse yet - lightly sleeping, at risk of being woken up by our voice (or the assistant‚Äôs). What we needed was a button (well, two - one for pee and one for poo). I had a Raspberry Pi ZeroW lying around from a previous project and decided to use it for this (the small OLED display wasn‚Äôt used for this project, but I didn‚Äôt find a good reason to take it off yet; more on that later). With bits I had from a generic ‚Äúlearn electronics‚Äù kit (which I bought for the specific purpose of having such bits), I created the user interface: Two buttons, a green LED for ‚ÄúOK‚Äù, a red LED for ‚Äúsomething went wrong‚Äù; all tied together by some jumper cables and a mini breadboard. The Raspberry Pi would handle communicating with BabyBuddy‚Äôs API (over wifi), reading the buttons, and driving the LEDs. The setup was indeed quite similar to PiTemp‚Äôs with the software written in Go, cross-compiled, and run on startup using systemd. PooButtons on Raspberry Pi ZeroW One annoying quirk with the Raspberry Pi Zero for this is that it would register phantom button presses; they‚Äôd be quite rare, fewer than 5 a day, but that‚Äôs certainly enough to mess up diaper reporting. I‚Äôm not sure if it‚Äôs something about the particular GPIO pins I used (GPIO24, GPIO22), and disconnecting the OLED display didn‚Äôt work. I ended up following the old joke: How many software engineers does it take to change a lightbulb? None, it‚Äôs a hardware problem. How many hardware engineers does it take to change a lightbulb? None, they‚Äôll fix it in the software drivers. Specifically it ended up looking something like this (with another goroutine listening on the resulting channel): const ( debounceTime = 2 * time.Second stableTime = 100 * time.Millisecond ) func listenButtons(ch chan\u003c- int) { pull := gpio.PullUp edge := gpio.FallingEdge level := gpio.Low for i, pin := range []gpio.PinIO{ pinButton1, // GPIO24 pinButton2, // GPIO22 } { n := i + 1 pin := pin go func() { for { time.Sleep(debounceTime) if err := pin.In(pull, edge); err != nil { log.Fatalf(\"Failed to set pin to input: %v\", err) } if pin.WaitForEdge(-1) { log.Printf(\"Got edge, waiting %v for stability\", stableTime) time.Sleep(stableTime) if pin.Read() == level { log.Print(\"Signal was stable, counting as press\") ch \u003c- n } else { log.Print(\"Signal did not remain stable, discarding\") } } else { log.Print(\"WaitForEdge returned false, ignoring\") } } }() } } It‚Äôs not ideal, but it seemed to work; certainly seemed like it should be library code, for someone smarter to debug. Indeed, it turns out that the periph.io library had a Debounce function to help with this, but at the time it wasn‚Äôt implemented at all (and now that I‚Äôve spent some time on it, it‚Äôs partially implemented). Ultimately, the device worked rather well, and the button pushes were quite satisfying, especially after a particularly nasty diaper change (AKA a poonami). However, it did leave a lot to be desired: The cabling was flimsy and patchy (the pins coming from the ribbon were easy ","date":"2021-10-05","objectID":"/posts/software-parenting-2/:0:0","tags":["software","life","hardware"],"title":"Newborn parenting software - part 2","uri":"/posts/software-parenting-2/"},{"categories":["Newborn parenting software"],"content":"A few months ago, I became a father. To help overcome some of the challenges of raising a newborn, I decided to employ my standard MO - software; preferably the kind where I understand what it‚Äôs doing. It‚Äôs been working well, and I learned a lot doing it - several blog posts‚Äô worth, in fact. For this story to make sense, it bears mentioning that our conditions are pretty much optimal for it: My employer provides a generous parental leave for the non-birth parent; we decided in advance to formula-feed, which allows us to share that load, which means we need to communicate about it; my partner is an early bird whereas I am a night-owl, meaning we essentially have separate shifts necessitating a handoff; and, critically, we‚Äôre the type of people who like everything being super-organized and scheduled and spreadsheet-y (calms us down, gives us an illusion of control). Furthermore, our baby is remarkably consistent, being hungry right about every 3 hours - so the question we ended up constantly asking (of each other and our phones) was ‚Äúhow long since the baby ate‚Äù. We knew in advance we‚Äôd need some sort of a baby tracking app, of which there are many. After some research, I found that few of the free ones are designed to be used from multiple devices (e.g. dad‚Äôs and mom‚Äôs phones), which is a hard requirement. We found two contenders: Baby+ and BabyBuddy. ","date":"2021-10-03","objectID":"/posts/software-parenting-1/:0:0","tags":["software","life"],"title":"Newborn parenting software - part 1","uri":"/posts/software-parenting-1/"},{"categories":["Newborn parenting software"],"content":"Baby+ Baby+ is an Android and iPhone app for tracking babies; it follows pregnancy+, which we were quite happy with (especially as, before the birth, our responsiveness requirements were looser - I‚Äôll get to that). It can track quite a few things, but not Tummy Time for one (in our case it turns out to be pretty important). Like pregnancy+, the design is very aesthetically pleasing, and it regularly shows timely, short, and useful articles for the parents. While the app does have cloud sync, it doesn‚Äôt have a web UI (it‚Äôs phone/tablet-only) nor an open HTTP API for me to reasonably code against. It does have an export function, but it‚Äôs only really intended for importing by the app itself as backup. It‚Äôs super-clunky to work with - I know because I ended up using it to perform some analysis with a spreadsheet(‚Äúhow long is the baby going between feeds‚Äù). The biggest disadvantage of Baby+ is that it doesn‚Äôt really support multiple users. From the app‚Äôs internal FAQ (only available after installing it and setting up an account): How can I use this app with my partner? You can share the app by logging in with the same email and password. If you use your device and enter data (e.g. a note) then you need to minimise or close the app for it to send the new data to the server [‚Ä¶]. Important: the app is designed to be used by on person at a a time [‚Ä¶] otherwise data can be overwritten or deleted. [‚Ä¶] allow a few mins for the data to sync (the second device should also have the app closed for a few mins at this point so it can fetch the data [‚Ä¶]). Please note that you will encounter data loss if you are using the app on two devices at the same time. I‚Äôd guess that the app basically talks to the server on startup, compares timestamps of its entire database, and downloads or uploads the entire database depending on which version is newer. The startup time checks out: Starting Baby+ on an android phone, after closing it so it syncs, takes about 7 seconds; an eternity in screaming-baby-debug-time. Furthermore, that doesn‚Äôt include sync time, and old data will be shown for a few more seconds before the sync is complete; that starts off with slight frights (‚Äúthe baby didn‚Äôt eat for 5 hours?! oh, wait, actually 1 hour‚Äù), and eventually devolves into distrusting the app. This felt like a silly problem to have; almost any web-based app would have none of these issues. Furthermore, I thought, there‚Äôs surely an open-source one where I could fix any annoyances I have myself. Indeed, that would be BabyBuddy. ","date":"2021-10-03","objectID":"/posts/software-parenting-1/:1:0","tags":["software","life"],"title":"Newborn parenting software - part 1","uri":"/posts/software-parenting-1/"},{"categories":["Newborn parenting software"],"content":"BabyBuddy BabyBuddy is an open-source web app, self-described as ‚Äúto help caregivers track sleep, feedings, diaper changes, and tummy time to learn about and predict baby‚Äôs needs without (as much) guess work‚Äù. I describe it as ‚Äúthe dumbest-sounding idea ever - sleep-deprived parents of newborns creating and maintaining baby-tracking software as a hobby‚Äù. It turns out to be wonderful, and is what we use today. It requires self-hosting (but provides a button to do that easily on Heroku), but works remarkably well. It didn‚Äôt work exactly like I wanted, but that just provided ample opportunity to hack on it. Before we could use it, I had to make it more mobile-friendly. While it technically worked on phones, it had several usability issues, which I described in #229: horizontal scrolling was needed in places; the ‚ÄúTimeline‚Äù view didn‚Äôt show a lot of the critical bits of info, requiring more clicks; the contrast was too low for sunlight; and more. Fortunately, through some wonderful collaboration from the author, I was able to quickly get it into a wife-acceptable state and transition us over from Baby+. As I hacked on the project, I added a Gitpod config and a link to the README. This allows people to hack on Babybuddy without installing any software whatsoever - everything is done through, essentially, a free tier cloud instance (on which my config will install everything needed) with a browser-builtin VSCode UI. I used this today to whip up another pull request. In addition to being quick and comfortable to use, BabyBuddy allowed me to set up two integrations that I had in mind. The first is an always-on display, essentially intended as ‚Äúthe baby clock‚Äù. It‚Äôs positioned by the couch where we usually feed, so it‚Äôs great as a feeding timer as well. I had started out with an old tablet (Huawei T3 Mediapad) running wallpanel - this is a form of ‚Äúkiosk‚Äù application, which locks the device into a mode where it always runs the browser on a particular page (the device has no other credentials on it, so it‚Äôs reasonably safe). The tablet‚Äôs battery, unfortunately, did not like that - seemingly having the screen on discharges it faster than it can charge, and after a few weeks the tablet refused to charge at all. I‚Äôve therefore switched to using an old ASUS C100P Chromebook running kiosk - this gives the benefit of having a physical keyboard, useful for entering the food amounts. The second integration I call ‚Äúpoobuttons‚Äù - a couple of tactile buttons on the changing dresser which tell BabyBuddy to mark a diaper (they are labeled ‚Äúpoo‚Äù and ‚Äúpee‚Äù). This is both easier than fumbling with a phone touchscreen and, frankly, way more satisfying. The next posts will detail the iterations of these buttons and how I built them. This has been a wonderful and challenging journey so far. I wonder what else I‚Äôll find myself building. ","date":"2021-10-03","objectID":"/posts/software-parenting-1/:2:0","tags":["software","life"],"title":"Newborn parenting software - part 1","uri":"/posts/software-parenting-1/"},{"categories":null,"content":"Here‚Äôs how to quickly determine if a USB cable is fully operational or charge-only. Purchase several identical USB gadgets that require data transfer but are cheap and therefore don‚Äôt come with their own cables; e.g. a fun microcontroller like an ESP8266. Grab a cable from your big box ‚Äòo cables that you can‚Äôt bring yourself to throw out Test it, doesn‚Äôt work - powers on, but not identified on computer. Test with two other cables, just to be sure it‚Äôs not the cable. Test all of the gadgets you got - same problem across the board. Suspect your computer; try another one. Try another OS or two. Read up about debugging the device and whether this is a known fault; identify online posts about several similar-sounding but ultimately unrelated issues. Begin to package gadgets for return/trash, nearly admitting defeat In a moment of desperation, try hooking up another micro-USB gadget to your computer. Discover that doesn‚Äôt work either. Question own sanity. Try three other cables from your big box ‚Äòo cables. One finally works with the other gadget. Try that cable with the little microcontroller. Still doesn‚Äôt work. Discover this is actually yet another cable, which looks identical to the one that does work. Become very angry. Get some brightly-colored electrical tape in two colors. Use the electrical tape to mark each and every last damned cable in the damned box, with the two colors denoting ‚Äúworked at least once‚Äù and ‚ÄúPOS cable for charging ancient crap only‚Äù You can now easily identify the fully-operational USB cables, as they will have a brightly-colored electrical tape indicating this! (if any additional unmarked micro-USB cables should appear, go back to step 14) Info This post is backported from Facebook, for the sole reason of, in August 2023, replying to this post about a device that makes it easier. ","date":"2021-09-09","objectID":"/posts/charge-only-usb-cables/:0:0","tags":["hardware"],"title":"Charge-only USB cables","uri":"/posts/charge-only-usb-cables/"},{"categories":null,"content":"Good code comments only describe why the code is (or isn‚Äôt!) doing something. When teaching coding or reviewing code, I sometimes encounter comments describing what it‚Äôs doing, and those are almost always harmful. To be clear, I‚Äôm talking about code comments, not documentation comments. This nuance is different in every language and setup, but for Go, this is it: // UsefulFunction does useful things. This is a documentation // comment, and will be displayed in godoc, IDE autocomplete, // and more. func UsefulFunction() { // this and all of the below are code comments // count visitors // // x is the visitor counter x := 0 x++ // increment x } ","date":"2021-05-02","objectID":"/posts/comments/:0:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Document ‚Äúwhy‚Äù In some code, things are done for non-intuitive reasons. It‚Äôs worth pointing that out - it makes your code easier to read for a newcomer trying to understand why it‚Äôs written that way. In this example, technically sumOfIntsWithThreshold will work absolutely correctly without its input being sorted, but it turns out that it will be faster if it is. sort.Ints(a) // improves performance; see https://stackoverflow.com/questions/11227809 x := sumOfIntsWithThreshold(a, 128) Other good ‚Äúwhy‚Äù examples are code being written in a less-intuitive way to make a particular test possible or to avoid a specific edge-case - be sure to note what those are. If a well-researched algorithm is being used, definitely add a reference to it, including the best URL you have for someone who wants a quick overview of how it works. ","date":"2021-05-02","objectID":"/posts/comments/:1:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Document ‚Äúwhy not‚Äù In some code, the reader might see something missing, a pattern apparently broken. Sometimes this is for a good reason, as keeping with the pattern would cause a bug. More specifically, you might be fixing a bug by breaking the pattern. In this example, especially if you‚Äôre removing a line sort.Strings(c), it‚Äôs a good idea to leave a comment explaining why it shouldn‚Äôt be there. func handle(a, b, c []string) {} sort.Strings(a) sort.Strings(b) // don't sort c, we need to keep its original order for foo foo(c) } ","date":"2021-05-02","objectID":"/posts/comments/:2:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Don‚Äôt document ‚Äúwhat‚Äù when it‚Äôs trivial You might be asking yourself ‚Äúwhat‚Äôs the harm in a comment if it isn‚Äôt needed. The answer is that it can be misleading; code will function correctly even if it‚Äôs out-of-sync with its comments, so comments aren‚Äôt always updated when code is changed, leading to this canonical example: // increment x by 1 x += 2 In less-trivial cases, the reader can be left scratching their head for far longer than they would‚Äôve if the comment weren‚Äôt there in the first place. ","date":"2021-05-02","objectID":"/posts/comments/:3:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Documenting ‚Äúsections‚Äù is a code smell If your code looks is divided using comments into ‚Äúsections‚Äù, it‚Äôs probably long and difficult to reason about: func ServeSite(o io.Writer) { //// Get site data //// f := os.Open(\"data.md\") defer f.Close() parser := markdown.NewParser(f) data := parser.Parse() //// Get layout data //// f2 := os.Open(\"layout.cfg\") defer f2.Close() layoutReader := awesomelayout.NewReader(layoutOpts.Defaults) // Name \"data\" is already in use\" dataOfLayout := layoutReader.Read(f2) //// Set up HTML renderer //// renderer := htmlrender.NewRenderer() renderer.SetHTMLMode(\"my-favorite-html-style\") renderer.SetCompression(\"max-compression\") renderer.Render(o, data, dataOfLayout) } This gets even messier if you don‚Äôt sneakily omit error handling. In any case, the section headers are reasonable (albeit not great) candidates for function names: func ServeSite(o io.Writer) { siteData := getSiteData() layoutData := getLayoutData() renderer := setupHTMLRenderer() renderer.Render(o, data, dataOfLayout) } func getSiteData() markdown.Data { f := os.Open(\"data.md\") defer f.Close() p := markdown.NewParser(f) return p.Parse() } func getLayoutData() awesomelayout.Data { f := os.Open(\"layout.cfg\") defer f.Close() r := awesomelayout.NewReader(layoutOpts.Defaults) return layoutReader.Read(f) } func setupHTMLRenderer() htmlrenderer.Renderer {} r := htmlrender.NewRenderer() r.SetHTMLMode(\"my-favorite-html-style\") r.SetCompression(\"max-compression\") return r } The main ServeSite function is now much easier to read. The ‚Äúsection names‚Äù are now function names, and are less likely to fall out of date. And as a bonus, the scope of many variables is reduced - so the reader doesn‚Äôt have to keep them in mind, and we can use short names for them. ","date":"2021-05-02","objectID":"/posts/comments/:4:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Don‚Äôt leave code scars around Finally, just a pet peeve - while it‚Äôs absolutely fine to ‚Äúcomment out‚Äù code while developing, you usually shouldn‚Äôt commit this to version control. I like calling these ‚Äúcode scars‚Äù: x := getMaxValue() // x = 3 handle(x) In this case, x = 3 was there for testing ‚Äúwhat if getMaxValue returns 3‚Äù. You should not commit this. However, a possible exception can be if you‚Äôre documenting ‚Äúwhy not‚Äù as above - if it comes with an explanation. ","date":"2021-05-02","objectID":"/posts/comments/:5:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"Conclusion Code is meant to be read by machines and humans, with comments generally being intended for humans to read. Therefore, all of these should be taken as guidelines rather than gospel. Hopefully this post can be of some use for people trying to reason about comment etiquette, or perhaps for code reviewers wanting to point their reviewees at a preexisting summary. ","date":"2021-05-02","objectID":"/posts/comments/:6:0","tags":["software"],"title":"Code comments","uri":"/posts/comments/"},{"categories":null,"content":"I had been looking for an excuse to mess around with Raspberry Pi for a while, and found one: I wanted a graph of temperature and humidity over time, and - while we‚Äôre at it - a nice display of those two. Technically speaking, I already have a Nest thermostat which should provide those, but it won‚Äôt display humidity and there‚Äôs no easy way to get a graph off it (besides, then I‚Äôd need another excuse for messing around with a Pi). The code for the final result is in https://github.com/lutzky/pitemp. ","date":"2021-03-14","objectID":"/posts/pitemp/:0:0","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"Stage 1: LCD and DHT Hardware: A Raspberry Pi Zero W a friend gave me (that‚Äôll become important later on) A DHT11 temperature \u0026 humidity sensor A 4x20 character LCD; apparently an HD44780 controller or compatible. This was my first time coding for hardware on the raspberry pi, and it went fairly well. ","date":"2021-03-14","objectID":"/posts/pitemp/:1:0","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"LCD quirks Getting the degree symbol (¬∞, ASCII 0xb0) was a bit of a challenge. While the official HD44780 spec shows it should be available with ‚ÄúROM Code A02‚Äù (i.e. Latin mode), it‚Äôs not clear if this can be toggled in software, and the characters my unit displayed matched ‚ÄúROM Code A00‚Äù (Japanese)‚Ä¶ mostly, that is. Some characters were malformed, and the unofficial library I used didn‚Äôt support custom characters (which the hardware seems to support). Fortunately, the Japanese ROM code had a Handakuten symbol (Ôæü, like the circle from „ÅΩ but as a separate character), which is close enough. The LCD was also quite slow to refresh, the way I was using it; any faster than 1 hz would lead to corruption, meaning that the ‚Äúsecond-by-second‚Äù clock display I wanted wasn‚Äôt feasible. Finally, the LCD unit is much, much large than the Raspberry Pi Zero, and has to be wired awkwardly to it. With some covid-lockdown-induced creativity, a twist tie, and a bit of sewing thread (!), I turned the box it came in into a ‚Äúcase‚Äù. LCD in a cardboard box ‚Äúcase‚Äù ","date":"2021-03-14","objectID":"/posts/pitemp/:1:1","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"Cross compilation While the Pi Zero is certainly capable of being a fully-fledged Go development environment, it‚Äôs not a fast one (and me using a cheap old SD card isn‚Äôt helping). I got a much faster edit-compile-run loop by working on my main laptop, cross-compiling for ARM, and scp-ing the result over. That‚Äôs despite Go‚Äôs hefty statically-build binaries (7-12MB for these, depending on stripping). Cross compiling is done like so (e.g. in a convenience script): sudo apt install gcc-arm-linux-gnueabi export CC=arm-linux-gnueabi-gcc CGO_ENABLED=1 GOOS=linux GOARM=6 GOARCH=arm go -o main.arm build main.go For build-and-run-on-save, this can be used with entr. However, because you can‚Äôt modify an executable file as it runs (in this case), you need to use a temporary file. On my laptop, I run: find | entr -c -s \"./build.sh \u0026\u0026 scp main.arm TARGET-MACHINE:main.arm.new Then, on the pi, I run: ls main.arm.new | sudo entr -r -c -s \"cp main.arm.new main \u0026\u0026 exec ./main\" ","date":"2021-03-14","objectID":"/posts/pitemp/:1:2","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"Stage 2: PiOLED I looked for a not-so-ridiculously-large display, and found adafruit‚Äôs PiOLED to be perfect. Its HAT form factor makes for a much tidier device, and the display itself is reminiscent of the 2007 Sansa Clip m300 (albeit monochromatic). Library support is also much better, thanks to http://periph.io. That being said, my friend soldered the Pi‚Äôs pins on ‚Äúdownwards‚Äù, as this is apparently more convenient when using it on a breadboard. I figured it‚Äôs time to order my own Pi Zero (you can get them with the pins pre-soldered, facing ‚Äúup‚Äù); I later found that this might be configurable, but it‚Äôd still be pretty awkward. The PiOLED library (actually periph.io‚Äôs ssd1306 library) essentially lets you render an image.Image; since these are also trivially renderable to PNG, I could speed up development even further by adding an HTTP endpoint to serve the current image, even if the hardware isn‚Äôt present; this also let me zoom into the rendered image instead of squinting at the actual display, making it easier to align things pixel-by-pixel. I eventually ended up separating the code into two binaries - pitemp would communicate with the sensors and provide an HTTP endpoint, whereas pitemp_pioled (and pitemp_lcd) would communicate with pitemp and the physical display (or run in --simulator mode on my laptop, for HTTP-endpoint-only rendering). I‚Äôm quite happy with the final result: PiTemp with PiOLED Happy hacking! ","date":"2021-03-14","objectID":"/posts/pitemp/:2:0","tags":["hardware","software"],"title":"PiTemp","uri":"/posts/pitemp/"},{"categories":null,"content":"This is as good a time as any to give a quick tour of my ‚Äúhomelab‚Äù or server drawer. The external view is rather innocuous: A visually inoffensive Nest Wifi, a rather elegant Nest Thermostat (shame that the display can‚Äôt be always-on), and the gorgeous Nintendo Switch dock cover my partner got me. The TV aerial is tucked to the back, a reasonable compromise between ‚Äúgets reception‚Äù and ‚Äúhidden away and ugly‚Äù. The TV is mounted on upside-down IKEA boxes which we painted to roughly match the rest, hiding some botched carpentry behind the TV. External view You may note some cables heading down through a hole in the woodwork (yeah, I could probably make them a bit neater on the way down): Through the hole When opened, the drawer shows the Virgin Media router (in Modem Mode), hooked up to the Nest Wifi and back into a small switch. The TV is hardwired in, and so is the NUC i3 media server (‚ÄúMichael‚Äù, replacing the previous server ‚ÄúGeorge‚Äù). The NUC is wearing a 4TB USB HDD as a hat. Everything is quite low-powered, and Michael usually hovers around 42¬∞C. Top view Finally, here‚Äôs how everything is powered. The guy who built it thought 10 sockets (8 in the drawer, 2 behind the TV) was overkill. It was not. Power view ","date":"2021-01-03","objectID":"/posts/server-drawer/:0:0","tags":["networking"],"title":"Server drawer","uri":"/posts/server-drawer/"},{"categories":null,"content":"2020 being what it is, I‚Äôve been working from home for quite a while. We decided to convert our spare bedroom into a home office, and I realized how nice it is to have a proper desk at home, even for non-work stuff (I haven‚Äôt had one in over 10 years!). That being said, wifi is a challenge with the apartment‚Äôs structure. (Diagram below is approximate; I‚Äôll explain why and how it was created in a bit.) Approximate apartment structure; explanation on how and why it was created coming in a bit. My broadband comes in via a cable connection in the living room - the modem and router/AP sit in the bottom middle of the room. Before WFH times we would occasionally work from home, mostly from the living room, which was the only place with chairs. To get wifi in the bedrooms (one of which is now labeled ‚Äúoffice‚Äù), I used a TP-link powerline pack - i.e. one thing stuck to a power socket by the router in the living room, and another in the bedroom. Or the hallway. The tradeoffs were these: We wanted to have it as close to the bedroom as possible, so we‚Äôd have good reception there. Having it in the bedroom let us hard-wire the TV to it. It‚Äôd have better performance the closer it was to the living room. While I‚Äôm not sure what the electrical topology of my apartment is, the further from the living room it got, the worse its ‚Äúreception‚Äù got - i.e. the slower and less reliable its communication with the one in the living room would be. So for the most part, it worked. We‚Äôd get the odd disconnections or slowness, but it was used mostly on our phones, so we could switch wifi off (or, better yet, just go to sleep or get out of bed). There was one annoying issue though - roaming never worked right. Giving the powerline wifi network a different name worked OK, but we‚Äôd have to manually switch networks; especially on my partner‚Äôs iPhone, which tends to be ‚Äústicky‚Äù (and requires more taps to switch wifi networks to boot). Giving the powerline wifi network the same name (SSID) and password worked OK for roaming most of the time, but not always - and now it was quite difficult to tell, when a problem occurred, if it was due to our phones looking for the wrong AP; turning wifi off and on again didn‚Äôt always fix this. Working from home, connectivity suddenly became important. We have a ton of video meetings, we‚Äôre using our laptops all day, and sometimes we need to move around quickly - we can‚Äôt both have meetings in the home office, so one of us needs to switch to the living room table and have the connection work with minimal extra fiddling. I decided two get a two-pack of Nest Wifi devices (a Router and a Point). Over time, I found a third one was necessary, and still doesn‚Äôt always work quite right. Unfortunately, running ethernet to the home office isn‚Äôt currently a possibility (‚Ä¶but should definitely be a priority for any renovation). After some messing around, I came up with a solution, but figured I‚Äôd try and understand if I can do better by analyzing the apartment. So, step 1 - I needed a floor plan. I do not have one of my apartment, but the 3D visualization the realtor provided was still up and had a ‚Äúmeasurement‚Äù tool. So I went to http://floorplanner.com and used that visualization to sketch up the diagram above. The point of this was the next step: In a wonderful company-internal talk about home wifi (this is a common issue in Israel, where many apartments have concrete-walled shelters), the neat mapping capability of Unifi‚Äôs controller software was shown. While I don‚Äôt own any Unifi gear, I installed the controller software (available as a neat docker container), imported my diagram, drew the walls, and positioned my living room router. Router in the living room This is, naturally, only an estimate; the AP model is wrong, the -64dBm client sensitivity is just a guess, as are the wall widths and materials; reflections also aren‚Äôt taken into account (and I suspect the Nest Wifi is making good use of those). The washing machine and dryer in t","date":"2020-12-10","objectID":"/posts/wfh-wifi/:0:0","tags":["networking"],"title":"WFH Wifi","uri":"/posts/wfh-wifi/"},{"categories":null,"content":"In the 90s, my family (along with much of the rest of the world) filmed a lot of home videos. At some point we converted them to what we believed to be DVD for preservation and ease-of-access, but this was actually VCD (which has somewhat worse compatibility), burned on CD-R (which degrades faster than you might think), and optical media has pretty much become extinct as well. In a family visit in 2018 I found the old stash of original video cassettes, flew them with me from Israel to Ireland, and got a local shop called DVD Centre to re-rip them - these guys provide the great service of uploading directly to Dropbox. I‚Äôve been spending some sporadic time on weekends rewatching all of these, cataloguing them into what Googlers call a ‚Äúone-pager‚Äù - a long document that may span many pages if printed out, but can be loaded by normal software with simple search functionality (a Google Doc, in my case). This is great for searching by name or event to more easily locate the right video. The tapes are still quite long though - usually 1-2 hours, and can be logically split into smaller segments. They also often have audio issues, such as audio only coming out of one side or having very inconsistent volume. For the last few weekends (2020 is a weird year that gives me more time to do this kind of thing), I‚Äôve been working my way through the videos, correcting audio and splitting them into smaller logical chunks. I‚Äôve uploaded them to Google Drive and shared with my family, who can now easily access them right from their phones from a different continent. It‚Äôs been bringing back many memories and feels like a worth preservation effort for these memories. Here‚Äôs my workflow, in case it‚Äôs useful for anyone else: ","date":"2020-11-07","objectID":"/posts/editing-old-family-videos/:0:0","tags":null,"title":"Editing old family videos","uri":"/posts/editing-old-family-videos/"},{"categories":null,"content":"Audio corrections First, split the audio stream into a separate file so you can modify it with the software of your choice. I use ffmpeg for this. The ffprobe program lets me determine the current audio type, which is aac in my case, so I do: ffmpeg -i ORIGINAL_VIDEO.mov -vn -acodec copy output-audio.aac Now I open output-audio.aac in Audacity, and perform: If only one audio stream is available, downmix stereo to mono so it at least comes out of both speakers. (Tracks -\u003e Mix -\u003e Mix Stereo down to Mono) Normalize, to get the baseline audio levels comfortable (Effects -\u003e Normalize) As a personal choice, to get the audio levels consistent, I apply extremely aggressive compression - Effects -\u003e Compressor, lowest possible threshold (-60 dB here), maximal possible ratio (10:1), attack time of 0.2 seconds and release time of 1.0 seconds. This destroys any dynamic range, but the forced consistency of audio levels helped me pick up what people are saying - they were being recorded from various distances at varying noise levels. There‚Äôs a lot more processing you can do here (graphic equalization may be a good idea), but the ones I described worked well as ‚Äúcatch-all‚Äù fixes that I could apply to all audio without thinking about it too much. Export this in the same audio format (again, aac in my case - I‚Äôd use ffprobe on the original to see the approximate bitrate, but it‚Äôs not necessary to match it precisely), and recombine like so: ffmpeg -i ORIGINAL_VIDEO.mov -i output-audio-fixed.aac -c:v copy -map 0:v:0 -map 1:a:0 ORIGINAL_VIDEO_sound_fixed.mov This method was both faster and more flexible than using the video editors I have at my disposable. ","date":"2020-11-07","objectID":"/posts/editing-old-family-videos/:1:0","tags":null,"title":"Editing old family videos","uri":"/posts/editing-old-family-videos/"},{"categories":null,"content":"Splitting video Note from the future (2021-12-25): LosslessCut does a far better job of this than my hacky scripts, and is far easier to use. At this point, I watch the video through, writing down key points of what‚Äôs going on with approximate time-codes. It helps to do 3-4 different tapes of this before moving forward, as it gives you a feel for what the ‚Äúlogical separation‚Äù to smaller chunks is. I usually define those chunks as ‚Äúdifferent set of consecutive days‚Äù (usually just one), but it helps to have all the timecodes available in text so you don‚Äôt have to re-watch. I recommend using a player that supports faster-than-realtime viewing, such as VLC (speed up, stop on ‚Äúhey what was that‚Äù, rewind, watch at regular speed). This is the most time-consuming part. After this, I decide on the section structure, and need to determine the precise frames where I want to split. Since most video players aren‚Äôt designed to ‚Äúgo back one frame‚Äù, I actually open the video in a video editor (the free HitFilm Express, in my case). I start with the rough time-codes from the previous step, and step frame-by-frame back-and-forth until I find the first and last usable frames of a section. I write these to a points.txt file with the following syntax: 00:00:00:00-00:15:48:13 00:15:50:17-00:40:14:01 ... Here, the format is Hour:Minute:Second:Frame - in my case the video is 25 FPS, so Frame is between 00 and 24. Next, I want to split the video using ffmpeg - this can be done without recoding, which is much faster (on my laptop - a few seconds per section, as opposed to multiple minutes) and doesn‚Äôt degrade quality. For the timecodes above, the correct split commands are: ffmpeg -ss 0:00:00.000 -i audio_corrected.mov -to 0:15:48.520 -c copy segment_1.mov ffmpeg -ss 0:15:50.680 -i audio_corrected.mov -to 0:24:23.360 -c copy segment_2.mov These are annoying to create manually, because: The timecode for ffmpeg is given in milliseconds, so 13 frames in 25fps becomes 520 milliseconds. The -to offset is from the section‚Äôs start (so it‚Äôs more of a -length), and subtraction is hard. So, of course, I wrote some code to do this for me. It takes a points.txt as described above, and outputs the appropriate series of commands. All that‚Äôs left to do is to let the commands run, upload the videos, and wait for Google Drive‚Äôs video-rendering to catch up. Good luck on your video preservation adventure! ","date":"2020-11-07","objectID":"/posts/editing-old-family-videos/:2:0","tags":null,"title":"Editing old family videos","uri":"/posts/editing-old-family-videos/"},{"categories":null,"content":"When presenting SRE postmortem culture, and the importance of its blamelessness, I always find it useful to present its antithesis. As it‚Äôs often-claimed that the Eskimo have many words for snow, my home country of Israel has a word for covering one‚Äôs ass - ◊õ◊°◊™\"◊ó, pronounced /kastaÃÅœá/, an abbreviation of ◊õ◊ô◊°◊ï◊ô ◊™◊ó◊™. This abbreviation is impressively conjugatable; for example, the term ◊û◊õ◊ï◊°◊™\"◊ó roughly corresponds to ‚Äúappears as though it was made while covering one‚Äôs ass‚Äù. I have it on good authority that the italian term ‚ÄúParaculo‚Äù is closely related. Ori Katz‚Äôs blog post provides a wonderful introduction to this concept. I bring this translated version before you as a warning example of the importance of blame-free culture. Notes in (OL:) are translator‚Äôs notes. I have attempted to represent the original (Hebrew) post as accurately as possible. ","date":"2019-07-12","objectID":"/posts/asscover/:0:0","tags":null,"title":"Ass-cover","uri":"/posts/asscover/"},{"categories":null,"content":"The translated blog post One of the common and erroneous beliefs is that the primary business of people responsible for something - be they politicians, military commanders, civilian managers etc. - is managing the thing they‚Äôre responsible for. This belief is fed by the illusion of control, which has us overestimating the importance of conscious actions of people as reasons for things that happen, and underestimating blind luck and circumstances that are outside the control of those involved. The truth is that many things happen for no reason, by chance. A commander might make all the correct decisions in battle, but still lose due to an error in judgement by his superiors or subordinates. A businessperson might make the worst possible decisions, and still turn a profit because the entire field of his business has had an impressive profit surge due to an external reason, or because a competitor went bankrupt. A minister can make correct decisions that would only affect the following term of office, and be criticized for decisions made by his predecessor or a global economic crisis outside of their control. Therefore, in many cases the best managers, politicians and commanders (and anyone else who manages anything) are those who excel at the following task: Make the bad things that happened during their shift look like someone else‚Äôs fault, as external circumstances outside their control or bad luck, and make the good things that happened during their tenure look like they happened thanks to them. Truly, many of the managers I‚Äôve met are experts in this matter - the ass-covering ability. Ass-covering is far more than military slang intending to describe amusing phenomena. Ass-covering is the way a world works when there‚Äôs uncertainty about people‚Äôs ability to properly perform their job; when there‚Äôs no way to accurately measure the output of most people in most professions, especially higher-ranking ones, and it‚Äôs impossible to separate individual contributions from external influences. Ass-covering is the way our world works. Many things which seem as though they shouldn‚Äôt exist in a logical world with rational humans have their roots in ass-covering. For example, recruitment screening agencies. If there are ten measures of stupidity in the business world, recruitment screening agencies have taken at least eight upon themselves1. Upon first exposure to the phenomenon, people are astounded by its scope, the superficiality of the tests and interviews, and the cheap psychology behind the whole matter. The truth is that recruitment screening agencies exist for a very good reason: it‚Äôs difficult to find good employees. People (especially those who read my post on the matter) don‚Äôt represent themselves fairly during job interviews, school grades don‚Äôt accurately predict the required traits for an excellent employee, and ultimately hiring a new employee is always a wager. And once there‚Äôs uncertainty, ass-covering slithers its way in. When an HR officer at a certain company needs to hire new people, they can make this wager themselves, or they can send them to one of the recruitment screening agencies. There, the potential employees will pass a variety of tests which, as is known for decades, predict next-to-nothing; they will be asked to draw trees in order to see that they draw pretty and optimistic trees; to fill in blanks such as ‚Äúthe child was sad when ‚Ä¶‚Äù (recommended: ‚Äúwhen an analyst at the recruitment screening agency decided he wasn‚Äôt a good fit for the job, and he was forced to kill them‚Äù), et cetera. If the candidates turn out to be bad employees, the HR officer can always say ‚Äúthey passed ScreenAgent‚Äù. It isn‚Äôt their responsibility. In his book ‚ÄúRationality, Fairness, Happiness‚Äù, economics nobel laureate Daniel Kahneman describes tests he performed decades ago on IDF officer‚Äôs course candidates (it‚Äôs possible the same tests are being performed today). He and his colleagues gave soldiers various tasks, and observed which ","date":"2019-07-12","objectID":"/posts/asscover/:1:0","tags":null,"title":"Ass-cover","uri":"/posts/asscover/"},{"categories":null,"content":"Appendix: Related terms I highly recommend understanding the related term ‚ÄúSentry Syndrome‚Äù (◊™◊°◊û◊ï◊†◊™ ◊î◊©\"◊í), explained in the Wikipedia entry for Night of the Gliders. A related slang term to ◊õ◊°◊™\"◊ó/Kastach/Asscover is ◊ë◊ú◊™\"◊ù/Baltam. It‚Äôs an abbreviation of ◊ë◊ú◊™◊ô ◊û◊™◊ï◊õ◊†◊ü, or ‚Äúunplanned‚Äù, but is used as a noun (one Baltam, many Baltamim), representing an unexpected event that throws a wrench in your plans. This is often the result of poor planning, possibly as a result of lack of taking responsibility due to ass-cover. The presence of these within blameful culture also necessitates additional ass-covering, altogether creating the ◊ë◊ú◊™\"◊ù-◊õ◊°◊™\"◊ó cycle. OL: This is a Talmud reference. Originally: ‚ÄúTen measures of beauty descended to the world, nine were taken by Jerusalem.‚Äù¬†‚Ü©Ô∏é OL: Lieutenant Commander, the 4th rank of officers in naval terminology.¬†‚Ü©Ô∏é OL: For those familiar with the font, the signature was originally in Guttman Yad Brush; the signature is represented in Comic Sans, an appropriate approximation.¬†‚Ü©Ô∏é ","date":"2019-07-12","objectID":"/posts/asscover/:2:0","tags":null,"title":"Ass-cover","uri":"/posts/asscover/"},{"categories":null,"content":"Now that we‚Äôre done yak shaving, we can start talking about mutation testing. As an engineer at Google, I often use the Go programming language (which I really enjoy), so that is my choice for these examples; however, mutation testing is available for other languages. ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:0","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"Constructing Bolson people Let‚Äôs start with an example; we have a people package, where a person has an age and a name. For these people to be appropriate for our quest, they need to be over 18, have names with at least two whitespace-separated words in them, and have those names end with -son. You can claim those are the strangest software project requirements you‚Äôve ever had all you want, I know better. package people import ( \"strings\" ) type person struct { name string age int } func checkAge(p person) bool { return p.age \u003e 18 } func checkValidName(p person) bool { return len(strings.Fields(p.name)) \u003e 1 } func checkBolsonPolicy(p person) bool { return strings.HasSuffix(p.name, \"son\") } func validatePerson(p person) bool { return checkAge(p) \u0026\u0026 checkValidName(p) \u0026\u0026 checkBolsonPolicy(p) } Now, validatePerson performs the overall validation, but we‚Äôve split it into smaller check* functions to make them simple to test independently, in case the requirements get more complicated in the future. Here are the tests: package people import \"testing\" type testSet []struct { person person want bool } func runTestSet(t *testing.T, check func(person) bool, tests testSet) { t.Helper() for _, tc := range tests { got := check(tc.person) if tc.want != got { t.Errorf(\"check(%#v) = %t; want %t\", tc.person, got, tc.want) } } } func TestCheckAge(t *testing.T) { runTestSet(t, checkAge, testSet{ {person{age: 5}, false}, {person{age: 17}, false}, {person{age: 19}, true}, }) } func TestCheckValidName(t *testing.T) { runTestSet(t, checkValidName, testSet{ {person{name: \"\"}, false}, {person{name: \"Ohad Lutzky\"}, true}, {person{name: \"John J.J. Schmidt\"}, true}, }) } func TestCheckBolsonPolicy(t *testing.T) { runTestSet(t, checkBolsonPolicy, testSet{ {person{name: \"Hudson\"}, true}, {person{name: \"Rhondson\"}, true}, {person{name: \"Eriksen\"}, false}, }) } func TestValidPerson(t *testing.T) { runTestSet(t, validatePerson, testSet{ {person{\"Rito Fryson\", 19}, true}, {person{\"Greyson\", 20}, false}, {person{\"Zora Kapson\", 15}, false}, }) } Running go test -cover will show us that we have 100% test coverage! Hurray! However, danger lurks. In a couple of months, a newcomer to the team will refactor validatePerson to add logging indicating why a person is considered invalid, all the tests will pass‚Ä¶ and suddenly one ‚ÄúChristian Eriksen‚Äù is counted by the system as valid. How can this be? All the tests still pass, and we had 100% coverage! ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:1","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"Using mutation testing Let‚Äôs see if mutation testing can help us out. I put my code in $GOPATH/src/github.com/lutzky/people, so I install and run zimmski/go-mutesting: $ go get -v github.com/zimmski/go-mutesting $ go-mutesting github.com/lutzky/people/... PASS \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.0\" with checksum 252162809c884e5616872b71196c90df --- /home/lutzky/gopath/src/github.com/lutzky/people/people.go 2018-08-05 00:13:44.333319200 +0100 +++ /tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.1 2018-08-05 10:15:30.013388991 +0100 @@ -22,5 +22,5 @@ } func validatePerson(p person) bool { - return checkAge(p) \u0026\u0026 checkValidName(p) \u0026\u0026 checkBolsonPolicy(p) + return checkAge(p) \u0026\u0026 checkValidName(p) \u0026\u0026 true } FAIL \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.1\" with checksum 996748ab09eeca8feb3f87ecf23b8319 PASS \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.2\" with checksum 7be514fe57e53f4d02ce1e128641333f PASS \"/tmp/go-mutesting-036340603//home/lutzky/gopath/src/github.com/lutzky/people/people.go.3\" with checksum 88a83b2731fda42ae4f3ac9350191c9f The mutation score is 0.750000 (3 passed, 1 failed, 0 duplicated, 0 skipped, total is 4) What the mutation testing package does is take the test-covered code (all of people.go, in our case) and attempt to modify it at random, so that it will still build, but the logic will change; things like removing statements, changing conditions in if statements, or in this case - changing an arbitrary boolean value to true. If the code is correct and tested properly, any such mutated version of the code (‚Äúmutant‚Äù) should not pass the tests (the tests should ‚Äúkill the mutant‚Äù). In this case, it appears that modifying checkBolsonPolicy(p) to true (which is the same as just removing it and the preceding \u0026\u0026) does not cause any tests to fail. Indeed, in TestValidPerson, none of the test cases violate the Bolson policy! If we try adding a test case person{\"Bob Rasmussen\", 15} this mutant would still survive, as checkAge(p) would return false; so we have to make sure checkBolsonPolicy on its own is sufficient to identify this test case as invalid. Indeed, adding person{\"Bob Rasmussen\", 19} to the test cases for TestValidPerson gets a mutation score of 1.0, fixing our problem. ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:2","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"Drawbacks Mutation testing can sometimes be noisy. For example, if we write validatePerson like so: func validatePerson(p person) bool { result := true result = result \u0026\u0026 checkAge(p) result = result \u0026\u0026 checkValidName(p) result = result \u0026\u0026 checkBolsonPolicy(p) return result } ‚Ä¶then the following mutant would survive: --- bla 2021-05-09 15:57:12.242530400 +0100 +++ bla 2021-05-09 15:57:12.242530400 +0100 @@ -23,7 +23,7 @@ func validatePerson(p person) bool { result := true - result = result \u0026\u0026 checkAge(p) + result = true \u0026\u0026 checkAge(p) result = result \u0026\u0026 checkValidName(p) result = result \u0026\u0026 checkBolsonPolicy(p) I would treat this mutant possibility as very ‚Äúmeh‚Äù. So much like you shouldn‚Äôt necessarily fail your build if coverage is less than 100%, you probably shouldn‚Äôt fail your build if the mutation score is less than 1.0, and quite likely not based on the mutation score at all. It would help if there were a way to annotate lines as ‚Äúdo not mutate‚Äù. While zimmski/go-mutesting does support blacklisting of specific mutants, these blacklists are based on the checksum of the mutated code, which would have to be updated every time the tested code changes. Happy testing! ","date":"2018-08-05","objectID":"/posts/mutation-testing/:0:3","tags":null,"title":"Mutation testing in Go","uri":"/posts/mutation-testing/"},{"categories":null,"content":"I‚Äôve been planning to write a blog post about Mutation Testing, and finally got around to it a couple of weeks ago. I set up my example, and looked to some publicly-available mutation testing tools for my programming language of choice, Go (I get to use it quite often as an engineer in Google). The best-maintained one appears to be go-mutesting, so I figured I‚Äôll try it out. Unfortunately, I ran into a build issue with one of its depdencies: ../../../github.com/zimmski/osutil/capture.go:79: cannot assign to _Cmacro_stderr() ../../../github.com/zimmski/osutil/capture.go:79: cannot assign to _Cmacro_stdout() ../../../github.com/zimmski/osutil/capture.go:103: cannot assign to _Cmacro_stderr() ../../../github.com/zimmski/osutil/capture.go:103: cannot assign to _Cmacro_stdout() Yak shaving time! This was covered in zimmski/osutil#8, which showed it was an incompatibility with Go 1.10. ","date":"2018-08-04","objectID":"/posts/ioutil-yakshave/:0:0","tags":null,"title":"The osutil yakshave","uri":"/posts/ioutil-yakshave/"},{"categories":null,"content":"Testing the issue It turns out there‚Äôs a really convenient way to check this using Docker (which I finally took the time to learn for the umpteenth iteration of the show downloading stack): docker run -it --rm golang:1.9 go get -v github.com/zimmski/osutil This will download a minimal image for getting (using git), building, and running Go code, extract it, get the zimmski/osutil package, run the tests (successfully), and clean up after itself, leaving no trace on your system other than the cached base image for golang:1.9. Change the 1.9 to a 1.10 and the process will be identical, except for the version of Go, and fail. In my opinion that‚Äôs pretty astoundingly convenient, especially as the whole thing takes just under 38 seconds. We‚Äôre cheating here, of course - docker needs to be preinstalled, and you could solve this in other ways (e.g. gvm). However, docker is pretty ubiquitous nowadays (Google Cloud Shell conveniently includes it), and this method does have the benefit of testing on a completely clean image (no surprise dependencies). We can use a similar technique to test our fix, once we have it: On the host, go get github.com/zimmski/osutil, and from the downloaded directory, run: docker run -it --rm -v $PWD:/go/src/github.com/zimmski/osutil golang:1.10 \\ bash -c \"cd /go/src/github.com/zimmski/osutil; go get -t -v; go test -v\" This will mount the current directory into the GOPATH of the docker image (conveniently at /go), get the required dependencies, and run our tests. You could modify this one-liner to not remove the image every time, but seeing as it only takes 7 seconds on consequent runs, I didn‚Äôt bother. ","date":"2018-08-04","objectID":"/posts/ioutil-yakshave/:0:1","tags":null,"title":"The osutil yakshave","uri":"/posts/ioutil-yakshave/"},{"categories":null,"content":"The issue and the fix The root cause here is in capture.go, which provides the Capture and CaptureWithCGo functions. These get a func() callback, capture whatever it outputs to stdout and stderr, and return them as a string. The Capture function only works with pure Go code, and CaptureWithCGo is meant to support code that includes CGo as well. The latter assumes that the CGo code would use the C stdout and stderr globals (which are FILE * pointers which are used by printf and fprintf), so it creates a pipe and points stdout and stderr at it. This has two problems: Assigning to stdout and stderr is no longer allowed in Go 1.10 (and, according to golang/go#25221, was never intentionally allowed). Functions could output to standard output and error in other ways, such as calling external programs or using the write system call. This is true for the Capture function as well, but I wanted to modify as little behavior as possible. Technically, the behavior-preserving solution could be to just use freopen instead, but I didn‚Äôt know about it at the time. In general, capturing output using redirects seems to me like it should capture all output, regardless of how it‚Äôs generated. To accomplish this, let‚Äôs first have a look a how shells accomplish redirects. $ strace -f bash -c '/bin/echo hello \u003e /tmp/redirected' ... [pid 20210] openat(AT_FDCWD, \"/tmp/redirected\", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3 [pid 20210] dup2(3, 1) = 1 [pid 20210] close(3) = 0 [pid 20210] execve(\"/bin/echo\", [\"/bin/echo\", \"hello\"], 0x556c1736e260 /* 30 vars */) = 0 ... Here, strace runs a parent bash process (pid 20209, not shown in the trace above), which forks into PID 20210 which ultimately ends up running /bin/echo (and not the echo bash builtin). To accomplish the redirect, bash does the following: Open the requested file, which ends up being file descriptor 3. Use the dup2 system call to overwrite file descriptor 1 (standard output) with the same file descriptor as 3. Now this open file has two descriptors pointing at it. Close file descriptor 3; this reduces the number of file descriptors pointing at /tmp/redirected back to one. Finally, uses execve to replace the running program with /bin/echo, which will (as always) output to file descriptor 1, which now points to /tmp/redirected. No matter how echo internally causes output to appear (even if it ran yet another binary), the output would always go to /tmp/redirected. It‚Äôs worth mentioning that the dup system call is similar to the dup2 system call, but the caller doesn‚Äôt choose the destination file descriptor; instead, the first available file descriptor is used and returned. This technique is the basic one behind the fix. The old method was, roughly: Save the old os.Stdout, os.Stderr, C.stdout, and C.stderr objects Open a pipe - this gets you two file descriptors (w.Fd() and r.Fd()) Point the Go objects os.Std{out,err} at w.Fd() by just assigning w to them Point the C objects C.std{out,err} at w.Fd() by opening it with fdopen and assigning the result to them. (This no longer works) Call the callback function Copy from the r end of the pipe to a buffer using io.Copy. When the method returns (using defer), restore the four objects we saved The new technique is, roughly: Use syscall.Dup to save file descriptors 1 and 2 (standard output and error) Open the pipe as before Use syscall.Dup2 to overwrite file descriptors 1 and 2 with w.Fd() When the method returns, restore the original file descriptors Call the callback function Close all instances of the w end of the pipe Copy from the r end of the pipe to a buffer using io.Copy. WHen the method returns, restore the original file descriptors 1 and 2 When closing all instances of the w end of the pipe, this means w.Fd(), syscall.Stdout, and syscall.Stderr. If any of those three stays open, the underlying file descriptor will still count as open, and io.Copy will never return. To demonstrate this, let‚Äôs take a look at a simplified version (no error handling, don‚Äô","date":"2018-08-04","objectID":"/posts/ioutil-yakshave/:0:2","tags":null,"title":"The osutil yakshave","uri":"/posts/ioutil-yakshave/"},{"categories":null,"content":"My native language, Hebrew, has a useful term - the ‚ÄúMatzliah‚Äù method. It‚Äôs documented in a hebrew wikipedia entry, but my translation can‚Äôt make it past the draft stage. I‚Äôll add my translation here for posterity: The ‚ÄúMatzliah‚Äù (Hebrew: ◊û÷∑◊¶÷∞◊ú÷¥◊ô◊ó÷∑) method is a common phrase in Hebrew slang, translating roughly as ‚ÄúWorks‚Äù, which describes exploitation of other people‚Äôs lack of attention, and capitalization on their account. Its name is based on a joke, which tells of a restaurant customer, who discovers a charge for an item called ‚ÄúMatzliah‚Äù, which they don‚Äôt remember ordering. To the question of what dish this is, the waiter responds: ‚ÄúIf the customer pays, it works (matzliah)‚Äù. In its most common and most negative description, the method exists between two parties who have a business or other relationship. It is based on premeditated and hidden dishonesty, and includes an attempt of one side to perform an action that affects the other. The effect of the action depends on the second party and their ability to detect the attempt. With detection, the first party withdraws the action. The Israeli law of consumer protection determines in section 13D1 (A) that if a customer was overcharged in an ongoing deal beyond the amount the business-owner is allowed to charge according to the details of their agreement, the business-owner will return the excess with interest and indexation, in 4 business days. Furthermore, the businessman will compensate the consumer at 16 Israeli new shekel for their expenses. ","date":"2017-10-23","objectID":"/posts/matzliah/:0:0","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":"Usage of the method This method is most prevalent in the financial field, for example: A commercial company increases its service charge without notifying the customer; this is done under the assumption that the customer, who is used to get their monthly charge, will not notice the change. If the assumption turns out to be true, it ‚Äúworks‚Äù; if the customer notices and appeals the charge - it ‚Äúdoesn‚Äôt work‚Äù, and the company will correct the charge, with barely any damage (e.g. public relations damage). The constant rule of this method, from which it gets is name, is ‚Äúif it works - it works; if it doesn‚Äôt work - it doesn‚Äôt work‚Äù; in other words, there‚Äôs a chance the attempt will succeed, and conversely, little to no damage will happen if it won‚Äôt, so there‚Äôs nothing to lose and it‚Äôs worth trying. The Matzliah method occurs in other fields as well: A business-owner that doesn‚Äôt pay their employees the full wage and benefits they deserve Litigation intended to intimidate into settlement, such as vexatious litigation. A business-owner deducts taxes for expenses, when they are unsure if the expenses are deductible or not. If the IRS does not review this business, it works. If a review occurs, they will remove the deduction. A failing politician is called to resign, but does not hurry to do so, assuming that the public is otherwise occupied. If the public notices, the politician can always resign. An insurance company dismisses a claimant‚Äôs demand for payment with various claims, such as contradicting with the terms of the policy. If the claimant does not respond nor refer to the courts, the insurance company profits (due to non-payment). If the claimant does refer to the courts, the insurance company will offer to settle for a partial sum, hoping that the claimant, due to pressure and interest in shortening legal proceedings, will agree to it. The insurance company will, at most, pay part of the policy‚Äôs sum. (See Insurance bad faith). In The Rainmaker, a young lawyer called Rudy Baylor deals with an insurance company operating with the Mazliah method: it would initially deny every insurance claim submitted, and only pay claimants that continued to fight for their rights. A softer version of the Mazliah version is ‚Äúat least we tried‚Äù, or ‚Äúcan‚Äôt blame us for trying‚Äù. In this version, an attempt is made to gain an advantage, but not necessarily with fair means. For example, haggling by presenting unreasonably extreme opening positions. ","date":"2017-10-23","objectID":"/posts/matzliah/:0:1","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":"See also Patent troll ","date":"2017-10-23","objectID":"/posts/matzliah/:0:2","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":"External links A verdict denouncing the ‚ÄúMatzliah‚Äù method Insurance companies and the ‚ÄúMatzliah‚Äù method, at the Israeli bar association. ","date":"2017-10-23","objectID":"/posts/matzliah/:0:3","tags":null,"title":"The Matzliah method","uri":"/posts/matzliah/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew due to the target audience. TL;DR - TransportDroidIL can no longer function. ◊™◊ß◊ú◊î ◊ë-TransportDroidIL ◊ú◊¶◊¢◊®◊ô, ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î TransportDroidIL ◊î◊§◊°◊ô◊ß◊î ◊ú◊§◊¢◊ï◊ú, ◊ï◊î◊°◊ô◊ë◊î ◊î◊ô◊ê ◊õ◊ñ◊ï ◊©◊ú◊ê ◊û◊ê◊§◊©◊®◊™ ◊™◊ô◊ß◊ï◊ü. ◊ê◊†◊ô ◊û◊û◊ú◊ô◊• ◊ë◊ó◊ï◊ù ◊¢◊ú ◊î◊ó◊ú◊ï◊§◊î Google Maps. ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:0:0","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"◊©◊ê◊ú◊ï◊™ ◊ï◊™◊©◊ï◊ë◊ï◊™ ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:0","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"◊ú◊û◊î ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊î◊§◊°◊ô◊ß◊î ◊ú◊¢◊ë◊ï◊ì? ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î TransportDroidIL ◊§◊ï◊¢◊ú◊™ ◊¢\"◊ô ◊ë◊ß◊©◊™ ◊†◊™◊ï◊†◊ô◊ù ◊û◊ê◊™◊® ◊ê◊í◊ì ◊ê◊ï ◊û◊©◊®◊ì ◊ê◊™◊® ◊î◊™◊ó◊ë◊ï◊®◊î, ◊™◊ï◊ö ◊©◊ô◊û◊ï◊© ◊ë◊û◊†◊í◊†◊ï◊ü ◊î\"◊©◊§◊î ◊ó◊ï◊§◊©◊ô◊™\". ◊©◊†◊ô ◊î◊ê◊™◊®◊ô◊ù ◊î◊©◊™◊†◊ï ◊ë◊¶◊ï◊®◊ï◊™ ◊©◊ï◊†◊ï◊™, ◊©◊ú◊ê ◊û◊ê◊§◊©◊®◊ï◊™ ◊ú◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊ú◊§◊¢◊ï◊ú ◊ô◊ï◊™◊®: ◊ë◊ê◊™◊® ◊û◊©◊®◊ì ◊î◊™◊ó◊ë◊ï◊®◊î, ◊û◊†◊í◊†◊ï◊ü ◊î\"◊©◊§◊î ◊ó◊ï◊§◊©◊ô◊™\" ◊õ◊ë◊® ◊ú◊ê ◊¢◊ï◊ë◊ì ◊õ◊ú◊ú - ◊ß◊ï◊§◊¶◊™ ◊î◊î◊ï◊ì◊¢◊î [object Object], ◊ï◊û◊ê◊ó◊ï◊®◊ô ◊î◊ß◊ú◊¢◊ô◊ù ◊†◊ô◊™◊ü ◊ú◊®◊ê◊ï◊™ ◊©◊î◊ê◊™◊® ◊ú◊ê ◊û◊ß◊ë◊ú ◊û◊®◊õ◊ô◊ë ◊î\"◊©◊§◊î ◊î◊ó◊ï◊§◊©◊ô◊™\" ◊™◊©◊ï◊ë◊î. ◊ë◊ê◊™◊® ◊ê◊í◊ì, ◊û◊†◊í◊†◊ï◊ü ◊î\"◊©◊§◊î ◊î◊ó◊ï◊§◊©◊ô◊™\" ◊¢◊ì◊ô◊ô◊ü ◊§◊ï◊¢◊ú,◊ï◊î◊©◊™◊†◊î ◊ô◊ó◊°◊ô◊™ ◊û◊¢◊ò, ◊ï◊ô◊õ◊ï◊ú ◊ë◊î◊ó◊ú◊ò ◊ú◊î◊ô◊ï◊™ ◊ê◊§◊©◊®◊ô ◊ú◊í◊®◊ï◊ù ◊ú◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊ú◊¢◊ë◊ï◊ì ◊ê◊ô◊™◊ï ◊©◊ï◊ë, ◊ê◊ë◊ú‚Ä¶ ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:1","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"◊®◊í◊¢ ◊®◊í◊¢, ◊ë◊¢◊¶◊ù ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊ú◊ê ◊¢◊ï◊©◊î ◊©◊ï◊ù ◊ì◊ë◊® ◊ï◊û◊ë◊ô◊ê◊î ◊ê◊™ ◊õ◊ú ◊î◊†◊™◊ï◊†◊ô◊ù ◊û◊ê◊™◊®◊ô◊ù ◊ß◊ô◊ô◊û◊ô◊ù? ◊ê◊ñ ◊ú◊û◊î ◊õ◊™◊ë◊™ ◊ê◊ï◊™◊î? ◊†◊õ◊ï◊ü! ◊î◊°◊ô◊ë◊î ◊©◊õ◊™◊ë◊™◊ô ◊ê◊™ ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊î◊ô◊ô◊™◊î ◊©◊î◊ê◊™◊®◊ô◊ù ◊î◊ê◊ú◊î, ◊ë◊°◊§◊ò◊û◊ë◊® 2010, ◊ú◊ê ◊î◊ô◊ï ◊û◊ï◊™◊ê◊û◊ô◊ù ◊ú◊ò◊ú◊§◊ï◊†◊ô◊ù ◊†◊ô◊ô◊ì◊ô◊ù ◊ï◊î◊©◊ô◊û◊ï◊© ◊ë◊î◊ù ◊û◊î◊†◊ô◊ô◊ì ◊î◊ô◊î ◊õ◊ê◊ë-◊®◊ê◊© ◊û◊ï◊ó◊ú◊ò. ◊ú◊û◊¢◊©◊î, ◊ê◊™◊® ◊û◊©◊®◊ì ◊î◊™◊ó◊ë◊ï◊®◊î ◊¢◊ì◊ô◊ô◊ü ◊ú◊ê ◊û◊ï◊™◊ê◊ù, ◊ï◊†◊®◊ê◊î ◊õ◊ô◊ï◊ù ◊ì◊ï◊û◊î ◊û◊ê◊ï◊ì ◊ú◊ê◊ô◊ö ◊©◊ê◊™◊® ◊ê◊í◊ì ◊†◊®◊ê◊î ◊ë-2010. ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊î◊ô◊ô◊™◊î ◊û◊ô◊ï◊¢◊ì◊™ ◊ê◊ö ◊ï◊®◊ß ◊ú◊™◊™ ◊û◊û◊©◊ß ◊û◊©◊™◊û◊© ◊†◊ï◊ó ◊ô◊ï◊™◊® ◊ú◊ê◊ï◊™◊ù ◊î◊ê◊™◊®◊ô◊ù. ◊ú◊û◊®◊ë◊î ◊î◊©◊û◊ó◊î, ◊ê◊™◊® ◊ê◊í◊ì ◊û◊ï◊™◊ê◊ù ◊õ◊ô◊ï◊ù ◊ë◊¶◊ï◊®◊î ◊§◊ó◊ï◊™-◊ê◊ï-◊ô◊ï◊™◊® ◊°◊ë◊ô◊®◊î ◊ú◊ò◊ú◊§◊ï◊†◊ô◊ù ◊†◊ô◊ô◊ì◊ô◊ù. ◊ú◊ê ◊û◊ï◊©◊ú◊ù, ◊ê◊ë◊ú ◊ë◊î◊ó◊ú◊ò ◊©◊û◊ô◊©. ◊ê◊ö, ◊ó◊©◊ï◊ë ◊û◊õ◊ú‚Ä¶ ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:2","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"◊ë◊™◊õ◊ú‚Äô◊° ◊ô◊© ◊ê◊§◊ú◊ô◊ß◊¶◊ô◊ï◊™ ◊ô◊ï◊™◊® ◊û◊ï◊¶◊ú◊ó◊ï◊™, ◊õ◊û◊ï Google Maps, ◊ê◊ñ ◊ú◊û◊î ◊ú◊î◊©◊™◊û◊© ◊ë◊ê◊™◊®◊ô◊ù ◊î◊ê◊ú◊î ◊ë◊õ◊ú◊ú? ◊ê◊ô◊ü ◊ô◊ï◊™◊® ◊°◊ô◊ë◊î! ◊ë-2010 Google Maps ◊ê◊û◊†◊ù ◊ú◊ê ◊°◊ô◊§◊ß◊î ◊û◊ô◊ì◊¢ ◊™◊ó◊ë◊ï◊®◊î ◊¶◊ô◊ë◊ï◊®◊ô◊™ ◊ë◊ô◊©◊®◊ê◊ú, ◊ê◊ë◊ú ◊õ◊ô◊ï◊ù ◊î◊û◊ô◊ì◊¢ ◊ß◊ô◊ô◊ù ◊©◊ù ◊ë◊¶◊ï◊®◊î ◊û◊ú◊ê◊î ◊ï◊û◊ß◊ô◊§◊î. ◊î◊û◊ô◊ì◊¢ ◊û◊í◊ô◊¢ ◊ú◊í◊ï◊í◊ú ◊ô◊©◊ô◊®◊ï◊™ ◊û◊ê◊™◊® ◊û◊ê◊í◊®◊ô ◊î◊û◊ô◊ì◊¢ ◊î◊û◊û◊©◊ú◊™◊ô◊ô◊ù, ◊ë◊§◊ï◊®◊û◊ò GTFS ◊î◊û◊ï◊™◊ê◊ù ◊ú◊õ◊ö. ◊ñ◊ï ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊ë◊î ◊ê◊†◊ô ◊û◊©◊™◊û◊© ◊õ◊ô◊ï◊ù. ◊î◊û◊ô◊ì◊¢ ◊î◊û◊°◊ï◊§◊ß ◊î◊ï◊ê, ◊õ◊û◊ï ◊™◊û◊ô◊ì, ◊û◊ô◊ì◊¢ ◊©◊ú ◊ú◊ï◊ó◊ï◊™ ◊ñ◊û◊†◊ô◊ù ◊ï◊ú◊ê ◊û◊ô◊ì◊¢ ◊ñ◊û◊ü-◊ê◊û◊™. ◊õ◊ï◊ú◊ô ◊™◊ß◊ï◊ï◊î ◊©◊ó◊ë◊®◊ï◊™ ◊î◊ê◊ï◊ò◊ï◊ë◊ï◊°◊ô◊ù ◊ô◊™◊ó◊ô◊ú◊ï ◊ú◊§◊®◊°◊ù ◊û◊ô◊ì◊¢ ◊ñ◊û◊ü-◊ê◊û◊™ ◊ë◊§◊ï◊®◊û◊ò GTFS-realtime, ◊ê◊©◊® ◊ô◊í◊®◊ï◊ù ◊ú◊õ◊ö ◊©-Google Maps ◊ï◊ê◊§◊ú◊ô◊ß◊¶◊ô◊ï◊™ ◊ê◊ó◊®◊ï◊™ ◊ô◊ï◊õ◊ú◊ï ◊ú◊î◊®◊ê◊ï◊™ ◊û◊ô◊ì◊¢ ◊û◊¶◊ô◊ê◊ï◊™ ◊ô◊ï◊™◊® ◊¢◊ú ◊ñ◊û◊ü ◊î◊í◊¢◊™ ◊î◊ê◊ï◊ò◊ï◊ë◊ï◊°◊ô◊ù. ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:3","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"◊û◊ô ◊§◊ô◊™◊ó ◊ê◊™ ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊ï◊û◊î ◊î◊ß◊©◊® ◊©◊ú◊ï ◊ú◊¢◊†◊ô◊ô◊ü? ◊ê◊†◊ô ◊î◊û◊§◊™◊ó ◊î◊û◊ß◊ï◊®◊ô ◊©◊ú ◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î - ◊©◊û◊ô ◊ê◊ï◊î◊ì ◊ú◊ï◊¶◊ß◊ô. ◊î◊™◊ó◊ú◊™◊ô ◊ú◊¢◊ë◊ï◊ì ◊¢◊ú ◊™◊ï◊õ◊†◊ï◊™ ◊©◊û◊ë◊ô◊ê◊ï◊™ ◊û◊ô◊ì◊¢ ◊û◊ê◊™◊® ◊û◊©◊®◊ì ◊î◊™◊ó◊ë◊ï◊®◊î ◊ë◊ñ◊û◊ü ◊©◊î◊ô◊ô◊™◊ô ◊°◊ò◊ï◊ì◊†◊ò ◊ë◊ò◊õ◊†◊ô◊ï◊ü ◊©◊†◊ï◊°◊¢ ◊î◊®◊ë◊î ◊ë◊ê◊ï◊ò◊ï◊ë◊ï◊°◊ô◊ù, ◊ë◊¢◊®◊ö ◊ë-2007. ◊ë-2010 ◊î◊û◊®◊™◊ô ◊ê◊™ ◊î◊™◊ï◊õ◊†◊î ◊ú◊ê◊§◊ú◊ô◊ß◊¶◊ô◊ô◊™ ◊ê◊†◊ì◊®◊ï◊ê◊ô◊ì ◊õ◊©◊î◊ô◊ô◊™◊ô ◊ë◊¶◊ë◊ê ◊ï◊†◊°◊¢◊™◊ô ◊î◊®◊ë◊î ◊ë◊ê◊ï◊ò◊ï◊ë◊ï◊°◊ô◊ù; ◊õ◊û◊î ◊ó◊ë◊®◊ô◊ù ◊î◊™◊¢◊†◊ô◊ô◊†◊ï, ◊ï◊î◊¢◊ú◊ô◊™◊ô ◊ê◊™ ◊î◊™◊ï◊õ◊†◊î ◊ú-Play Store. ◊ó◊ë◊® ◊ò◊ï◊ë ◊û◊î◊ú◊ô◊û◊ï◊ì◊ô◊ù, ◊ó◊í◊ô, ◊©◊ú◊ó ◊û◊°◊§◊® ◊©◊ô◊§◊ï◊®◊ô◊ù ◊ï◊ê◊£ ◊î◊ï◊°◊ô◊£ ◊û◊†◊í◊†◊ï◊ü ◊¢◊ì◊õ◊ï◊†◊ô-◊ñ◊û◊ü-◊ê◊û◊™, ◊ê◊©◊® ◊î◊ô◊î ◊™◊ú◊ï◊ô ◊ë◊ó◊°◊ì◊ô ◊î◊ê◊™◊®◊ô◊ù ◊©◊ú ◊ó◊ë◊®◊ï◊™ ◊ê◊ï◊ò◊ï◊ë◊ï◊° ◊°◊§◊¶◊ô◊§◊ô◊ï◊™ ◊©◊°◊ô◊§◊ß◊ï, ◊í◊ù ◊î◊ü, ◊ê◊™ ◊î◊û◊ô◊ì◊¢ ◊ë◊¶◊ï◊®◊î ◊ú◊ê-◊°◊ò◊†◊ì◊®◊ò◊ô◊™. ◊ë◊©◊ú◊ë ◊õ◊ú◊©◊î◊ï ◊¢◊ú◊ï ◊ê◊§◊ú◊ô◊ß◊¶◊ô◊ï◊™ ◊ó◊ú◊ï◊§◊ô◊ï◊™ ◊ú◊®◊©◊™, ◊ì◊ï◊í◊û◊™ Moovit - ◊ê◊ö ◊ê◊£ ◊ê◊ó◊ì ◊û◊î◊ü ◊ú◊ê ◊û◊¶◊ê◊î ◊ó◊ü ◊ë◊¢◊ô◊†◊ô◊ô. ◊ë◊§◊®◊ò, ◊ú-Moovit ◊ú◊ß◊ó ◊ñ◊û◊ü ◊®◊ë ◊ú◊¢◊ú◊ï◊™, ◊ë◊¢◊ï◊ì ◊©◊î◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊©◊ú◊ô ◊î◊ô◊ô◊™◊î ◊û◊ô◊ï◊¢◊ì◊™ ◊ú◊û◊ë◊ò ◊û◊î◊ô◊® ◊™◊ï◊ö ◊õ◊ì◊ô ◊©◊î◊ê◊ï◊ò◊ï◊ë◊ï◊° ◊û◊™◊ß◊®◊ë ◊ú◊™◊ó◊†◊î. ◊ë◊©◊ú◊ë ◊õ◊ú◊©◊î◊ï (2012 ◊ú◊õ◊ú ◊î◊û◊ê◊ï◊ó◊®) ◊û◊©◊®◊ì ◊î◊™◊ó◊ë◊ï◊®◊î ◊î◊™◊ó◊ô◊ú ◊ú◊§◊®◊°◊ù ◊û◊ô◊ì◊¢ GTFS ◊©◊ê◊§◊©◊® ◊ú◊í◊ï◊í◊ú ◊ú◊î◊¶◊ô◊í ◊û◊ô◊ì◊¢ ◊™◊ó◊ë◊ï◊®◊î ◊¶◊ô◊ë◊ï◊®◊ô◊™ ◊ë◊ô◊©◊®◊ê◊ú, ◊ï◊ê◊†◊ô ◊î◊§◊°◊ß◊™◊ô ◊ú◊î◊©◊™◊û◊© ◊ë◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊©◊õ◊™◊ë◊™◊ô. Google Maps ◊û◊®◊ê◊î ◊ê◊™ ◊î◊™◊ó◊†◊ï◊™ ◊¢◊ú ◊û◊§◊î, ◊®◊©◊ô◊û◊™ ◊™◊ó◊†◊ï◊™-◊ë◊ô◊†◊ô◊ô◊ù ◊ï◊¢◊ï◊ì. ◊¢◊ù ◊ñ◊ê◊™, ◊û◊ê◊ó◊® ◊ï◊ú◊ê◊§◊ú◊ô◊ß◊¶◊ô◊î ◊¢◊ï◊ì ◊î◊ô◊î ◊û◊°◊§◊® ◊ú◊ê-◊ß◊ò◊ü ◊©◊ú ◊û◊©◊™◊û◊©◊ô◊ù (◊ß◊¶◊™ ◊ô◊ï◊™◊® ◊û-55,000 ◊ë◊©◊ô◊ê), ◊î◊û◊©◊õ◊™◊ô ◊ú◊™◊ß◊ü ◊ë◊¢◊ô◊ï◊™ ◊ß◊ò◊†◊ï◊™ ◊õ◊©◊î◊ü ◊¶◊¶◊ï ◊ï◊õ◊©◊î◊ô◊î ◊ú◊ô ◊ñ◊û◊ü. ◊õ◊ô◊ï◊ù ◊ê◊†◊ô ◊¢◊ï◊ë◊ì ◊ë◊í◊ï◊í◊ú ◊ë◊¢◊¶◊û◊ô - ◊ú◊ê ◊ë◊¶◊ï◊ï◊™ ◊©◊ú Google Maps, ◊ê◊ú◊ê ◊ë◊¶◊ï◊ï◊™ Search. ◊ê◊†◊ô ◊ë◊î◊ó◊ú◊ò ◊ó◊ï◊©◊ë ◊©◊í◊ï◊í◊ú ◊û◊°◊§◊ß◊ô◊ù ◊û◊¢◊†◊î ◊ò◊ï◊ë ◊ô◊ï◊™◊® ◊ú◊™◊ó◊ë◊ï◊®◊î ◊¶◊ô◊ë◊ï◊®◊ô◊™ ◊û◊ê◊©◊® TransportDroidIL üòÑ ","date":"2016-01-11","objectID":"/posts/transportdroidil-outage/:1:4","tags":["hebrew","software","TransportDroidIL"],"title":"TransportDroidIL outage","uri":"/posts/transportdroidil-outage/"},{"categories":null,"content":"The Faculty Programmer Sharon, a close friend of mine, has been studying psychology for the past few years. At some point she needed to run an experiment in the field of perception. While the exact form of the experiment was pending professor vetting, she did know that the experiment will take place with a user sitting in front of a desktop computer, responding to various stimuli, often with the reaction time being recorded. Seeing as programming is not in her faculty‚Äôs curriculum (a mistake, in my opinion), the students are provided with a faculty programmer. Dozens of students would contact this jaded craftsman, describe what they need, wait patiently, and then - as it happens in the world of software - receive something almost, but not quite, entirely unlike what they asked for. I was all too happy to help (and owe Sharon an insurmountable number of favors to start with), but had nothing to start with at the time. The weeks and months passed, I was deep into my move and training at my new job1, and happily suggesting (using my limited understanding of psychology) experiments. When the final proposal was authorized, the timing was inconvenient - I was going on a business trip to California the next day, putting a 10 hour time difference between Sharon and myself. No matter. The experiment was fairly well-defined before I left - a word out of three word-sets, designated as ‚Äúup‚Äù, ‚Äúdown‚Äù and ‚Äúneutral‚Äù, was to flash in the middle of the screen, and then a circle would appear at the top or bottom. The user had to react to this circle as quickly as possible, and the idea was to test whether or not a word from the ‚Äúup‚Äù category (such as ‚Äúsky‚Äù or ‚Äúcloud‚Äù) would correlate with better reaction time when the circle appeared at the top, and vice versa. There were some other details such as ‚Äúcatch trials‚Äù when no circle would show up at all, but it sounded fairly simple. (Keep reading for a demo!) ","date":"2015-05-30","objectID":"/posts/seaplane/:1:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"Getting started My experience had me worried, as no software project is ever as simple as it originally seems. Sharon and I agreed that, while this seems completely reasonable and quite thought-out, we would work in an iterative fashion, and have regular video-chats on what should be done next. Also, to simplify things, I asked to create the software as a web page intended for use on Chrome, rather than Matlab as suggested by her faculty programmer (who seemed convinced, for whatever reason, that Matlab could give better timing precision - this turned out to be false). She agreed, and within a few hours on a plane, I had a basic draft working. I emailed Sharon a copy of the draft; it was split into a simple index.html file, a style.css file, a seaplane.js code file, and a config.js code file. That last split was deliberate: Sharon, who has no experience in coding (and even claims to be a technophobe), could modify clearly defined configuration (including the sets of words and tuned delays) with no anxiety of ‚Äúmessing up‚Äù the more complex code. Soon enough, timezones flipped by, and Sharon was happy enough with the result to respond with a modified config.js file, and a list of changes she wanted - mostly present in the original requirements, but some which could only be understood while trying out the first draft. Naturally, some of the changes would require the syntax of config.js itself to change, and Sharon had more data to add to it. To avoid seaplane7-final-really.zip email attachments flying back and forth, version control would be required. Using Github would facilitate this, and also allow us to use its Issues mechanism for tracking remaining work. It took a few minutes over the phone to explain the basic concept of version control to Sharon, as well as how to create a Github account, modify files using the web-based interface, report and comment on issues. While I did mention Github for Windows as an option, I didn‚Äôt pressure Sharon into using it, especially as I wasn‚Äôt familiar enough with it myself. Over 10 days and 48 commits (27 mine, 20 Sharon‚Äôs) we got the code working well enough to run the experiment. There were a few reported bugs, but nothing substantial that skewed the results, as far as we can tell. You‚Äôre welcome to see a Demo of Seaplane, as well as browse the Seaplane source code. If you can read Hebrew, you can also read Sharon's paper. ","date":"2015-05-30","objectID":"/posts/seaplane/:2:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"What worked Issues worked quite well for tracking the work; Sharon and I found them more useful than emails for keeping state. Being a fully client-side web application, seaplane was (and still is) trivially hosted by Github Pages. This made deployment of new versions as easy as hitting F5. For changes that could be previewed in chrome using developer tools, Sharon got instant feedback on her changes without needing to commit anything. Sharon made 4 commits to change config.js, modifying the word sets according to discussions with her supervisor. Sharon also made 11 commits to change style.css, 2 commits to change index.html, and even 3 to change seaplane.js. ","date":"2015-05-30","objectID":"/posts/seaplane/:3:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"What didn‚Äôt work Github‚Äôs UI for submitting changes online has a default value for the commit message, and no recommendations against using it. As a result, there are 8 commits called ‚ÄúUpdate style.css‚Äù. Sharon didn‚Äôt have a working copy on her own machine, and not all changes could be easily previewed in chrome. As a result, there were some back-and-forth commits by Sharon and myself which weren‚Äôt necessary. (I could‚Äôve avoided this by providing appropriate ‚Äúrefresh‚Äù functionality in the app) The format I chose for the word list made right-to-left issues rear their ugly head in the editor. All in all, the project went swimmingly. Using progamming-oriented version control software to collaborate with non-programmers may be less crazy than you think. I highly recommend giving it a try. Oh yeah, I‚Äôm a Site Reliability Engineer at Google Ireland now, which is too awesome to detail in this footnote.¬†‚Ü©Ô∏é ","date":"2015-05-30","objectID":"/posts/seaplane/:4:0","tags":["git","software"],"title":"Seaplane - Github with a non-programmer","uri":"/posts/seaplane/"},{"categories":null,"content":"This is part of the ‚ÄúGit While You Sit‚Äù series, a play on Google‚Äôs Testing on the Toilet. It‚Äôs intended to fit on a printed page. Currently Chrome doesn‚Äôt seem to correctly print columns, but Firefox does. {: .no-print } Sometimes, git does something unexpected while merging or rebasing. It might seem like git misunderstood a rename, but it‚Äôs far more likely that git did the ‚Äúright‚Äù thing after all. Here are a couple of examples I‚Äôve seen recently. ","date":"2014-08-17","objectID":"/posts/git-rename-edge-cases/:0:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 3 - \"Rename\" edge cases","uri":"/posts/git-rename-edge-cases/"},{"categories":null,"content":"First case When rebasing, conflicts might occur before renames: o---o---E---F---G (master) \\ A---B---RENAME---C (feature *) When the current branch is feature, and running git rebase master, what happens is that the commits from feature will be cherry-picked onto G in order - A, B, RENAME, and C. If a conflict occurs in B, in a file that was later renamed (in RENAME), conflict resolution will have to happen using the original name. If there was a massive reworking, it might be simpler and more sensible to merge in this case. ","date":"2014-08-17","objectID":"/posts/git-rename-edge-cases/:1:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 3 - \"Rename\" edge cases","uri":"/posts/git-rename-edge-cases/"},{"categories":null,"content":"Second case It wasn‚Äôt a rename, it was a copy. --o---E----F [MODIFY]----G (master) \\ \\ A---B [COPY]---C---D---M (feature *) In this case, the user thought he renamed dir1/file.xml to dir2/file.xml in B [COPY]. Then, when he merged master into feature, he expected that the modifications in file.xml in F [MODIFY] would, as part of the merge in M, be applied to dir2/file.xml. This would indeed have happened if B had a move operation. However, it doesn‚Äôt make sense for git to merge the changes from a copy of a file, so it didn‚Äôt. The fix here was to undo the merge: git reset --hard D ‚Ä¶and then edit the commit: git rebase -i A ‚Ä¶and set B to edit instead of pick. Amend the commit for B so that it doesn‚Äôt just create dir2/file.xml, but also deletes dir1/file.xml. If it‚Äôs indeed the same file (or has very similar contents), this will be automatically detected as a rename during log and merge operations. It should be noted that git doesn‚Äôt track renames (or copies) at all during commits. It only figures out that they happened retroactively when it‚Äôs relevant (log, merge, cherry-pick, diff‚Ä¶), by comparing the contents. This is why those operations have options like rename-threshold, find-renames, find-copies and even find-copies-harder. ","date":"2014-08-17","objectID":"/posts/git-rename-edge-cases/:2:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 3 - \"Rename\" edge cases","uri":"/posts/git-rename-edge-cases/"},{"categories":null,"content":"This is part of the ‚ÄúGit While You Sit‚Äù series, a play on Google‚Äôs Testing on the Toilet. It‚Äôs intended to fit on a printed page. Currently Chrome doesn‚Äôt seem to correctly print columns, but Firefox does. {: .no-print } Your repository has files which are generated as part of your build process or as part of running your software, which you don‚Äôt want in source control. They keep showing up in git status. What to do? You can create a file called .gitignore - note that the filename starts with a ., which is standard for configuration files in Unix and causes them to be hidden from normal listing. Each .gitignore file affects the current directory and its subdirectories - you can have multiple .gitignore files to create more specific rules for subdirectories. Note: .gitignore can only be used for files which shouldn‚Äôt be in source code at all (those show up as ‚ÄúUntracked files‚Äù. Modified files can‚Äôt be ignored in this way. If you really want to, you can force git to ignore modifications with this command: git update-index --assume-unchanged FILE However, this is usually a bad idea and indicates you need to refactor your file handling - split files which get modified locally from files which contain information which should be source-controlled. Here is an annotated excerpt from a .gitignore file: # Extensions of compiled files *.a *.so *.o # ... # Files generated by build system build.ninja .ninja_deps # Ignore bin/ and obj/, as they contain # compiled files. This is ignored # recursively within the repository. bin/ obj/ # ...except (\"!\") for the scripts, which # are in the \"scripts\" dir in the same # one as this .gitignore file (hence the # leading \"/\") !/scripts/bin Addendum: A reader has mentioned gitignore.io, which auto-generates useful .gitignore files. ","date":"2014-08-15","objectID":"/posts/git-ignore/:0:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 2 - .gitignore","uri":"/posts/git-ignore/"},{"categories":null,"content":"This is part of the ‚ÄúGit While You Sit‚Äù series, a play on Google‚Äôs Testing on the Toilet. It‚Äôs intended to fit on a printed page. Currently Chrome doesn‚Äôt seem to correctly print columns, but Firefox does. {: .no-print } Ever find yourself printf-debugging? You found the bug, but now you have printf statements all over the place. Running git diff, you get: diff --git a/hello.c b/hello.c index 93ca08c..c7d354a 100644 --- a/hello.c +++ b/hello.c @@ -4,6 +4,7 @@ void b(); void a() { + printf(\"Bug is here?\\n\"); return; } @@ -13,9 +14,10 @@ int main() { printf(\"Hello, world!\\n\"); - return 1; + return 0; // Found it! } void b() { + printf(\"Bug is here?\\n\"); return; } It‚Äôs actually pretty easy to get rid of them. Run git add -p and you will be shown each patch ‚Äúhunk‚Äù separately: diff --git a/hello.c b/hello.c index 93ca08c..c7d354a 100644 --- a/hello.c +++ b/hello.c @@ -4,6 +4,7 @@ void b(); void a() { + printf(\"Bug is here?\\n\"); return; } ### Stage this hunk [...]? n (No) ### @@ -13,9 +14,10 @@ int main() { printf(\"Hello, world!\\n\"); - return 1; + return 0; // Found it! } void b() { + printf(\"Bug is here?\\n\"); return; } ### Stage this hunk? [...] s (Split) ### @@ -13,7 +14,7 @@ int main() { printf(\"Hello, world!\\n\"); - return 1; + return 0; // Found it! ### Stage this hunk [...]? y (Yes) ### void b() { + printf(\"Bug is here?\\n\"); return; } ### Stage this hunk [...]? n (No) ### Now, only the return 0 line is stage for commit. To get rid of the rest of the changes, run git checkout -- hello.c. Now the printf statements have been removed! ","date":"2014-08-13","objectID":"/posts/git-add-patch/:0:0","tags":["git-while-you-sit","git"],"title":"Git While You Sit 1 - Add --patch","uri":"/posts/git-add-patch/"},{"categories":null,"content":"After 6 years with my previous employer, as a DevOps engineer and DevOps team leader, I‚Äôve learned two important lessons. I wanted to get these in here before I start my new position (‚Ä¶as an SRE in Google Dublin, which I am very excited about!), as it‚Äôs always fun to look back after a few years and see if what I wrote is still relevant. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:0:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"Keep it tidy Working in a tidy manner is incredibly important. Tidy code is more important than fast code. It‚Äôs even more important than correct code! Tidy code is obvious about what it does, and the incorrectness will be apparent to anyone who reads it. However, correct messy code will be misleading about what it does, and what subtleties had to be dealt with in order for it to be correct. This will cause long hours and hair loss when refactoring or when tending to changing requirements. Requirements change. A good team leader will be able to predict how they‚Äôll change, and direct his team around that. Incorrect predictions are inevitable and costly, but so is a complete lack of change prediction. Operations need to be just as tidy as code, if not tidier. Operations performed manually will inevitably be performed wrong, usually by the one person you‚Äôre sure can‚Äôt possibly get it wrong. As such, operations need to be as idiot-resistant as possible (nothing is completely idiot-proof). ‚ÄúRun this job in Jenkins, the rest is a script‚Äù is a good place to be, but you should make sure it‚Äôs really hard to run the wrong job, or get any parameters harmfully wrong. Any knowledge contained within one brain reduces your bus factor to 1. Use pair programming (or pair-ops) to increase your bus factor. Whenever possible, let someone from your team tackle a task he has no idea how to perform, but make sure both you and someone knowledgeable are available (and willing) to answer questions. However, containing knowledge within brains is fleeting - even with a high bus-factor, some areas will be left untouched for years, and subsequently re-touched when nobody remembers anything about them. When this happens, you‚Äôll be much happier to find out your predecessor (or past-you) has left solid documentation and completely obvious code. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:1:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"Don‚Äôt write it yourself This is a special case of ‚Äúkeep it tidy‚Äù. Writing your own code should be your last resort: Someone else has already written, tested, fixed, debugged, documented, rewritten, and perfected a piece of code that does exactly what you need. They did this with the help of far better coders than you can afford and a QA team comprised of countless relentlessly nitpicking users. Your problem is not as unique as you think. You will ignore this advice. You‚Äôll write your own ‚Äúsuper efficient‚Äù database/JSON parser combo, and guard it as a trade/military secret. And it‚Äôll even work for the first few years, and perform fantastically. But as requirements change (requirements change!), you‚Äôll suddenly find out that you can‚Äôt push new features and bugfixes out as fast as your competition. This happens because your competition is using a widely-adopted database, and a (separate) widely-adopted JSON parser. These are both open-source, and you will see that some kid in a basement has stumbled onto your clever optimizations and suggested them - these have been merged in. And while you‚Äôre stuck debugging your code, with its sparse unit tests and misleading function names, your competition is looking up known issues and workarounds on Stack Overflow. Hiding within this advice is the one worse thing you can do than writing it yourself: Using unpopular closed-source software (especially if it‚Äôs hard/impossible to search for in Google). This has all the detriments of writing code yourself, with the added hell of being unable to read or modify the code yourself when something goes wrong. This advice is clearly quite extreme and is intended to be cautionary (and you will therefore, as mentioned, ignore it). You probably do have some business logic to implement. You probably do need to write glue code in order to connect your proprietary code with some external provider. You might be dealing with insane, Google-scale problems and have found (after checking!) that all existing solutions don‚Äôt meet your performance/capacity criteria. But this is no reason to implement your own version of ping. Or rsync. Or cron. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:2:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"Afterword That‚Äôs my 2 cents on how to do DevOps (for a rather narrow definition of DevOps). They‚Äôre the instructions I left my team. I wonder if they‚Äôll stand the test of time. ","date":"2014-08-13","objectID":"/posts/lessons-learned/:3:0","tags":null,"title":"Lessons learned","uri":"/posts/lessons-learned/"},{"categories":null,"content":"I‚Äôve recently been rewriting a mess of bash, tcsh and Python code as a Python script, and this has proven interesting to test. I‚Äôve written a tiny Python library called fakefile to help out with it, so I can write code like this: import fakefile import unittest import mock def my_function(): with open(\"somefile\", \"w\") as f: f.write(\"correct output\") with open(\"existing_file\", \"w\") as f: return f.read() class TestMyCode(unittest.TestCase): def test_my_function(self): faker = fakefile.FakeFile() faker.set_contents(\"existing_file\", \"correct input\") with mock.patch('__builtin__.open', faker.open): result = my_function() # No file \"somefile\" will be created! # No file \"existing_file\" will be read! self.assertEquals(faker.files[\"somefile\"].file_contents, \"correct output\") The library is available on github as lutzky/fakefile. Naturally, however, it turns out I‚Äôve been outdone by Google‚Äôs pyfakefs. They have some clever bast^H^H^H^Hgooglers working there! ","date":"2014-07-02","objectID":"/posts/fakefile/:0:0","tags":["software","python","testing"],"title":"FakeFile","uri":"/posts/fakefile/"},{"categories":null,"content":"Here‚Äôs a fun little bash script: #!/bin/bash ( sleep 20 \u0026 ) ps -f $(pidof sleep) echo \"Bye\" Run it, and you‚Äôll notice a few things: Because the subshell running sleep dies immediately, sleep gets reparented to init. (Interestingly enough, on newer Ubuntu releases this isn‚Äôt PID 1‚Ä¶), so the script doesn‚Äôt have any child processes by the time it prints ‚ÄúBye‚Äù. After ‚ÄúBye‚Äù is shown, the script exits immediately, returning control to the shell. Now, call the script pied_piper.sh, and try the following: ./pied_piper.sh | cat ./pied_piper.sh | ts # Awesome timestamping utility, same problem though ssh localhost ./pied_piper.sh Annoying, isn‚Äôt it? These commands won‚Äôt finish for 20 seconds! The problem is that sleep is keeping its stdout open, which is the input pipe for cat, ts, ssh, or whatever else you‚Äôre piping to (this is very annoying on Jenkins jobs as well). If a third-party product is pissing you off this way - that is, it died, but somehow still keeps its pipe open, you can find the culprit like so: fuser -v /proc/$PID_OF_PROCESS_WITH_OPEN_PIPE/fd/0 This will usually yield a sleep process as the culprit, with the useless parent information of init (as per my example). The only information you have is the precise delay - in my experience, it helps to find all ‚Äúsleep‚Äù commands lurking about, and tinker with the delay amounts: Found a sleep 30? Change it to sleep 29, see if that‚Äôs what shows up. Here‚Äôs how to actually fix the problem: #!/bin/bash ( sleep 20 \u003e\u0026- 2\u003e\u0026- \u003c\u0026- \u0026 ) ps -f $(pidof sleep) echo \"Bye\" This will close stdout, stderr and stdin. As a friend pointed out, it‚Äôs often safer to do \u003e /dev/null rather than \u003e\u0026-, as some processes will crap out if they don‚Äôt have some semblence of an stdout. However, \u003e\u0026- is shorter, faster, and perfectly safe for sleep. Of course, it‚Äôs better to save the PID for this sleep and kill it when appropriate from within the script - otherwise, you might be accumulating many useless sleep processes. ","date":"2014-06-22","objectID":"/posts/fun-with-file-descriptor-leaks/:0:0","tags":["software","linux"],"title":"Fun with file descriptor leaks","uri":"/posts/fun-with-file-descriptor-leaks/"},{"categories":null,"content":"There is a well-known problem on today‚Äôs social network platforms - spoilers. Anyone watching a show and failing to immediately catch up to the latest episode will see a lot of posts on their feed dancing around the spoiler, and finally revealing it completely. This makes sense - people like to talk about their favorite shows, and social networks are a great place to do it. What I‚Äôd like to suggest is a mechanism for mitigating the spoiler problem. This mechanism is optimized for Facebook, but could easily be applied to Google+, Twitter et cetera. The short version: Mark potential spoilers, keeping track of what exactly they might be spoiling Allow voluntary marking by the original poster Allow reporting of spoilers, similarly to spam reports Collapse spoiler materials, showing what is being spoiled Allow users to view spoilers When they do this, optionally ‚Äúlearn‚Äù that these spoilers can now safely be shown. For an example, consider the following scenario: I‚Äôm watching the fantastic show Game of Scones, and in the latest episode - season 4, episode 3 - Lord Muffin has been surprisingly murdered. I might want to post the following status: OMG can‚Äôt believe Lord Muffin was murdered no waayyyyyy Now, one of the following happens: Before posting, I check a box saying ‚Äúthis status contains spoilers‚Äù, clearly indicating Game of Scones S04E03. I post without checking the box, ticking off my spoiler-sensitive friends. Several unfriend me, but a few of them hit the ‚ÄúSpoiler alert‚Äù button adjacent to the post. Bonus points: The social network platform automatically recognizes the spoiler and asks me to mark it. Once the post was marked, it looks like this: Spoiler to Game of Scones S04E03 hidden. Click to unhide Clicking the ‚Äúclick to unhide‚Äù link should, naturally, show the status as it was originally posted. However, the social network can be smarter about this, and remember that as of now - spoilers to S04E03 are OK, and shouldn‚Äôt be hidden from the user. A few notes about this: This shouldn‚Äôt be done automatically, and a confirmation should be shown - at least at first (‚ÄúShould spoilers for this episode still be hidden? Show Spoilers/Keep hiding spoilers‚Äù) Posts containing spoilers should have a small visual indicator of them being as such. This is a good hint for what other people are seeing, and assists helpful users in marking spoilers. It would be useful to allow searching for spoilers - for example, if I just saw the episode and want to see what people are saying about it. Finally, this is a neat signal that can be used by whatever social network implements it - imagine, a percentage graph of ‚Äúhow many people have already watched the latest episode‚Äù. Seeing as many people Tivo or torrent episodes, that kind of data has got to be worth some money to someone. Note that there are existing spoiler prevention mechanisms implemented as browser extensions, and what I‚Äôm suggesting is more complex and requires integration into the social network itself. This is important anyway, as you want the social network to work the same on any device or browser. Unfortunately, this also means that I am currently powerless to implement it. So if you think this is a good idea and know someone relevant, pass it along! ","date":"2014-04-26","objectID":"/posts/social-network-spoiler-prevention/:0:0","tags":null,"title":"Social network spoiler prevention","uri":"/posts/social-network-spoiler-prevention/"},{"categories":null,"content":"My show downloading stack lives on. I‚Äôm curious as to which will happen first: NetFlix hits Israel, or I switch over to Sick Beard. At any rate, nowadays I use flexget, transmission, tvnamer and xbmc, held together with some bash scripts. On debian- and ubuntu-based systems, the transmission daemon runs as a separate user (debian-transmission), so this requires a bit of care with file and group ownership. After rebuilding my system, I couldn‚Äôt get tvnamer to work right for some reason, no matter how careful I was. I‚Äôd keep getting this error: Loading config: config.json #################### # Starting tvnamer # Found 1 episode #################### # Processing file: Sherlock.S03E01.mkv # Detected series: Sherlock (season: 3, episode: 1) #################### Old filename: Sherlock.3x01.The.Empty.Hearse.720p.HDTV.x264-FoV.mkv New filename: Sherlock - [03x01] - The Empty Hearse.mkv New path: /home/debian-transmission/inbox/Sherlock - [03x01] - The Empty Hearse.mkv Creating directory /home/debian-transmission/inbox rename Sherlock.3x01.The.Empty.Hearse.720p.HDTV.x264-FoV.mkv to /home/debian-transmission/inbox/Sherlock - [03x01] - The Empty Hearse.mkv OSError(1, 'Operation not permitted') New path: /media/Store/shows/Sherlock/Season 3/Sherlock.3x01.The.Empty.Hearse.720p.HDTV.x264-FoV.mkv Creating directory /media/Store/Shows/Sherlock/Season 3 OSError(2, 'No such file or directory') For a few weeks I‚Äôd double-check the permissions, fail to understand what was going on, groan and copy the files manually. The new Sherlock episode had me in a bit of a more investigative mood. This turns out to be an exercise in confusing OS logic and logging. It looks like the rename operation failed, and somehow the directory creation failed as well. Neither is the case. A hint can be found in the precise error after the rename: ‚Äú1 - Operation not permitted‚Äù (that‚Äôs EPERM). If that seems a bit off, that‚Äôs because it is: When renames fail because of inadequate permissions, they return EACCES ‚Äú13 - Permission denied‚Äù. So what‚Äôs going on? It turns out that after renaming, tvnamer tries to preserve the access and modification times of renamed files. A noble cause, but it turns out that Linux won‚Äôt allow this unless you are the owner of the file - even if you do have write permissions. Therefore, this fails, which causes tvnamer to believe the rename failed - although it hasn‚Äôt. Afterwards, the directory is created (this succeeds), but since tvnamer tries to copy using the old filename (thinking the rename failed), we get an ENOENT ‚Äú2 - No such file or directory‚Äù error about the source of the copy operation. The fix can be found in this pull request. Happy bug hunting! ","date":"2014-01-05","objectID":"/posts/investigate/:0:0","tags":["software","show downloading"],"title":"Weird permission issues with tvnamer","uri":"/posts/investigate/"},{"categories":null,"content":"Lately, a facebook comment of mine on the subject of Java‚Äôs slowness has proved quite popular, so here goes: Here‚Äôs a listing of a few Hello World programs and running times for them (including startup, which is a big deal in Java) on my laptop: $ grep '^model name' /proc/cpuinfo | head -1 model name: Intel(R) Core(TM) i5-3337U CPU @ 1.80GHz $ uname -a Linux orca 3.11.0-14-generic #21-Ubuntu SMP Tue Nov 12 17:04:55 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux The following script will be timed: #!/bin/bash n=$1 shift for ((i=0; i \u003c $n; i++)); do $@\" \u003e /dev/null done Times are for n=100. ","date":"2013-12-11","objectID":"/posts/startup-times/:0:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"C #include \u003cstdio.h\u003e int main(int argc, char * argv[]) { printf(\"Hello, world!\\n\"); return 0; } /* Result: 0.17s * ...unless you give it a .cc extension, and then it's 0.30s! * It turns out that gcc/g++ guess the language from the file extension. */ ","date":"2013-12-11","objectID":"/posts/startup-times/:1:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"C++ #include \u003ciostream\u003e int main(int argc, char * argv[]) { std::cout \u003c\u003c \"Hello, world!\" \u003c\u003c std::endl; return 0; } // Result: 0.30s ","date":"2013-12-11","objectID":"/posts/startup-times/:2:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"Python #!/usr/bin/python print \"Hello, world!\" # Result: 1.33s ","date":"2013-12-11","objectID":"/posts/startup-times/:3:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"Java public class Hello { public static void main(String args[]) { System.out.println(\"Hello, world!\"); } } // Result: 8.60s. No, I am not kidding. There you have it. Sun‚Äôs Java takes 28x-51x as much time to run ‚ÄúHello World‚Äù (startup included) than native applications, and (shockingly, in my opinion) over 6x as much as non-precompiled Python. That‚Äôs meaningless for long-running applications, but is a very big deal for small, often-run ones. ","date":"2013-12-11","objectID":"/posts/startup-times/:4:0","tags":["software"],"title":"Startup times","uri":"/posts/startup-times/"},{"categories":null,"content":"I‚Äôve had several opportunities to write unit tests for code that outputs large strings. It‚Äôs important that your unit-testing framework handles this well. Here‚Äôs my example data: STRING_A = \"\"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. Suspendisse ut augue placerat, venenatis ante a, aliquam nibh. Sed vitae massa a nibh dignissim porta id rhoncus neque. Etiam commodo dapibus magna sit amet pellentesque. Aenean venenatis vulputate eros, sit amet sagittis ligula laoreet vel. Pellentesque consectetur viverra nunc, vel interdum turpis tempor nec. Quisque vel purus in quam facilisis gravida posuere in mi. Aenean ligula sem, mattis ut feugiat sit amet, lobortis ut sapien. Vestibulum laoreet aliquam lorem pulvinar lobortis. Mauris quis orci lorem. Mauris ut ante id nulla ultrices gravida vel et orci. Suspendisse potenti. \"\"\" STRING_B = \"\"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. Suspendisse ut augue placerat, venenatis ante a, aliquam nibh. Sed vitae massa a nibh dignissim porta id rhoncus neque. Etiam commodo dapibus magna sit amet pellentesque. Aenean venenatls vulputate eros, sit amet sagittis ligula laoreet vel. Pellentesque consectetur viverra nunc, vel interdum turpis tempor nec. Quisque vel purus in quam facilisis gravida posuere in mi. Aenean ligula sem, mattis ut feugiat sit amet, lobortis ut sapien. Vestibulum laoreet aliquam lorem pulvinar lobortis. Mauris quis orci lorem. Mauris ut ante id nulla ultrices gravida vel et orci. Suspendisse potenti. \"\"\" STRING_A and STRING_B are different, by one character. Can you tell which one? If you‚Äôd use your unit testing framework‚Äôs equivalent of assertEqual(STRING_A, STRING_B), it would correctly report that they are different. But would it help you identify the difference? C#, for example, is quite horrible with this. It outputs both strings in their entirety. In Visual Studio, it doesn‚Äôt even seem to be possible to copy the output into an external comparison tool. This has caused some developers (myself included) to implement an ad-hoc ‚Äúcharacter-by-character string equality tester‚Äù. For C++, if testing with Google‚Äôs gtest library, the result is the same - the entire strings are shown, and an external tool needs to be used to get a reasonable indication of what the difference is. Python 2.7‚Äôs assertMultiLineEqual gives a good solution to the problem (in Python 3, this becomes the default behavior for standard assertEqual). There are similar comparison methods for other large data types. Output: F ====================================================================== FAIL: testLongStringEquality (__main__.TestLongStrings) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/home/ohad/test/test_equal.py\", line 35, in testLongStringEquality self.assertMultiLineEqual(STRING_A, STRING_B) AssertionError: '\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. [truncated]... != '\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. [truncated]... Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce ut tempus dui. Suspendisse ut augue placerat, venenatis ante a, aliquam nibh. Sed vitae massa a nibh dignissim porta id rhoncus neque. Etiam commodo dapibus magna sit amet - pellentesque. Aenean venenatis vulputate eros, sit amet sagittis ligula laoreet ? ^ + pellentesque. Aenean venenatls vulputate eros, sit amet sagittis ligula laoreet ? ^ vel. Pellentesque consectetur viverra nunc, vel interdum turpis tempor nec. Quisque vel purus in quam facilisis gravida posuere in mi. Aenean ligula sem, mattis ut feugiat sit amet, lobortis ut sapien. Vestibulum laoreet aliquam lorem pulvinar lobortis. Mauris quis orci lorem. Mauris ut ante id nulla ultrices gravida vel et orci. Suspendisse potenti. ---------------------------------------------------------------------- Ran 1 test in 0.003s FAILED (failures=1) For Ja","date":"2013-12-02","objectID":"/posts/asserting-string-equality/:0:0","tags":["software","testing"],"title":"Asserting string equality","uri":"/posts/asserting-string-equality/"},{"categories":null,"content":"A conversation with a friend reminded me that, in fact, I‚Äôve been doing test-driven development long before I knew it was called that. Back in Introduction to Systems Programming (a second-semester course revolving around abstract data types in C, introduction to C++, and hands-on experience building multi-module C programs), most homework exercises looked something along these lines: Write a program managing a store inventory, with a command-line client conforming to a given set of specifications. For an input file looking like this: addcategory Fruit addproduct Fruit Banana 2.30 addproduct Fruit Tomato 1.20 addproduct Fruit Apple 1.50 addproduct Fruit Apple 1.60 list Fruit The output file would be expected to look like this: OK OK OK OK ERROR Duplicate fruit Apple Fruit ----- Apple 1.50 Banana 2.30 Tomato 1.20 Of course, error messages, sorting and spacing for the output would be part of the spec. That provided an effective way of checking your program‚Äôs correctness: Run it on a given input, and compare its output - using diff - to expected output. Some TAs even provided simple test files (input + expected output) for this exact method (but not revealing the ‚Äúreal‚Äù test files which would they use while grading), but the ‚Äúserious‚Äù tests happened in the student-run ‚Äúhomework help‚Äù forum (ah, phpbb‚Ä¶), where students would regularly place gargantuan test files to compare your program against (these were very helpful in finding memory handling errors). For an advanced technique, I wrote a ‚Äúreference‚Äù implementation in Python (this is much shorter than the C version, and probably less bug-prone). I then generated random input files, fed them into both programs, and whenever the output would differ between the two - I‚Äôd found in a bug (in one of the versions). I recall a certain student festival, a friend ran up to me, and exclaimed: ‚ÄúI‚Äôm totally wasted. I‚Äôve had no sleep for the past two days, but I‚Äôve finally finished the exercise. diff [outputs] 0 [lines of difference]! Whoo!‚Äù He ran off at this point. What does all of this have to do with test-driven development? It became ‚Äúknown‚Äù that it‚Äôs better to start the exercises later, so that early-bird students will have test data up on the forum before you start. Then, just code until the tests pass. Ah, the excuses we students come up with for procrastination‚Ä¶ I‚Äôve been striving to do test-driven development ever since, with the help of proper unit testing frameworks, and it‚Äôs hard for me to think of having ever coded without it. There are plenty of resources online explaining why unit-testing is such a helpful idea‚Ä¶ all I‚Äôm saying is that you might already be testing your code, not realizing that a nice framework can help. But more on that later‚Ä¶ ","date":"2013-12-01","objectID":"/posts/test-driven-procrastination/:0:0","tags":["software","testing"],"title":"Test-driven procrastination","uri":"/posts/test-driven-procrastination/"},{"categories":null,"content":"Working with vendor code in C can get very tricky, especially when you except breaking changes to occur. Especially when you have multiple binaries depending on that vendor code, updating at different times, necessitating different live versions. Let‚Äôs explore. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:0:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Introduction Assume you‚Äôre working with an external vendor, who is providing you with code for a wonderful function getFoo: // foo.h version 1.2.3 int getFoo(); // foo.c version 1.2.3 int getFoo() { sleep(1000); // TODO improve performance return 42 } You use this function in many of your products - for example, in your best-selling barApp application: // barApp.c #include \u003cstdio.h\u003e int main() { printf(\"%d\\n\", getFoo()); return 0; } So barApp, and other applications, would want to use a foo library. It makes sense to provide this function in a shared library (libfoo.so). However, this library will change in the future, in several ways: Binary-compatible changes Performance improvements (sleep will be removed) Additional functionality will become available (new functions) Binary-incompatibile changes - at the very least, recompilation will be necessary For C, this is usually caused by changes to macros For C++, a plethora of reasons: Virtual function reimplementation, function inlining, new private data members‚Ä¶ Source-incompatible changes - these will require you to change your source code (in barApp): Functions (which you use) being removed or renamed Semantic changes - getFoo could return 43 This gets even more complicated due to the fact that barApp is an operational, mission-critical application for your organization. Developers may need to hotfix older versions of barApp, which use older versions of libfoo. The build servers and developer boxes will need to be able to have multiple versions of libfoo installed simultaneously. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:1:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Compiling, installing, and using a shared library properly First, the upstream vendor should compile libfoo.so with an SONAME, like so: gcc -shared -Wl,-soname,libfoo.so.1 -o libfoo.so.1.2.3 foo.c objdump -x libfoo.so.1.2.3 | grep SONAME # SONAME libfoo.so.1 The guarantee the upstream vendor should give is this: As long as SONAME doesn‚Äôt change, binary compatibility will be retained. Now, you (or, preferably, your package manager) should install the package on your machine like so: mkdir -p /usr/include/foo1 cp foo.h /usr/include/foo1 cp libfoo.so.1.2.3 /usr/lib ldconfig -v | grep libfoo # libfoo.so.1 -\u003e libfoo.so.1.2.3 Now, traditionally another symlink libfoo.so -\u003e libfoo.so.1.2.3 would be created, so you could compile barApp with -lfoo. However, here‚Äôs an alternative: gcc -I/usr/include/foo1 -l:libfoo.so.1 barApp.c -o barApp ldd barApp # linux-vdso.so.1 =\u003e (0x00007fff8edfe000) # libfoo.so.1 =\u003e /usr/lib/libfoo.so.1 (0x00007fb367cce000) # libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007fb367906000) # /lib64/ld-linux-x86-64.so.2 (0x00007fb367ef2000) Now barApp is compiled, and looks for libfoo.so.1 - it will find it thanks to the symlink created by ldconfig, and use libfoo.so.1.2.3. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:2:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Aftermath ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:3:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Binary-compatible updates Suppose a new, compatible, faster version of libfoo is released - say version \\1.3.0, which has removed that pesky sleep. Well, just place it in /usr/lib and rerun ldconfig. cp libfoo.so.1.3.0 /usr/lib ldconfig -v | grep libfoo # -\u003e libfoo.so.1 -\u003e libfoo.so.1.3.0 The symlink has been updated, and now all applications (barApp, for example) which were linked against libfoo.so.1 will have improved performance. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:3:1","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Incompatible updates Suppose a new, incompatible version 2.0.0 of libfoo is released, which would force the newer barApp2.0 to be recompiled against the new, different headers. No problem: mkdir -p /usr/include/foo2 cp foo.h /usr/include/foo2 cp libfoo.so.2.0.0 /usr/lib ldconfig -v | grep libfoo # -\u003e libfoo.so.2 -\u003e libfoo.so.2.0.0 # -\u003e libfoo.so.1 -\u003e libfoo.so.1.3.0 gcc -I/usr/include/foo2 -l:libfoo.so.2 barApp2.0.c -o barApp2.0 Both versions of libfoo are installed simultaneously, and do not conflict. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:3:2","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Final thoughts The Debian policy guide states that -dev packages should include the libfoo.so symlink. However, this would cause a conflict between the -dev packages for two different generations of libfoo. I am curious as to how this problem is solved ‚Äúin the wild‚Äù, as I‚Äôm sure Debian have good reasons for suggesting this. ","date":"2013-05-15","objectID":"/posts/multiple-library-versions/:4:0","tags":["software","c","linux"],"title":"Multiple library versions","uri":"/posts/multiple-library-versions/"},{"categories":null,"content":"Vacations are a great time for doing that problematic category of things every management course teaches you about: important, but not urgent. For some people, it‚Äôs housework or schoolwork which gets drowned out by day-to-day life. For others it‚Äôs keeping up with friends and family. Myself, I also like to read and write. Writing, for me, is usually about practical stuff. Sometimes it‚Äôs simply code (most of those projects were written on vacations). Other times, it‚Äôs writing to this blog (in one of its incarnations) - which usually has to do with technical tinkering of some sort or other. It‚Äôs not that I don‚Äôt do enough writing in my day job; but there does tend to be an accumulation of things to write: ‚ÄúI should blog about that‚Äù, ‚ÄúI should write that code‚Äù, ‚ÄúI should try and get my router to do that‚Äù, and so forth. When a few days off come by, and I feel that I have enough time to get more urgent stuff done - it‚Äôs quite satisfying to be able to dig into that write-queue. Reading is the same, but the other way around. I‚Äôm not talking about standard RSS feeds (Google Reader R.I.P.), which I usually only have time to skim through. I mean something pertaining to that: Once in a while, I come across an article (be it from an RSS feed, a social network, or a news site), which is too long to read immediately, but I‚Äôd really like to get into later on, when I have time. Usually it‚Äôs text, but sometimes it‚Äôs a long form video (usually from a technical conferences such as the recent C++ and Beyond or Google I/O). Either way, these past few days I‚Äôve had the opportunity to take a nice bite out of my reading queue, with some entries being over a year old. To manage this queue I use Pocket (integrates well with Chrome, Android, Feedly and others), and I highly recommend it. If you have some time off, enjoy it. Read something. Write something as well. ","date":"2013-03-27","objectID":"/posts/reading-writing-and-vacation/:0:0","tags":["life"],"title":"Reading, writing and vacations","uri":"/posts/reading-writing-and-vacation/"},{"categories":null,"content":"As part of my M.Sc. studies, I‚Äôve recently completed a small laboratory project in natural language processing. I‚Äôve learned quite a bit from it, and had a chance to use a few of my favorite technologies. The project was coded in Python, which is not my favorite programming language - Ruby is. However, since Python is more popular at my workplace, and seems to have a richer ecosystem around it (sometimes, at any rate), I‚Äôve grown to love it almost as much over the years. It‚Äôs quick, easy, and has fantastic libraries; specifically, for this project, we made heavy use of the Natural Language Toolkit. We used Git for source control and Github for hosting, Travis for continuous integration, and ReadTheDocs for documentation. All of these culminate in the project being handed in as a single link: http://github.com/lutzky/translationese. The translationese project is a re-implementation of the concepts presented in ‚ÄúOn The Features Of Translationese‚Äù, an article describing an attempt to automatically distinguish between texts written in English originally, and texts translated to English from a different language. Since this turned to be an easy problem, the focus was to determine what specific features of a given text are better at distinguishing between the two categories. Why reproduce results from an existing article? Well, beyond academic points, we wanted to provide well-documented, easily-extensible, tested code. The article was not always clear on specific definitions of various features; Python code makes these completely explicit, in a relatively readable way (for code, at any rate). To keep code quality high, we used test-driven development: each feature was coded only after a (failing) unit test for it was written. This helped keep the code modular, and made refactoring (which happened quite a bit) easy and safe. The resulting design proved to be quite flexible, as I will shortly explain. SVM is a form of machine learning. Simply put, it‚Äôs a method of teaching a machine to distinguish between two categories of ‚Äúpoints‚Äù (in our case, ‚Äútranslated‚Äù and ‚Äúoriginal‚Äù). The SVM is given two such sets, and tries to draw a ‚Äúline‚Äù (or, generally, a hyperplane) separating them. Afterwards, it should be able to classify new points (without being told which set they belong to) by which side of the line they are. The following image (Wikipedia) shows a simple, two-dimensional case (the red line properly distinguishing the two sets): For our case, each ‚Äúproperty‚Äù took a block of text, and translated it to an n-dimensional point. For some properties, the dimension was quite extreme. For example, the property of character trigrams gives each coordinate the value of ‚Äúhow many times does each permutation of three consecutive letters appear in the text‚Äù. There are 17,576 such permutations, so each text became a point in a 17,576-dimensional space. These points were fed into an SVM algorithm implemented in Weka. During the final presentation of the project, we explained that the particularly high-dimensionality properties proved to be too much for Weka (it would use up all available RAM), so smaller sample sizes were used for those. However, we were told that using sparse vector representation as Weka‚Äôs input could allow it to be more efficient. Fortunately, our design proved to be robust enough that I could implement (and test) the change during the presentation (1278645). Indeed, we now had no problems with the high-dimensionality properties, and repeated our runs, updating the documentation (after we were given our grade‚Ä¶) There‚Äôs a somewhat eerie aspect to this project. Having used SVM, I have no idea how it works. While I know exactly how my Python code works, and exactly what the SVM algorithm does, I still don‚Äôt know how to tell a translated text from one written in English originally. Even looking at the SVM output, which details exactly what the resulting classifier does, the data is the result of analyzing thousands of texts, and so","date":"2013-03-24","objectID":"/posts/translationese/:0:0","tags":["natural language processing","software","python"],"title":"Translationese","uri":"/posts/translationese/"},{"categories":null,"content":"Here is an assortment of Linux-related tips and tricks. If you‚Äôre tired of hitting your SSH password over and over again, you might want to take a look at this guide: SSH Public Key Authentication. If you‚Äôre a Technion student taking the Matam course, you should definitely check out the Matam Guide. Here is a list of lectures I‚Äôve given in Haifux: Lightning Talks 2005 (w/Many others) LIRC - Infrared Remote Control (w/Alon Altman) WiFi in Linux The VIM Editor for beginners (Rerun of Shlomi‚Äôs lecture) FatNS - How to develop a DNS forensics tool (w/Boaz Goldstein) Linux for CS Students - a Primer Linux for CS Students - Debugging If you‚Äôre with a russian keyboard and need a stress sign, try /russian-stress. ","date":"2013-03-23","objectID":"/linux-stuff/:0:0","tags":null,"title":"Linux stuff","uri":"/linux-stuff/"},{"categories":null,"content":"If you find yourself logging into SSH servers a lot, you might find this tip useful - you‚Äôll only need to type your password once per session. But first, let‚Äôs set the default username (so you don‚Äôt have to tell SSH what user you are every time): $ cd ~ $ mkdir .ssh $ chmod 700 .ssh $ cat \u003e\u003e .ssh/config Host t2.technion.ac.il User slutzky Ctrl-D $ Now, create a public/private key pair for SSH, like so: $ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/tactless/.ssh/id_rsa): Enter passphrase (empty for no passphrase): use_a_password Enter same passphrase again: use_a_password Your identification has been saved in /home/tactless/.ssh/id_rsa. Your public key has been saved in /home/tactless/.ssh/id_rsa.pub. The key fingerprint is: 5a:3a:e3:f4:6e:91:fe:3f:27:4e:f4:46:0d:5e:50:4f tactless@dolphin Now you have a public and private key: ~/.ssh/id_rsa is the private key (don‚Äôt give this to anyone!), and ~/.ssh/id_rsa.pub is the public key - give this to everyone. Specifically, put it on the SSH server you want to log into, making sure the permissions are correct. There‚Äôs a script which does this: ssh-copy-id t2.technion.ac.il It basically does the following for you: $ scp ~/.ssh/id_rsa.pub t2.technion.ac.il: password: $ ssh t2.technion.ac.il \u003e mkdir .ssh \u003e cat id_rsa.pub \u003e\u003e .ssh/authorized_keys \u003e chmod 700 .ssh .ssh/authorized_keys \u003e chmod 755 . \u003e logout Now, when you log in to your local account, before using SSH for the first time, type the following command: $ ssh-add Enter passphrase for /home/tactless/.ssh/id_rsa: your-password-here $ ssh t2.technion.ac.il \u003e # notice, didn't type a password \u003e logout $ ssh t2.technion.ac.il \u003e # no password this time either ","date":"2013-03-23","objectID":"/linux-stuff/ssh-public-key-authentication/:0:0","tags":null,"title":"SSH public key authentication","uri":"/linux-stuff/ssh-public-key-authentication/"},{"categories":null,"content":"I‚Äôve already mentioned my show downloading stack on this blog. It‚Äôs changed a bit since - I now use Transmission rather than rtorrent, as it has the excellent transmission-daemon package which has it acting exactly the way I like (without using screen). Also, it now E-mails me when a torrent is done downloading. So while this may be how TV works for you: Notice that a new episode is out Torrent it Wait for the download to finish Watch it ‚Ä¶this is how TV works for me now: Receive E-mail notification of a new downloaded episode Watch it Here‚Äôs how it‚Äôs done: First, write /usr/local/bin/notify_torrent_done: #!/bin/bash cat_the_message() { cat \u003c\u003cEOF Subject: Torrent done: $TR_TORRENT_NAME Hello from transmission $TR_APP_VERSION at $(hostname). The following torrent has completed: Name: $TR_TORRENT_NAME Finished at: $TR_TIME_LOCALTIME Downloaded to: $TR_TORRENT_DIR Hash: $TR_TORRENT_HASH Enjoy! EOF } RETVAL=1 while [[ $RETVAL != 0 ]]; do cat_the_message | msmtp -C /etc/msmtprc.transmission --from default -t your@email.address RETVAL=$? done The various environment variables will be set by transmission when it calls this script. We rerun msmtp until it succeeds because you will often get a ‚Äúconnection timed out‚Äù response from gmail (‚Ä¶at least on my ISP‚Ä¶). Here‚Äôs /etc/msmtprc.transmission which is relevant to gmail (this is a bit tricky and took a lot of fiddling around with): defaults tls on tls_starttls on tls_trust_file /etc/ssl/certs/ca-certificates.crt timeout 60 account default host smtp.gmail.com port 587 auth on user yourusername@gmail.com password yourpasswordhere from yourusername@gmail.com syslog LOG_MAIL As usual, caution is required when saving your password in plaintext. I highly recommend using Google‚Äôs two-step authentication, which will have you creating a one-time password for each application - use one of those one-time passwords here. Finally, in /etc/transmission-daemon/settings.json, add the following code: \"script-torrent-done-enabled\": true, \"script-torrent-done-filename\": \"/usr/local/bin/notify_torrent_done\", Important: You need to run /etc/init.d/transmission-daemon reload at this point, not restart - that would cause settings.json to be rewritten from runtime configuration. That‚Äôs it. Enjoy! ","date":"2011-12-15","objectID":"/posts/the-show-downloading-stack-part-n1/:0:0","tags":["show downloading"],"title":"The show downloading stack - part n+1","uri":"/posts/the-show-downloading-stack-part-n1/"},{"categories":null,"content":"Here are a few words on developing TransportDroidIL, a small utility to query Israeli public transportation sites more easily using an Android phone. Source control is super important. Mistakes will be made, other coders will want to join in, and experimental features will want to be in their own branches. Git is awesome; it does source control right, gives me powerful tools, and isn‚Äôt a hassle to set up - even for a small project like this. Github is also awesome; it makes collaboration with other coders - even just one, in my case - easy, organized, and fun. One of my favorite git features is revert. It allows you to automatically inverse a previous change. Here‚Äôs an example from TransportDroidIL: 0e194de. This commit reverts a previous ‚Äúcleanup‚Äù commit in the autocompletion code - allegedly, I was keeping two copies of the autocompletion option list for no reason: One as a LinkedList\u003cstring\u003e, and one internal to the AutoCompleteTextView which I can access via an ArrayAdapter\u003cstring\u003e. Turns out that my LinkedList\u003cstring\u003e copy is necessary, because the ArrayAdapter\u003cstring\u003e always behaves as though it‚Äôs empty, so it cannot truly be read from. Despite having performed a few commits since that bad ‚Äúfix‚Äù, git was very helpful in letting me revert that particular change, showing me the conflicts this operation causes, and allowing me to fix them. The lesson is an important one: Make small, manageable commits. Git is optimized for this, as commits are local (no need to contact the server until a push). Developing for Android makes a lot of sense when using Eclipse. I‚Äôm a VIM junkie, and generally dislike IDEs. Eclipse is slow and heavy - but it gets the job done, and it does it very well. It‚Äôs a bit weird that a plugin is required to manage color schemes - but it exists. It‚Äôs very weird (and quite annoying) that it doesn‚Äôt remove end-of-line white-space, and doesn‚Äôt have an option to do this. This makes git complain. There is an option to add ‚Äúclean-up‚Äù settings which are activated on every save, but this is far too cumbersome and might change code I didn‚Äôt intend to change (which becomes confusing in the revision log). Still, the excellent debugging, JUnit and logcat support are worth it. Logcat is another awesome feature of Android. Every logged line has both a ‚ÄúTag‚Äù (usually defined per-class) and a severity. Logs can be filtered with a different severity for each tag, and still - one can use the same logcat to show messages from anything running on the Android device at the moment. It‚Äôs basically Syslog done better. One last point is about Hebrew. This has been a problem with Android for quite a while; for example, in a stock Android 2.3.3, numbers embedded in Hebrew string appear backwards. Fixes exist, and are implemented in most Israeli ROMs, especially the ones distributed by phone carriers - but they‚Äôre different, and sometimes don‚Äôt work for all applications. This causes numbers to appear backwards in TransportDroidIL, which in turn caused me to implement an ugly hack. I hope the upcoming Ice Cream Sandwich release fixes this. ","date":"2011-10-08","objectID":"/posts/developing-transportdroidil-for-android/:0:0","tags":["android","TransportDroidIL"],"title":"Developing TransportDroidIL for Android","uri":"/posts/developing-transportdroidil-for-android/"},{"categories":null,"content":"I don‚Äôt like wireless connections; they‚Äôre always second-best, be it in terms of security, speed, or reliability. Here‚Äôs how my apartment looks (very approximately): .-P1----. .-------------------P4-,---------, | PC | | COMFY SOFA . | | | | . Closed | | .-, | | Living room . Porch | | |B| P2 | . | | |E| | . | | |D| | HUGE CUPBOARD TV . R PC | `-------' `-P3-------------------'--P5-----' My room The room on the left is mine, with my (constantly torrenting) PC in bed-viewing position. The router (R) is in the closed porch, connected to my roommate‚Äôs PC. Wifi doesn‚Äôt stand a chance through two walls and the porch‚Äôs glass screen. P1 through P5 are power outlets. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:0:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"First solution Put a reverse DD-WRT router at P2 (with a cable going across the room from the PC). Slow connection, not very reliable. This worked well enough for several months. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:1:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"Second solution Get a pair of homeplugs. Stick one at P1 (connected through a power strip shared by the PC, speakers, screen and guitar amp). Stick another at P5 (connected through a power strip shared by the other PC, router, modem, TV, fan, printer, speakers and a lamp). It shouldn‚Äôt work - but it does. It blinks red, is nowhere near the promised 200Mbps, but it‚Äôs still faster (and more reliable) than my internet connection. These homeplug devices are fantastic - they require literally no configuration (unless you want to reconfigure the encryption keys) and work very well, I highly recommend them. The problem was when I got an Xtreamer - a cute device to watch my shows on my living room TV (see: comfy sofa). Once I plug it in, the homeplug connection dies on me, proverbially the last straw. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:2:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"Third solution Thankfully, I have my Big Box of Electronic Junk, which contained a Super Long (read: haven‚Äôt measured it) network cable. Moved the homeplug to P3, hid the cable behind the Huge Cupboard. Problem solved. On a side note, I would have preferred a Boxee Box, but sadly it doesn‚Äôt support lame old RCA connections. ","date":"2011-09-04","objectID":"/posts/home-network-wiring/:3:0","tags":["networking"],"title":"Home network wiring","uri":"/posts/home-network-wiring/"},{"categories":null,"content":"Hello everyone, TransportDroidIL 1.0 will be released this month. It has quite a few new features: Separate ‚ÄúSource‚Äù, ‚ÄúDestination‚Äù and ‚ÄúTime‚Äù fields. This is much better for auto-completion as well. Automatic location-based detection of ‚ÄúSource‚Äù. Hopefully you‚Äôll find the interface for this unobtrusive. Quick reversal of ‚ÄúSource‚Äù and ‚ÄúDestination‚Äù, for your return trip. A new settings screen, with: Provider selection (currently Egged or MOT) A small attempt at right-to-left fixes for non-supporting devices. A ‚Äúclear history‚Äù button Everyone loves screenshots: Separate source and destination fields Select data provider Automatic location detection, Egged provider For a sneak peek, go to http://github.com/lutzky/TransportDroidIL for the latest sources. You can also report issues there. ","date":"2011-09-02","objectID":"/posts/upcoming-features-in-transportdroidil/:0:0","tags":["TransportDroidIL","android"],"title":"Upcoming features in TransportDroidIL","uri":"/posts/upcoming-features-in-transportdroidil/"},{"categories":null,"content":"Don‚Äôt get me wrong. I love being able to communicate textually with friends, coworkers and family. It‚Äôs ideal for a noisy pub; a somewhat-private conversation on a crowded bus; telling something to someone who may be asleep, so they see it first thing when they wake up; making quick responses while in a meeting without being rude (well, at least at my workplace it‚Äôs considered perfectly acceptable). It‚Äôs also very handy when you want to tell someone something they ought to write down, such as a phone number or something they should remember to buy. My problem isn‚Äôt with the concept of mobile textual messaging - it‚Äôs with SMS, the ‚ÄúShort Message Service‚Äù, as provided by Israeli carriers (and possibly worldwide). The first problem I‚Äôd like to discuss is length. SMS messages are limited to 160 characters, or rather - 160 bytes. If your message includes any foreign characters, such as Hebrew letters, then UTF-16 mode takes effect, and your message is limited to 70 characters, which is ridiculously short. While the name of the service, SMS, implies that the messages should indeed be short, this is not the only common usage: If you want to have an actual conversation with someone (and this is a perfectly reasonable situation), messages will be longer than 160 characters, and certainly longer than 70. The problem becomes worse if u dont want to use shorthands n skip punctuations like many smsers do. (Ever found yourself about to send a 75-character message, going over it to find 5 characters to trim without looking like an idiot?) There have been several attempts to overcome the short-message problem, all of them implemented as workarounds in cellphone software. The initial, primitive approach was to simply split a message up into appropriately-sized chunks, and send out those chunks as separate messages: A 150-character Hebrew message would be sent out as 3 separate messages (70, 70, 10 characters respectively). Later on, a mechanism was invented for the phones to detect the split messages, stitch them back up on the recipient‚Äôs phone, and notify the recipient if the message is incomplete. Poor man‚Äôs TCP. The split-message solution is very problematic, especially when taking into account two other problems with SMS: Reliability and price. The reliability problem is subtle: SMS message usually make it across, but when they don‚Äôt (and sometimes, in fact, they don‚Äôt), no notification is given. Where E-mail servers notify you about delivery failure, where instant messaging services tell you that the other party has disconnected, SMS has‚Ä¶ nothing. There‚Äôs no way to know that your message hasn‚Äôt been received, unless a little-known, not-supported-everywhere and highly annoying ‚Äúread receipt‚Äù feature is enabled. The price problem is completely absurd: I have a small 1GB plan at Orange, which costs 70‚Ç™/month. That‚Äôs 70 NIS / 1GB, 1GB being 109 bytes. That comes to 7 \u0026times 10-6 Agorot per byte. Suppose that an SMS-style service would need a bloated 100-byte header, so an SMS message is 260 bytes. Therefore, an SMS message should cost 0.00182 Agorot. In reality, it costs 44 Agorot (inter-carrier average) without a plan, or 14 Agorot (at best, requiring a 1000-SMS plan) with a plan. That‚Äôs between 7692√ó and 24176√ó as much. One additional problem with SMS is the fact that they‚Äôre locked into your device. Got a new phone? You have to go through a very complicated process to transfer your SMS messages over, and this isn‚Äôt possible for every phone. Lost your old phone? Unless you were backing up manually, your messages are gone. Have a separate work-phone? You‚Äôll need to use each phone to see messages sent specifically to it. None of these problems occur with an online E-mail provider, why should they happen with mobile texting? With modern phones, sending and receiving E-mail is just as easy as sending and receiving SMS messages. The main problem is that not everyone has a modern phone, and E-mail on older phones is quite cumbersome. Worse yet, ","date":"2011-04-25","objectID":"/posts/sms-and-why-it-annoys-me/:0:0","tags":["phones"],"title":"SMS and why it annoys me","uri":"/posts/sms-and-why-it-annoys-me/"},{"categories":null,"content":"Since I‚Äôve last posted, I‚Äôve moved to a new apartment. First order of business - get a working internet connection. This is extra-challenging when your primary machine doesn‚Äôt even have a wireless network card. My first hack used my trusty laptop - it has a properly working wireless card, and could connect to my roommate‚Äôs router quite easily. It runs Ubuntu, and as it turns out, that means sharing the connection was dead-simple: Right-click on the network manager icon, add a new wired connection called ‚ÄúShared‚Äù, and under IPv4 settings, choose ‚ÄúShared to other computers‚Äù. That‚Äôs it. Once I connected my desktop to my laptop, it automatically got all of its settings, and I was good to go. However, this was kind of annoying - I had to leave my laptop on, the reception in my room isn‚Äôt perfect so it would sometimes disconnect (requiring manual intervention), and my laptop wasn‚Äôt free for ordinary use (if I wanted my torrents to keep going). The solution: I grabbed my (horrible) old D-Link DIR-300 router, and installed DD-WRT on it. This gave it an awesome ‚Äúclient mode‚Äù feature, which allowed it to use it the same way I used my laptop to bridge my wireless connection. Flashing it worked quite well by following the guide (the updated version in the wiki, that is - it has proper instructions for connecting to RedBoot, the D-Link flashing interface, from Linux), and another guide helped me set up Client mode. All seems well, except for two issues: First, port forwarding doesn‚Äôt seem to work properly - it works well on the internal network (that is, I can SSH into my desktop using my laptop), but not on the internet (SSH port shows up as open, but I can‚Äôt connect). I‚Äôm also guessing that UPnP/NAT-PMP won‚Äôt work properly. Second, and this is an old problem - the router has a high-pitched whine. This may have something to do with the fact that the AC/DC adapter it came with is rated for 12V @ 1A, whereas the router is rated 5V @ 1.2A. Let‚Äôs hope it doesn‚Äôt fry (hasn‚Äôt for the 3 years I used it). ","date":"2010-11-20","objectID":"/posts/dd-wrt-awesomeness/:0:0","tags":["networking","hardware"],"title":"DD-WRT awesomeness","uri":"/posts/dd-wrt-awesomeness/"},{"categories":null,"content":"After a couple of days‚Äô messing with it, I‚Äôm releasing it: Transport Droid IL! It‚Äôs a handy little app for querying Egged‚Äôs site, as well as the new Ministry of Transportation site, on transportation information. This is pretty beta, but seems to work well enough. More info, source code: http://lutzky.github.com/TransportDroidIL APK File: TransportDroidIL.APK ","date":"2010-09-04","objectID":"/posts/transport-droid-il/:0:0","tags":["TransportDroidIL","android"],"title":"Transport Droid IL","uri":"/posts/transport-droid-il/"},{"categories":null,"content":"There are several good guides for installing Gilad Ben-Yossef‚Äôs excellent Hebdroid fonts on physical Android devices, but those don‚Äôt really work with the Android SDK‚Äôs emulator - changes to the system directory aren‚Äôt persistent. Here‚Äôs how to get around that: First, a few downloads. You‚Äôll need: The android emulator (presumably you already have this, if not, you can get it at developer.android.com) The hebdroid fonts unyaffs, which will extract the system.img file A snapshot of yaffs2, which will create our new system.img file. This is actually today‚Äôs snapshot from the git repository, which worked for me. For later versions, take a look at the git repository. Building unyaffs is simple enough, or you can use the prebuilt version from the site. Building mkyaffs2image is also quite easy - just untar the snapshot, and run make in the utils directory. Put both of these utilities somewhere in your $PATH for convenience. Now we can get to work. First, locate your system.img file. It should be within your Android SDK directory, under platforms/android-3/images (or whatever version you‚Äôre emulating). We‚Äôll extract that - create a temporary directory, say /tmp/system.img.hebdroid, and cd to it. Then run: unyaffs /path/to/system.img The whole /system filesystem should be extracted. Now extract the ttf files from hebdroid.zip into the fonts directory, replacing the original font files. To pack everything back up, run: mkyaffs2image /tmp/system.img.hebdroid system.img.hebdroid Now, I recommend putting renaming your original system.img to system.img.orig, and using symlinking system.img.hebdroid as your new system.img (the emulator does indeed follow symlinks), but you can basically do whatever you like. You may have to recreate your AVD, but everything should work. Happy hacking! ","date":"2010-09-04","objectID":"/posts/setting-up-hebrew-android-fonts-on-your-avd-emulator/:0:0","tags":["android"],"title":"Setting up Hebrew Android fonts on your AVD emulator","uri":"/posts/setting-up-hebrew-android-fonts-on-your-avd-emulator/"},{"categories":null,"content":"I‚Äôve finally gotten the chance to get one of those newfangled Android phones. I‚Äôve recently ‚Äúbought‚Äù a Samsung Galaxy Android phone (the older i7500, not the newer i9000 ‚ÄúS‚Äù) model. It‚Äôs a seriously serious upgrade from my old Nokia 6120 Classic, and as I broke the 6120‚Äôs screen and reverted back to my trusty old Nokia 6070 (which I couldn‚Äôt even get to run the GMail app), I was quite a happy camper switching to a modern phone. The whole idea of Android has always been very appealing to me - Nokia‚Äôs software has been declining in quality, and while Motorola and Samsung have always made excellent hardware, they could never get the knack of good software. Google has. Problem solved, right? The Android software is miles ahead of anything I‚Äôve ever seen, including iPhone. I now have connectivity everywhere, and apps to sync all of my favorite things - GMail and Google Calendar are included, GTasks is great for tasks, Paperdroid is great for Read It Later, NewsRob is great for Google Reader. The Facebook and Twidroyd applications are also quite nice, and the convenience has me using those networks more. I even have nifty stuff like Transdroid, a Transmission web client which is actually very good at adding torrents while I‚Äôm away, so they‚Äôre done by the time I get home. I get my reading done with Aldiko and ACV (for comics). Even Israeli sites have some good applications up, such as YNet and Dapei Zahav have a nice Android app, though not as nice as their iPhone ones. And of course, there‚Äôs the wonderful Waze, which is the most Israeli solution to the road congestion problem I‚Äôve ever seen. I‚Äôve even had the chance to do some on-foot navigation with Google Maps, which is also handy. The phone itself has a beautiful AMOLED screen, great audio quality (comes with quite a good set of headphones as well), and looks sleek. The touchscreen is responsive enough (though not anywhere near new Android devices nor the iPhone/iPod touch), and it even comes with a free extra 8GB SD card, for a total of 16GB. And now, to rant. Battery life isn‚Äôt what is should be - the phone is awesome, I want to use it, and it can barely get through the day - especially if I‚Äôm doing heavy stuff like Waze (GPS + Data + screen is always on + voice), but even if I‚Äôm just surfing casually. The unlock button is located inconveniently on the bottom part of the right side, just above the camera button. The home button is located between the Back and Send buttons, meaning it‚Äôs very easy to hit by accident; it‚Äôs not even labeled. The CPU isn‚Äôt always fast enough to keep everything completely smooth, and while this is generally acceptable, it gets rather irksome in odd places: If you turn on screen auto-rotation (which uses more battery power), rotation takes a while and might be accidental. However, there is no manual screen rotation option as far as I can tell. As a music player (relating to my previous post), the device works well enough - but I couldn‚Äôt, for the life of me, get Hebrew support in ID3 tags (no matter what the encoding is), and only a limited subset of ID3 tag versions is supported, and everything works much better with Ogg files. The flaws I‚Äôve mentioned are relatively minor and nitpicky - for Waze, you can use the car charger (which comes with the phone, thankfully). The buttons are OK after some getting used to (and installing the excellent AnySoftKeyboard), and operation is generally smooth. However, there is a major issue I can‚Äôt wrap my head around - the shipped firmware is 1.5 cupcake, and there are absolutely zero updates available from Samsung. There is a semi-official leaked 1.6 update which, as I‚Äôve heard, is quite buggy. An awesome guy called drakaz has been working on a Froyo (2.2) port for the Galaxy, which I really should check out, but Samsung‚Äôs behavior on this topic is inexcusable in my opinion. All-in-all, however, I‚Äôm happy with my phone. It‚Äôs a joy to use, and the price is hard to beat - free with my phone plan, provided I can rake ","date":"2010-09-04","objectID":"/posts/android/:0:0","tags":["hardware","android","phones"],"title":"Android","uri":"/posts/android/"},{"categories":null,"content":"My Meizu Mini M6 has died a tragic death as a result of being left in my shirt pocket, which in turn was - with the rest of my shirt - in the laundry. I‚Äôve had it for three years, so this would be a good time to review. My favorite thing about the Mini was the cost. When I bought it, it was far cheaper than comparable players, at ~400‚Ç™ for 8GB. For a player with good video support, it was a steal. Other pros it had include: Great screen. I used to watch TV shows on it quite a bit Great audio quality, especially in the lower range - very important for a bass guitarist Perfect OS compatibility - shows up as a Mass Storage device, just drag your files over. This is also how firmware upgrades are performed EBook reader, of sorts Quite small and very thin However, the player is full of quirks: Slow startup time. This is compounded by the fact that to turn it on, you have to press the ‚ÄúPlay‚Äù button for about 3 seconds - too much less or too much more, and it won‚Äôt start up. This is even worse when unplugging it from USB - it would rebuild the library every time, even if you were just charging it. You can‚Äôt turn the player on when it‚Äôs connected to USB. When it‚Äôs off, connecting it to USB is for charging only - to access the filesystem, you have to disconnect it, turn it on, and connect it again. (‚Ä¶not that the player is functional when in it‚Äôs plugged in‚Ä¶) A few podcast niceties would be very easy to implement and extremely helpful. There‚Äôs no way to separate podcasts from the rest of the music, so you don‚Äôt get ‚ÄúThis Week In Tech‚Äù when you put it on ‚ÄúAll Music at random‚Äù mode. Also, the player doesn‚Äôt keep track of positions within audio streams, other than the last played one. There‚Äôs no way to delete a song from within the player. The interface is very inconsistent, with the video and audio sections having completely different key bindings. Long presses and short presses have very different meanings (but the length isn‚Äôt all that different), so you have to be very careful. Pressing various key during startup had interesting, non-obvious effects, such as rebuilding the music library or formatting the player without asking for confirmation. This isn‚Äôt in the official documentation, and even if it were - that‚Äôs a very bad misfeature. The newer version of the player, which I have, did away with the bottom ‚Äúplay‚Äù button, and moved it to the bottom of the 4-way D-pad, instead of the ‚ÄúEnter‚Äù key. The ‚ÄúEnter‚Äù key was replaced with a tap on the d-pad. Unfortunately, such a tap is very similar to a volume change drag, and even if it weren‚Äôt - is very easy to perform by accident. One more feature that I would have liked is one I‚Äôve only seen in the iPod (which I despise for a variety of reasons) - the iPod keeps track of which songs you‚Äôve played all the way through, and remembers that you ‚Äúlike‚Äù them - this information is later used when building playlists, and is integrated into iTunes playlists as well. Now, I might be going to a long course soon, one which will specifically mean plenty of bus time. So go ahead, guys - recommend a player. :) ","date":"2010-03-13","objectID":"/posts/my-music-player-has-sunk/:0:0","tags":["hardware"],"title":"My music player has sunk","uri":"/posts/my-music-player-has-sunk/"},{"categories":null,"content":"Last weekend I broke my Nokia 6120‚Äôs screen. I have a military phone, which is far cheaper, so I‚Äôve decided to keep it offline. However, being the sentimental guy that I am, I did want to save all of my contacts and SMS messages (in addition to the photos, which presented less of a problem). This proved to be a bit of a challenge without the screen working. Usually, when you connect the phone via USB, it asks if you want ‚ÄúPC Suite mode‚Äù or ‚ÄúData Transfer mode‚Äù. The ‚ÄúData Transfer‚Äù mode has the phone show up as a standard USB storage device, which allows for easy transfer of MP3 files, photos and videos to and from the phone, without any nokia-specific software. However, it only works for the external SD card, so you can‚Äôt use that to access SMS messages or contacts. I usually only need ‚ÄúData Transfer‚Äù mode, so I changed the default to that. Today I regret that decision, as it cost me a couple of hours‚Äô work. I called the Orange hotline, and they did their best to help me, including trying to blind-guide me through the menus, which failed because the menus are actually dynamic and I didn‚Äôt have the default setup. They actually got me 90% of the way there - here‚Äôs the solution I found: Hit the red (disconnect) button, and type the Soft Reset GSM code: *#7780#. Now press the ‚Äúleft menu‚Äù key (not the left key, nor the menu key - the left of the two ‚Äúdynamic‚Äù keys) - this part was what the Orange hotline missed, because it seemed so obvious. Then hit 12345 (this is the default ‚Äúsecret code‚Äù), and the left menu key again. I found this by watching a demo of the soft reset on YouTube. At this point I used VirtualBox and the Nokia PC suite (both are free-as-in-beer) to do the heavy lifting. I now have a text file with all of my contacts, a CSV file with all of my SMS messages, and all of my images saved both to my computer and a DR site. Now I just need to upgrade my military phone (Mirs)‚Ä¶ ","date":"2009-10-31","objectID":"/posts/broken-phone-screen-data-rescue/:0:0","tags":["hardware","phones"],"title":"Broken phone screen - data rescue","uri":"/posts/broken-phone-screen-data-rescue/"},{"categories":null,"content":"Totem is Gnome‚Äôs built-in media player, and it really annoyed me in previous versions, and had me switching to VLC. However, the version included in the Ubuntu 9.10 release candidate has two features which are very important, in my opinion. The first feature is smooth graphical integration with compositing managers (such as compiz). In previous versions, as well as VLC, once you fullscreen the window, moving the mouse (which causes the cursor and the partial interface to appear) causes a very annoying flicker. This has been fixed (at least on my box, using an NVidia card). The second, more important feature, is the exact one I‚Äôve been missing and talked about in the previous post - hit Edit -\u003e Preferences -\u003e Start playing files from last position, and Totem will keep track of your last playback position when you close the video. Reading the implementation patch shows that there is a certain threshold for this - the position won‚Äôt be saved if you‚Äôre too close to the beginning or end of the video. So there, my show downloading stack now has every feature I‚Äôd want from Miro, without the downsides I‚Äôve mentioned. ","date":"2009-10-10","objectID":"/posts/loving-the-new-totem/:0:0","tags":["show downloading"],"title":"Loving the new Totem","uri":"/posts/loving-the-new-totem/"},{"categories":null,"content":"I love watching TV, and hate it. Regular show schedules are horrible, commercial breaks are annoying, and the ability to rewind is very important. I love Hot‚Äôs VOD service (and happily pay to watch the shows I enjoy), but my true favorite for getting my entertainment is everyone‚Äôs favorite not-a-dumptruck, the internet. In this post, I will describe how I do it. Everything I describe in this post can be done using miro. It‚Äôs a neat piece of software, which lacked polish in version 2.4 (2.5 is out now though), but there are a few things I don‚Äôt like about it: You have to be graphically logged in for it to run. Among other things, this means that if someone reboots your computer, there‚Äôs no way to get it to start automatically. (I‚Äôll be very happy to know if I‚Äôm wrong about this) It doesn‚Äôt give you as much control as I‚Äôd like over torrents. Its BitTorrent client doesn‚Äôt perform as well as rtorrent. However, Miro does one thing which I haven‚Äôt figured out how to do myself yet: It keeps track of your position within watched shows. That is, stop watching a show -and next time playback will resume from the same place. The first thing you want to do is get a good RSS feed for your show. Unfortunately, Revision3‚Äôs shows (many of which are quite good), are direct HTTP download links, as per the advertiser‚Äôs request. For other shows, you can find torrent RSS feeds, which make much better use of everyone‚Äôs bandwidth. Also, downloading will be handled by our trusty rtorrent, which we can configure for bandwidth limiting. To download RSS feeds, I use flexget. It does its job well, but doesn‚Äôt support bandwidth limiting. It accepts a simple YAML configuration file, and has good logging. I run it as a cron job - its locking mechanism prevents multiple instances from running simultaneously. For non-torrents, I set the output directory to ~/torrents/inbox. For torrents, I set the output directory to ~/torrents/from_rss. For downloading torrents, I use rtorrent. It‚Äôs a curses-based client which performs very well. My .rtorrent.rc file looks like this: download_rate = 30 upload_rate = 2 directory = /home/ohad/torrents/in_progress on_finished = move_complete,\"execute=mv,-u,$d.get_base_path=,~/torrents/inbox/ ;d.set_directory=~/torrents/inbox/\" session = /home/ohad/torrents/.session schedule = watch_directory,5,5,load_start=/home/ohad/torrents/from_rss/*.torrent schedule = untied_directory,5,5,remove_untied= schedule = throttle_1,23:00:00,24:00:00,download_rate=0 schedule = throttle_2,05:00:00,24:00:00,download_rate=30 port_range = 6881-6889 encryption = allow_incoming,enable_retry,prefer_plaintext dht = auto peer_exchange = yes scgi_local = /tmp/rtorrent-scgi.socket Interesting things to note here are: Downloads live in one directory, but get moved to the inbox directory when they‚Äôre done. The session directory is important - this allows rtorrent to resume downloads if it‚Äôs shut down. The from_rss directory is watched for new torrent files. When the relevant downloads are stopped, remove_untied occurs and the torrent files are deleted. Throttling is fully customizable. The SCGI socket is useful for rtgui - we‚Äôll get to that. I have a ‚Äúwatchdog‚Äù-style cron job which makes sure it‚Äôs running if the computer is up. This is not as elegant as starting it from an RC-script, but keeps the whole setup confined to the limits of my own user. Again, rtorrent has a lock-file which prevents multiple instances from running. #!/bin/bash # A simple script to make sure I am running rtorrent in a screen set -e SCGI_SOCKET=/tmp/rtorrent-scgi.socket SESSION_DIR=~/torrents/.session screen -d -m -fn -S rtorrent -s /bin/bash -t rtorrent -m nice rtorrent while [[ ! -S $SCGI_SOCKET ]]; do sleep 1; done if [[ -S $SCGI_SOCKET ]]; then chgrp www-data $SCGI_SOCKET chmod g+rwx $SCGI_SOCKET fi RTGUI provides a nice web-based interface. It‚Äôs a bit tricky to configure, and you‚Äôll need to use an HTTP server - preferably lighttpd, as it has support for SCGI UNIX sockets (as oppose","date":"2009-09-05","objectID":"/posts/my-show-downloading-stack/:0:0","tags":["show downloading"],"title":"My show downloading stack","uri":"/posts/my-show-downloading-stack/"},{"categories":null,"content":"I‚Äôve been trying to work out a system to be able to cleanly switch between IST (Israel Standard Time, GMT+2:00) and IDT (Israel Daylight savings Time, GMT+3:00) on command. The logical way to do this, in my opinion, is to have two separate files in /usr/share/zoneinfo, say IsraelIST and IsraelIDT, and copy (or link) the relevant one as /etc/localtime. The trick is creating the IsraelIDT file. My first guess was the following zic source-file: # Zone NAME GMTOFF RULES/SAVE FORMAT [UNTIL] Zone IsraelIDT 2:00 01:00 IDT Now, this almost works. The problem is that both is_dst is set and timezone = -10800 (3 hours - should be 2, as it should represent local standard time), so some software double-compensates here for a grand total of GMT+4:00. After some research (walking through __tzfile_read gave the biggest hint), it turns out that timezone is set according to the minimal local time type which is transitioned into. So I came up with this file: # Rule NAME FROM TO TYPE IN ON AT SAVE LETTER/S Rule ZionIDT min 1939 - Jan 1 00:00 1:00 D Rule ZionIDT 1939 only - Jan 1 00:00 0:00 S Rule ZionIDT 1940 max - Jan 1 00:00 1:00 D # Zone NAME GMTOFF RULES/SAVE FORMAT [UNTIL] Zone IsraelIDT 2:00 ZionIDT I%sT Sounds about right, nay? Even my handy little pyzdump confirms that it looks about how I want it to: $ ./pyzdump.py /usr/share/zoneinfo/IsraelIDT Transitions: ['At Sat Dec 31 23:00:00 1938, switch to IST', 'At Sun Dec 31 22:00:00 1939, switch to IDT'] Types: [\u003ctztype dst=\"True\" idt:=\"\" utc+10800=\"\"\u003e, \u003ctztype dst=\"False\" ist:=\"\" utc+7200=\"\"\u003e] However, it still doesn‚Äôt work. A test program: int main() { tzset(); time_t t = time(NULL); printf(\"Timezone name is %s, timezone=%ld\\n\", __tzname[1], timezone); printf(\"The time is %s\", ctime(\u0026t)); printf(\"Timezone name is %s, timezone=%ld\\n\", __tzname[1], timezone); return 0; } And its results, as run at 14:42:17 UTC, which is 19:42:17 IDT: Timezone name is IDT, timezone=-7200 The time is Sat Apr 18 14:42:17 2009 Timezone name is UTC, timezone=0 Or, as I described it to a friend: Me: Hi computer, do you know what timezone are we in? Computer: Yeah, it‚Äôs Israel Daylight Savings time, GMT+2:00 for standard time. Me: OK, and what time is it? Computer: 14:42 Me: No, that‚Äôs 3 hours late. What timezone are we in? Computer: Umm‚Ä¶ UTC? Me: You just said IDT. Computer: Nuh-uh. I‚Äôll get to the bottom of this eventually :/ Addendum: It seems that the problem is even more complicated. For the following timezone file, C programs seem to work fine: # Rule NAME FROM TO TYPE IN ON AT SAVE LETTER/S Rule ZionIDT min 1939 - Jan 1 00:00 1:00 D Rule ZionIDT 1939 only - Jan 1 00:00 0:00 S Rule ZionIDT 1940 2030 - Jan 1 00:00 1:00 D Rule ZionIDT 2030 max - Jan 1 00:00 0:00 S # Zone NAME GMTOFF RULES/SAVE FORMAT [UNTIL] Zone IsraelIDT 2:00 ZionIDT I%sT However, Python programs still show timezone = -10800. Examining Python‚Äôs code, I found this: if( janzone \u003c julyzone ) { /* DST is reversed in the southern hemisphere */ PyModule_AddIntConstant(m, \"timezone\", julyzone); PyModule_AddIntConstant(m, \"altzone\", janzone); PyModule_AddIntConstant(m, \"daylight\", janzone != julyzone); PyModule_AddObject(m, \"tzname\", Py_BuildValue(\"(zz)\", julyname, janname)); } else { PyModule_AddIntConstant(m, \"timezone\", janzone); PyModule_AddIntConstant(m, \"altzone\", julyzone); PyModule_AddIntConstant(m, \"daylight\", janzone != julyzone); PyModule_AddObject(m, \"tzname\", Py_BuildValue(\"(zz)\", janname, julyname)); } And since June and July have the same timezone in our case, there‚Äôs a good chance that this is what‚Äôs going wrong. The moral of the story seems to be this - I should go with the first, simplest ‚Äúalways-DST‚Äù solution. Programs should ignore the timezone variable, as in our context it isn‚Äôt reliable. In general, all internal time handling should be done in UTC; when reading times from the outside world, if they are in local time - use mktime. If they are in a specified timezone, use timegm and compensate manually. I‚Äôd love to hear better idea","date":"2009-04-18","objectID":"/posts/timezones-are-fickle/:0:0","tags":["linux"],"title":"Timezones are fickle","uri":"/posts/timezones-are-fickle/"},{"categories":null,"content":"At my workplace, I‚Äôve recently been using git for code review purposes. I work on code in my own git clone, and ask a peer to review it. It works somewhat like this: master branch is same code as currently in upstream. Working to resolve issue #1234 pertaining to ‚ÄúPerformance for gizmo‚Äù, I work on a branch 1234-gizmo-performance. I mail a peer, John, with this information, as well as my repository location. John adds my repository as a remote, lutzky. Then he branches review1 (or review2 if that is taken, and so on) at lutzky/1234-gizmo-performance. John adds comments with nice big FIXME tags, which are highlighted in any decent editor. He commits this, the commit-message stating that it was code review. John tags his final review commit (or, if he had no comments - lutzky/1234-gizmo-performance) with a reviewed1 (or reviewed2, etc.) annotated tag. Since the annotated tag includes all the necessary information (who tagged, when, and what), the number doesn‚Äôt really matter. I merge john/review1, incorporate the changes (or reject them) and remove the comments. If no further review is necessary, I submit this - and once submitted, I merge this back into master. It‚Äôs a nice system. I wonder what other methods there are of doing this. ","date":"2009-04-04","objectID":"/posts/using-git-for-code-review/:0:0","tags":["git"],"title":"Using git for code review","uri":"/posts/using-git-for-code-review/"},{"categories":null,"content":"I‚Äôm a software kind of guy. Here‚Äôs proof. Today I went to visit my grandparents, and it turned out their computer wouldn‚Äôt boot. BIOS would load up fine, and I could browse the menus fine - but once it tried to go on from there, it would simply blink what looked like half a cursor (that is, half of a _-style cursor). I figured it might be the HDD - so I took it home, and decided to connect it to my own box. Upon disconnecting my DVD drive, I destroyed the SATA cord - it had an annoying little metal tab which had to be pushed in before it would release, and it just wouldn‚Äôt give, and the connector just broke, exposing and bending the wires. Checking if the computer still boots, the BIOS took much longer to display hard drive status, and while Ubuntu would start booting, it would fail in the process and tell me that my root hard drive (by UUID) isn‚Äôt available. Looking at dmesg, the ata2 module was indeed reporting that the hard drive was too slow - but a few seconds later it would finally access the drive, and mount properly. This problem, however, disappeared once I connected my grandparents' drive! (Mounting it would fail, telling me that I either have a hardware error or need to connect it to a Windows machine, which I don‚Äôt have, and run some diagnostic commands). Sure enough, when the HDD is connected by itself, it gets quite flaky, but once I connect a second drive (back to the DVD, eventually), everything works properly. This probably has to do with the fact that both drives are connected on continuations of the same power cord - but I‚Äôve never experienced such a problem, where you must connect devices to both connectors on the power cord. A hardware guy I know says he‚Äôs never heard of such a problem either. Naturally, these things never happen when I mess with hardware at work, where there are plenty of spare parts‚Ä¶ ","date":"2009-02-26","objectID":"/posts/hardware-doesnt-like-me/:0:0","tags":["hardware"],"title":"Hardware doesn't like me","uri":"/posts/hardware-doesnt-like-me/"},{"categories":null,"content":"I had a Game Boy once. I could play it just about anywhere, and battery life - for the time - was great. I lost it at one point, and replaced it with a Game Gear, which sucked the life out of 6 AA batteries rather quickly. The Game Boy Color was actually decent on battery life, but since it didn‚Äôt have a backlight, you had to play it at very specific angles. For gaming, I can appreciate the need for a color screen. My point has to do with cellphones. True, most cellphones today come with cameras, are able to play video, and are rather capable mobile gaming platforms (when compared to the Game Boy, that is). All this does, in fact, require a color screen. However, I believe that there is a market for cellphones which do not support these features, but do support neat things like 3G internet connectivity (GMail and RSS on the phone is a major Win, in my opinion), and have a comfortable SMS interface. These features actually suffer from having a color screen: Battery life (for the powerful backlight), viewing angle, and screen resolution take a hit. While it‚Äôs true that color LCDs have come a long way since the Game Gear, so have black \u0026 white display technologies (E-Paper, anyone?). Of course, my wish for a modern B\u0026W-screen cellphone will likely never come true. The simple reason is that they would be totally unmarketable. Even business-types like color screens nowadays. So I‚Äôll just keep holding out for a folding E-Paper mobile browser. ","date":"2008-11-22","objectID":"/posts/whatever-happened-to-black-white-lcds/:0:0","tags":["hardware","phones"],"title":"Whatever happened to black \u0026amp; white LCDs?","uri":"/posts/whatever-happened-to-black-white-lcds/"},{"categories":null,"content":"Ever have a machine you can only ssh into through another machine? It‚Äôs a very common situation in the Technion. Here‚Äôs one way to get around it: Assume you can directly ssh into alpha, and from alpha you can ssh into beta. Have the following code in your ~/.ssh/config: Host beta Hostname 1.2.3.4 # IP Address of beta ProxyCommand ssh alpha nc -w 1 %h %p This requires you to have nc (netcat) installed on alpha. Once you do that, you can run ssh beta directly from your own box. ","date":"2008-11-10","objectID":"/posts/another-ssh-trick/:0:0","tags":["networking"],"title":"Another SSH trick","uri":"/posts/another-ssh-trick/"},{"categories":null,"content":"These days I don‚Äôt stay at home often, but I do have an RSS/BitTorrent combo fetching me all kinds of neat stuff for me, so I can have it ready for me on the weekend. I love rtorrent, especially due to the fact that I can run it in screen, ssh home and see how things are doing (or add more torrent to the download). However, sometimes my net connection breaks down, computers gets shut off, or things like that. This week my router broke down, so I can‚Äôt even ssh home to manually start up rtorrent. My solution: A small script, which checks whether rtorrent is already running, and if not - runs it in a detached screen session. Run this with your favorite cron software. #!/bin/bash # A simple script to make sure I am running rtorrent in a screen if ! ps -o uname -C rtorrent | grep -q `whoami`; then screen -d -m rtorrent fi ","date":"2008-11-04","objectID":"/posts/automatically-starting-rtorrent-within-screen/:0:0","tags":["linux"],"title":"Automatically starting rtorrent within screen","uri":"/posts/automatically-starting-rtorrent-within-screen/"},{"categories":null,"content":"Gnome 2.24 adds a new Time Tracking feature, which I would have found useful. I don‚Äôt have Gnome 2.24 at work, but I do have a Unix-based operating system‚Ä¶ Here‚Äôs my new ~/bin/track: #!/bin/bash date \u003e\u003e ~/time_tracking vim ~/time_tracking + Now, if I could only get vim to automatically hit ‚ÄúA‚Äù and space for me afterwards‚Ä¶ (I‚Äôm betting there‚Äôs a way to do it, but AFAIK vim can only receive ex-mode commands as parameters). Edit: ‚Ä¶and, of course it‚Äôs possible. Here‚Äôs the new version: #!/bin/bash echo \"`date` \" \u003e\u003e ~/time_tracking vim ~/time_tracking + -c 'startinsert!' ","date":"2008-10-26","objectID":"/posts/quick-time-tracking-hack/:0:0","tags":["linux"],"title":"Quick time tracking hack","uri":"/posts/quick-time-tracking-hack/"},{"categories":null,"content":"Sometimes, when constructing a compound object, we are interested in exporting functionality while retaining encapsulation. For example, suppose we have a Secretary class: class Secretary def send_fax(destination, fax_contents) puts 'Sending fax \"%s\" to %s' % [fax_contents, destination] end def answer_call(call) # ... end # ... end Our Secretary provides a lot of useful functionality, that our Boss class would like to have. Boss would like to be able to say that he can send a fax, without having the user explicitly request his Secretary beforehand. The same goes for a lot of other methods Secretary provides. Instead of writing a stub function for each of these methods, it would be nice to do the following: class Boss delegate_method :my_secretary, :send_fax, :answer_call def initialize @my_secretary = Secretary.new end end john = Boss.new john.send_fax(\"Donald Trump\", \"YOU'RE fired\") Here‚Äôs how we can get this to happen: class Class def delegate_method(instance_var_name, *method_names) method_names.each do |method_name| define_method(method_name) do |*args| instance_var = instance_variable_get(\"@%s\" % instance_var_name) instance_var.send(method_name, *args) end end end end This solution does have its drawbacks - it will not work for methods which are meant to accept blocks. I‚Äôm not sure how to get that to happen, short of using a string-based class_eval, which I‚Äôm not very fond of. (I find eval to be, well, evil‚Ä¶) ","date":"2008-10-18","objectID":"/posts/delegating-methods-in-ruby/:0:0","tags":["ruby"],"title":"Delegating methods in Ruby","uri":"/posts/delegating-methods-in-ruby/"},{"categories":null,"content":" Ditz was lost in the mists of time, and I guess if ttime were maintained, issues would be tracked using Github. I‚Äôve added issue tracking for ttime using the fantastic ditz. I‚Äôve also added ttime‚Äôs rdoc documentation. (Note: Version 0.8.5 is out) ","date":"2008-07-30","objectID":"/posts/tracking-ttime/:0:0","tags":["ttime"],"title":"Tracking TTime","uri":"/posts/tracking-ttime/"},{"categories":null,"content":"Edit: I was misled! Illustrated here. Hints below. \u003e\u003e def inspect_x_and_y(x,y); puts \"x: %p, y: %p\" % [x, y]; end =\u003e nil \u003e\u003e inspect_x_and_y(y={\"hello\" =\u003e \"world\"},x=[1,2,3]) x: {\"hello\"=\u003e\"world\"}, y: [1, 2, 3] The bits I didn‚Äôt know about: \"Format strings using a %% sign, %s, %s!\" % [ \"just like in python\", \"but with arrays\" ] The %p formatting character is the same as inspect. You can call methods with method_name(param2=val2, param1=val1), also like in python. No you can‚Äôt! This code sets external variables called y and x. How embarassing‚Ä¶ :( ","date":"2008-07-25","objectID":"/posts/three-things-i-didnt-know-ruby-does/:0:0","tags":["software","ruby"],"title":"Three things I didn't know Ruby does","uri":"/posts/three-things-i-didnt-know-ruby-does/"},{"categories":null,"content":"This site gets indexed by the almighty google. This link is part of a security project I‚Äôm doing for my CS degree. The was part of project BadSense. See the BadSense report ","date":"2008-07-23","objectID":"/posts/security-project/:0:0","tags":["security"],"title":"Security project","uri":"/posts/security-project/"},{"categories":null,"content":"I was having a lot of trouble with gettext in Ruby, mostly due to lacking documentation. Here are some useful things I figured out while writing TTime. I ended up having a single gettext_settings.rb, included from every file which uses gettext. Here it is (with some extra notes) #!/usr/bin/ruby begin require 'gettext' require 'pathname' include GetText # This fixes a swarm of problems on Windows GetText.locale.charset = \"UTF-8\" # Ruby's gettext acts in a sane # method - add a path to the set of paths # scanned. locale_in_data_path = Pathname.new($0).dirname + \\ \"../data/locale/%{locale}/LC_MESSAGES/%{name}.mo\" add_default_locale_path(locale_in_data_path.to_s) bound_text_domain = bindtextdomain(\"ttime\") # For Glade, however, it only seems to # be possible to specify one path at a # time. Fortunately, gettext already # found it for us. my_current_mo = bound_text_domain.entries[0].current_mo if my_current_mo ENV[\"GETTEXT_PATH\"] = my_current_mo.filename.gsub( /locale\\/[^\\/]+\\/LC_MESSAGES.*/, \"locale/\") end rescue LoadError def _ s #:nodoc: # No gettext? No problem. s end end One note for context: I use setup.rb (and ruby-pkg-tools) to package TTime. So my localizations go in data/locale. ","date":"2008-07-20","objectID":"/posts/gettext-oddities-with-ruby/:0:0","tags":["ruby"],"title":"Gettext oddities with Ruby","uri":"/posts/gettext-oddities-with-ruby/"},{"categories":null,"content":"I has it. Sorta. A few weeks ago, the lovely NaNuchKa visited Israel for two and a half shows (the half-show was warming for Berry Sacharof). ‚ÄúThree shows in two weeks?‚Äù, people ask - well, yeah. They only come once a year. Their set is already too long to play all the songs I like, and that‚Äôs actually quite excellent - new EP and all. Great stuff :) Deep Purple should be coming to Israel this summer (holy crap!), and I need to see what I can do about getting tickets for that. This is my last semester at the Technion - then it‚Äôs off to the military for me. Courses for this semester are Electronic Switching Circuits (bleh‚Ä¶), Signals and Systems (which is actually turning out to be quite awesome!), and the neat Compilation Theory. After having thoroughly enjoyed Eli Biham‚Äôs excellent Modern Cryptology last semester, I‚Äôm visiting (but not taking) his advanced topics course this semester. I also have two projects: One in computer security, where we mess with Google, and another in EE, where we try using transactional memory in order to optimize Apache. And finally - next week on Thursday, Shlomi Shaban is doing a piano show in Haifa, just like the good old days. He was supposed to join NaNuchKa for one of their shows, but had to cancel, so my lovely lady (who introduced me to his work in the first place) and I haven‚Äôt been to his shows in quite a while. It seems that will be able to use the new 200 line - part of a long overdue project to have cheap public transportation available all night long. ","date":"2008-07-11","objectID":"/posts/that-life-category-there/:0:0","tags":["life","technion","music"],"title":"That \"Life\" category there","uri":"/posts/that-life-category-there/"},{"categories":null,"content":"I‚Äôve found myself working on TTime, the Technion Timetable Scheduler, quite a bit lately. Lots of cool stuff went in: Boaz Goldstein‚Äôs TCal, a Cairo-based schedule renderer (could you believe the old version used MozEmbed?) Sports courses are now correctly parsed Ability to select specific lectures and groups for the automated scheduler A manual scheduler - given an existing schedule, you can ask to show all alternatives at once, and hand-pick them. Some people (Tom, for example) prefer this. Just for kicks - interoperability with Grandpa‚Äôs XML format I‚Äôve also cleaned up the packaging quite a bit - it can now be installed using setup.rb, or the updated Debian package. I think it may soon be time to tag a release :) Sources at Github ","date":"2008-07-11","objectID":"/posts/been-working-on-ttime/:0:0","tags":["ttime"],"title":"Been working on TTime","uri":"/posts/been-working-on-ttime/"},{"categories":null,"content":"Today at the CS department of the Technion is a particularily Bad Network Day (TM) for laptop users; none of the wired connections at the farm work, and wireless doesn‚Äôt seem to working for HTTP at all. It does, however, work for SSH. Ka-ching! :) Tunneling your browser over SSH is a pretty simple affair - SSH into somewhere which has a decent connection, and use the -D9999 flag (9999 works, but it can be any 16-bit number over 1024). Then, configure your browser to work over a SOCKS proxy at 127.0.0.1:9999. How do you, however, get other things to work over that tunnel? There‚Äôs an excellent program called dante-client (that‚Äôs an apt package, folks. if you can‚Äôt apt-get due to your network situation, get it at packages.ubuntu.com or packages.debian.org). Install it, and make sure /etc/dante.conf has the following lines: route { from: 0.0.0.0/0 to: 0.0.0.0/0 via: 127.0.0.1 port = 9999 protocol: tcp proxyprotocol: socks_v4 socks_v5 } Then, run socksify whatever-you-want-to-do. For example, sudo socksify apt-get install something. Or perhaps socksify ssh somewhere. Or sudo wget something. Or socksify git do-something-awesome. (All of the above work for me) ","date":"2008-06-17","objectID":"/posts/tunelling-even-more-stuff-over-ssh/:0:0","tags":["networking"],"title":"Tunelling even more stuff over SSH","uri":"/posts/tunelling-even-more-stuff-over-ssh/"},{"categories":null,"content":"I neglected to post this here somehow, it‚Äôs about a month old by now‚Ä¶ Screenshot lost in the mist of time‚Ä¶ shows a program segfaulting, and then working properly when run within valgrind. The problem turned out to be an imprecise (false-positve) comparison operator implemented for a class used as a hash key. God, I hate C++. ","date":"2008-06-11","objectID":"/posts/valgrind-fail/:0:0","tags":["software"],"title":"Valgrind Fail","uri":"/posts/valgrind-fail/"},{"categories":null,"content":"So, I see I forgot to post my schedule for this semester‚Ä¶ ‚Ä¶ttime screenshot lost in the mists of time‚Ä¶ As you can see, it‚Äôs TTime! With a shiny new Cairo interface. We‚Äôre back to the Ruby version, too - as we have another coder on board, which is using his compilation skills in order to write a new REPY parser. You can also see it‚Äôs only found one schedule. This is thanks to the group selection constraint which was finally coded. Yes, that‚Äôs a link to the Github repository for TTime. You‚Äôre welcome to help write some constraints :) ","date":"2008-06-02","objectID":"/posts/scheduling/:0:0","tags":["ttime"],"title":"Scheduling","uri":"/posts/scheduling/"},{"categories":null,"content":" You can use git on a VFAT disk (for example, a USB key) without all of the annoying mode issues, by using the following setting in .git/config: [core] filemode = false What I haven‚Äôt figured out is how to do force a chmod in this situation; for example, if I create a new script, I was hoping to be able to git chmod +x it. Cream is a very good editor if you‚Äôre used to Windows applications. It‚Äôs a set of plugins for VIM which make it modeless and (very) familiar to Windows users. However, Ctrl-O still has its usual job for us ordinary junkies :) Vertically, two cans of Pepsi fit very snugly into a Pringles can. ","date":"2008-04-28","objectID":"/posts/things-i-learned-today/:0:0","tags":["linux","git","asides"],"title":"Things I learned today","uri":"/posts/things-i-learned-today/"},{"categories":null,"content":"Deskbar has a really neat plugin which allows you to search your browsing history and bookmarks. Firefox 3 has switched the storage format to an sqlite-based one. I‚Äôve been working on a new plugin to make use of that - so far it‚Äôs very enjoyable to use :) ¬ª Deskbar_FF3 ","date":"2008-04-28","objectID":"/posts/deskbar-and-firefox-3/:0:0","tags":["linux"],"title":"Deskbar and Firefox 3","uri":"/posts/deskbar-and-firefox-3/"},{"categories":null,"content":"This one took me a while to figure out, which is reason enough to post it here. First of all, you‚Äôll need aspell-he, as pidgin uses gtkspell (which, in turn, uses aspell) rather than enchant (which supports hspell). There is a patch for gtkspell which gets it to use enchant, but I don‚Äôt know of a simple way to get it to work in my distribution of choice, Ubuntu. Now you need a neat little plugin from the Guifications plugin pack, called SwitchSpell. Unfortunately, it‚Äôs in version 2.3.0 of the pack, whereas the current Ubuntu version is 2.0.0. It‚Äôs not complicated to install this from source though: I‚Äôve detailed the precise installation procedure below; the confusing thing is that if you forget to install libgtkspell-dev or libaspell-dev, SwitchSpell will not be built, but the configure script tells you that it will. sudo apt-get install build-essential gettext libgtkspell-dev libaspell-dev pidgin-dev wget http://downloads.guifications.org/plugins//Plugin%20Pack/purple-plugin_pack-2.3.0.tar.bz2 tar jxvf purple-plugin_pack-2.3.0.tar.bz2 cd purple-plugin_pack-2.3.0 ./configure --with-plugins=switchspell make sudo make install At this point, the Switch Spell plugin should show up in your Pidgin preferences. When you activate it, you should get a menu at the top of each conversation for choosing the dictionary in use. Enjoy! ","date":"2008-04-22","objectID":"/posts/hebrew-spell-checking-in-pidgin/:0:0","tags":["linux"],"title":"Hebrew spell-checking in Pidgin","uri":"/posts/hebrew-spell-checking-in-pidgin/"},{"categories":null,"content":"Due to an exercise in an AI course, I‚Äôm forced to confront an old nemesis - C++. Part of the reason is that the exercise contains a time-limited tournament, and the code needs to run very quickly. Another reason is, I guess, the fact that C++ serves as a sort of lowest common denominator in the course (which used, by the way, to be taught in LISP, along with the language). I never liked C++ language much. As a matter of fact, I prefer C. I‚Äôve been going over some old code for a project, which needed to use DBus to talk to NetworkManager. Back then I wrote it using Python, embedded in C - it seemed easier at the time, due to lack of documentation. After hunting around, I figured out how to do most of the stuff I wanted in C, using DBus‚Äôs GLib API. In this process, the most helpful bit of documentation turned out to be GLib‚Äôs. GLib looks like a wonderful library to get big-program stuff done relatively nicely in C, without mucking about in C++. Exception handling (of sorts), object-oriented programming (of sorts) as well as garbage collection (of sorts) are implemented in a usable way, and extremely well-documented. At the end of the day, I was able to turn this Python gem: import dbus def _nm_device_interface(dev_object): \"\"\"Returns an interface to the device object dev_object\"\"\" return dbus.Interface(dev_object, NM_DEVICE_IFACE) def _nm_get_object(object_path): \"\"\"Returns an object with the given object path using the NM service\"\"\" return dbus.SystemBus().get_object(NM_SERVICE, object_path) def _nm(): return _nm_get_object(NM_OBJECT_PATH) def _nm_dbus_exception(e, guessed_exception): \"\"\"Checks if the DBus exception e is (exactly) of type guessed_exception\"\"\" try: return e.get_dbus_name().endswith(guessed_exception) except: # If it doesn't have a get_dbus_name, it probably isn't the DBus # exception we're looking for. return False def _nm_all_device_interfaces(): \"\"\"Return a list of interfaces to all devices NM sees\"\"\" try: return [ _nm_device_interface(_nm_get_object(devicename)) for devicename in _nm().getDevices() ] except dbus.DBusException, e: if _nm_dbus_exception(e, \"NoDevices\"): return [] # No devices means list of devices is empty else: raise ‚Ä¶into this C gem: #define DBUS_SERVICE_NM \"org.freedesktop.NetworkManager\" #define DBUS_PATH_NM \"/org/freedesktop/NetworkManager\" #define DBUS_INTERFACE_NM \"org.freedesktop.NetworkManager\" #define NM_ERR_NODEVICES \"org.freedesktop.NetworkManager.NoDevices\" gboolean is_remote_dbus_exception(GError *error, char * exception_name) { g_assert(error); if (error-\u003edomain != DBUS_GERROR || error-\u003ecode != DBUS_GERROR_REMOTE_EXCEPTION) return FALSE; if (!exception_name) return TRUE; return strcmp(dbus_g_error_get_name(error), exception_name) == 0; } GPtrArray * get_nm_devices(DBusGConnection *connection, GError **err) { GError *tmp_error = NULL; DBusGProxy *proxy; GPtrArray *ptr_array; g_return_val_if_fail(connection != NULL, NULL); proxy = dbus_g_proxy_new_for_name( connection, DBUS_SERVICE_NM, DBUS_PATH_NM, DBUS_INTERFACE_NM); dbus_g_proxy_call(proxy, \"getDevices\", \u0026tmp_error, G_TYPE_INVALID, dbus_g_type_get_collection(\"GPtrArray\", DBUS_TYPE_G_PROXY), \u0026ptr_array, G_TYPE_INVALID); if (tmp_error != NULL) { if (is_remote_dbus_exception(tmp_error, NM_ERR_NODEVICES)) { g_error_free(tmp_error); return NULL; } else { g_propagate_error(err, tmp_error); return NULL; } } g_object_unref(proxy); return ptr_array; } The C code runs much faster, and I suspect is more maintainable then its original counterpart (which uses embedded python in C). ","date":"2008-04-16","objectID":"/posts/faster-languages/:0:0","tags":["software","c","python"],"title":"Faster Languages","uri":"/posts/faster-languages/"},{"categories":null,"content":"YNet was running a story on how to use your computer as an alarm clock. Here‚Äôs what I do, for our commandline junkies :) Here‚Äôs ~/bin/run_alarm.sh: #!/bin/bash find ~/music/ -name '*.mp3' -print0 | xargs -0 mplayer -shuffle \u0026 MAXVOL=31 TIME=900 for (( i = 0; i \u003c= $MAXVOL; i++ )); do amixer set Master $i \u003e /dev/null; sleep `echo $TIME / $MAXVOL | bc -l` done This basically plays all of my MP3 files, in random order. The -print0 and -0 arguments make it a null-terminated list, as some (most) files have spaces in their names. This process is backgrounded, and the script proceeds to gradually sweep the volume from 0 to the maximum, for a more gentle wakeup :) This script is basically intended for use with at. I made a little wrapper around it for my comfort: #!/bin/bash if [ -z \"$1\" ]; then echo \"Usage: $0 [time]\"; exit 1; fi echo /home/ohad/bin/run_alarm.sh | at $1 ","date":"2008-02-12","objectID":"/posts/my-alarm-clock/:0:0","tags":["linux"],"title":"My alarm clock","uri":"/posts/my-alarm-clock/"},{"categories":null,"content":"I‚Äôve switched to a Nokia 6120 Classic, and I‚Äôve switched my carrier over to Orange. I‚Äôm very happy with it: The price is right, at 0 NIS a month (if your monthly bill adds up to over 100 NIS without it, which it does). It‚Äôs very small, but has a nice screen and a respectable 2 megapixel camera. It‚Äôs ‚Äú3.5G‚Äù, which means it has a very fast internet connection (I‚Äôve clocked over 50kbyte/sec), and the Symbian S60 operating system lets me use it well - it comes with a very, very nice webkit-based browser and RSS reader, and a fast GMail client is a few clicks away. Another nice feature is the built-in MP3 player - which is actually made relevant due to the micro-SD support and included 1GB SD card. The device has a standard USB connection (cable included, but it‚Äôs an ordinary Mini-to-A cable), and has a Mass Storage Device mode, so it works well with any OS. It can also automatically text-to-speech the name of the caller (or dial by voice recognition, which works remarkably well), which is handy when listening to MP3s. I‚Äôve only had two problems with it so far - first, when viewing a long web page (on wikipedia, specifically), it gave an ‚Äúout of RAM‚Äù message and rebooted. I‚Äôm curious as to whether there‚Äôs a simpler, non-CSS version of Wikipedia, or a way to get the phone to ignore the CSS - this will probably save on RAM. Another problem I had was that the vibration feature didn‚Äôt work until I rebooted it - but this no longer seems to occur. I wonder how well puTTy would work on this‚Ä¶ ","date":"2008-02-11","objectID":"/posts/nokia-6120-classic/:0:0","tags":["hardware"],"title":"Nokia 6120 Classic","uri":"/posts/nokia-6120-classic/"},{"categories":null,"content":" The Egged Getter has been lost in the mists of time. However, it‚Äôs code has largely been integrated into TransportDroidIL. An old version of the Python code has been pasted at the end of this post. Here‚Äôs a little something I‚Äôve been messing with: A simple fetcher script for the Egged (Israeli bus company) site. I‚Äôve made a deskbar applet which uses it, which was fun to do :) (I‚Äôm looking for other cool ideas to implement as deskbar applets) You can get it at http://lutzky.net/files/egged_getter. The readme file includes installation instructions (‚Ä¶which involve placing the two included scripts in ~/.gnome2/deskbar-plugin/modules-2.20-compatible/. There‚Äôs also a git repository here: http://git.lutzky.net/?p=ohad/egged_getter.git. I don‚Äôt think I‚Äôve mentioned git on the blog before‚Ä¶ It‚Äôs freaking awesome. It made me really despise subversion :). Besides the abundance of information on the main site, there‚Äôs an excellent (and very amusing) talk by Linus about it. Also, I‚Äôm giving a talk about it in Haifux - this coming Monday (February 4th), the Taub building of the Technion, room 6, at 18:30. #!/usr/bin/python # coding: utf-8 import socket try: from pyfribidi import log2vis except ImportError: def log2vis(s): return s # Original values which worked: # User agent (a sane browser agent): # USERAGENT=\"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9b2) Gecko/2007121016 Firefox/3.0b2\" # Session ID: Can be retrieved from the site, but seems to have a very long # keepalive, and isn't checked anyway. # SESSION_ID=\"thjbzmnrhrks3a55w1dymvnx\" BUF_LEN=2048 HOST='mslworld.egged.co.il' PORT=80 DOUBLE_NEWLINE=\"\\r\\n\\r\\n\" USER_AGENT=\"EggedGetter\" SESSION_ID=\"0\" JSON_DATA=\"\"\"{\"str1\":\"%(query)s\",\"strSession\":\"%(session_id)s\"}\"\"\" _payload=\"\"\"POST /eggedtimetable/WebForms/wsUnicell.asmx/getAnswer HTTP/1.1 Host: mslworld.egged.co.il User-Agent: %(user_agent)s Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-us,en;q=0.5 Accept-Charset: utf-8 Keep-Alive: 300 Connection: keep-alive Content-Type: application/json; charset=utf-8 Referer: http://mslworld.egged.co.il/eggedtimetable/WebForms/wfrmMain.aspx?width=1280\u0026state=3\u0026taavura=0\u0026language=he\u0026freelang= Content-Length: %(content_length)d Cookie: ASP.NET_SessionId=%(session_id)s Pragma: no-cache Cache-Control: no-cache %(json_data)s\"\"\".replace(\"\\n\",\"\\r\\n\") def build_json_data(query, session_id = SESSION_ID): \"\"\"Build a JSON-formatted query for the egged site.\"\"\" return JSON_DATA % { 'query':query.replace('\"','\\\\\"').encode(\"utf-8\"), 'session_id':session_id, } def build_request(query, session_id = SESSION_ID): \"\"\"Build an HTTP request for the egged site.\"\"\" json_data = build_json_data(query, session_id) return _payload % { 'user_agent':USER_AGENT, 'content_length':len(json_data), 'session_id':session_id, 'json_data':json_data, } def send_query(query, session_id = SESSION_ID): \"\"\"Prepare and send query to site. Returned data is raw.\"\"\" http_data = build_request(query) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((HOST,PORT)) s.send(http_data) data = s.recv(BUF_LEN) s.close() return data def clean_response_html(response,linebreak=\"\\n\",item=\"\\n * \"): if response[0] == response[-1] == '\"': response = response[1:-1] BR = \"\\u003cbr\\u003e\" LI = \"\\u003cli\\u003e\" NBSP = \"\u0026nbsp\" return response.replace(BR,linebreak) \\ .replace(LI,item) \\ .replace(NBSP,\" \") \\ .replace(\"\\\\\",\"\") def query_site(query): \"\"\"Query the egged site with query\"\"\" site_response = send_query(query) returned_data = site_response.split(DOUBLE_NEWLINE)[1] try: cleaned_data = clean_response_html(returned_data) except: print \"Error occured when trying to clean up the following response:\" print \"site_response:\" print site_response print \"returned_data:\" print returned_data raise return unicode(cleaned_data, \"utf-8\") if __name__ == '__main__': query = unicode(raw_input(\"Enter query for Egged site: \"),\"utf-8\") result = query_site(query) print \"\" try: print log2vis(result) except UnicodeEncodeEr","date":"2008-02-01","objectID":"/posts/egged-getter-0-1/:0:0","tags":["software"],"title":"Egged Getter 0.1","uri":"/posts/egged-getter-0-1/"},{"categories":null,"content":"On an online board, friends posted a photo from a party a while back, as I‚Äôm chewing some extra-sour chewing gum: ◊ó◊û◊ï◊¶◊ß◊ô ◊†◊ï◊ú◊ì I find this suitable for use in macro form. For example, in the Computer Security course, we‚Äôre going to compromise a windows-based server using a buffer overflow vulnerability. Unfortunately, this means we‚Äôre going to have to use (as per the course‚Äôs demands) Visual Studio 2003. My response (now known as ◊ó◊û◊ï◊¶◊ß◊ô): ","date":"2007-12-19","objectID":"/posts/sour-chewing-gum/:0:0","tags":["asides"],"title":"Sour chewing gum","uri":"/posts/sour-chewing-gum/"},{"categories":null,"content":"New URL - not interesting. You‚Äôd notice by now, as you‚Äôve been redirected. Guess my new E-mail. OpenID - interesting, but I don‚Äôt have anything particularily interesting to say about it right now. This, however, is interesting: ‚Äú10 things christians and atheists can (and must) agree on‚Äù, a nicely written piece over at cracked.com. But this isn‚Äôt blogspam, I‚Äôll actually share my two cents. (or shnekel, if you like) I have a serious problem with religion; It is my opinion that it is an overly powerful means of control. Whether it has evolved as such or not is hard to tell. But today it seems to pose a very serious threat to the world. Now, don‚Äôt get me wrong - control of this type is very important and useful. Specifically, it manifests itself in a basic moral system which, many believe, has served mankind well. You know, ‚Äúthou shalt not murder‚Äù, stuff like that. Some may even say that it was a central factor in overcoming our primal urges, and development into the ever-so-slightly more sophisticated society we are today. However, there are other, more dangerous manifestations of this control. Specifically, it seems all-too-easy nowadays to get up and say ‚ÄúThis-and-that god has spoken to me - we must kill those-and-them‚Äù. ‚ÄúGod has spoken to me, we must, uh, enlighten these our-religious-character-rejecting other-religion-followers. There‚Äôs some oil in it for us, too‚Äù. ‚ÄúThis land has been promised to us this-and-that years ago, we must kill all other-religion-dwellers‚Äù. Of course, the link here is politics. When used as a series of anecdotes, morals, stories, hell - even as a way of life - religious is mostly harmless. However, when a religious leader becomes a political figure, the temptation is simply too great, and religion becomes used as a tool of the agenda. It doesn‚Äôt take a whole staff of advisors and a big media budget to convince the public now - it only takes a proper connection with arbitrary dogma to do that. Throughout the years, the secular public has wished for separation of church and state. But noone has yet stated it better than George Carlin - ‚ÄúKeep thy religion (or, in accordance with the linked post, thy lack thereof) to thyself.‚Äù ","date":"2007-12-17","objectID":"/posts/means-of-control/:0:0","tags":["life"],"title":"Means of control","uri":"/posts/means-of-control/"},{"categories":null,"content":"The most recent events in my life which I would consider to be vacations would be the second Lebanon war and my basic training. I love the Technion, but I think it‚Äôs high time for some R\u0026R. With no upcoming tests hovering over my head, homework pressure low-to-nonexistent, and my girlfriend‚Äôs birthday Murphy‚Äôs-law-bendingly coinciding with her getting some leave, this is a perfect opportunity to try my hand at a real vacation. Okay, so it‚Äôs just two days, but I could hardly ask for anything better. The location is a Tzimmer recommended by friends and family. My parents have graciously lent me the car for the purpose. Last but not least, I‚Äôve gotten my hands on some massage oil. :-) Studying at the Technion can get rather hectic. But hell, I have just one more year to go, after which I undergo lime-tinted metamorphosis. Perhaps low-key, nearby, short-term vacations are all I can afford. But with good friends, a wonderful girlfriend, and a geeky way of getting excited at seemingly mundane things, I can‚Äôt complain. Even with EE atrocities in my recent past and, in all likelihood, my near future, I can‚Äôt help but wear an annoying smile on my face. ","date":"2007-11-04","objectID":"/posts/vacation/:0:0","tags":["life"],"title":"Vacation","uri":"/posts/vacation/"},{"categories":null,"content":" All links in this post have been lost to the mists of time. I‚Äôve kept it here out of pure nostalgia. I‚Äôm typing the lectures of the course 236343 Computability Theory this semester. Attached are my lectures notes in PDF form: Computability Lecture Notes Computability Tutorial Notes If you also type the notes and would like to collaborate with me, I use a git repository stored here: http://yasmin.technion.ac.il/ohad/git/computability.git To use it, install git-core and curl, and run git clone http://yasmin.technion.ac.il/ohad/git/computability.git Any changes you have - send to me as patches, or push to your own repository and send me a link. (Drawings would be most welcome, and you‚Äôre obviously welcome to add your name to the list of typers) If you need git storage, try repo.or.cz, or ask the T2 admins to install git :) ","date":"2007-10-31","objectID":"/posts/computability-typed-lectures-and-tutorials/:0:0","tags":["technion"],"title":"Computability - Typed Lectures and Tutorials","uri":"/posts/computability-typed-lectures-and-tutorials/"},{"categories":null,"content":"Reading some backlog on this blog, I found the following gem: It‚Äôs a sad state of affairs that people go ahead and limit access to their wireless network. I keep mine wide open - ◊û◊ô ◊©◊ê◊ï◊õ◊ú ◊ú◊ë◊ì, ◊û◊™ ◊ú◊ë◊ì. Yeah‚Ä¶ not so anymore. For about four weeks (just a bit before the semester started), my net connection was working excrutiatingly slow. Now, we‚Äôre four roommates here, so we started blaming each other. But then I had a guess - I encrypted my connection with WPA/TKIP, and presto; the connection is now once again too fast for my browser to handle (‚Ä¶which sent me back to Epiphany). Guys, if you mooch wi-fi, please‚Ä¶ be nice about it :( ","date":"2007-10-28","objectID":"/posts/encrypted-my-wi-fi/:0:0","tags":["networking"],"title":"Encrypted my Wi-fi","uri":"/posts/encrypted-my-wi-fi/"},{"categories":null,"content":"Writing multi-threaded applications in Python is often a headache because of the Global Interpreter Lock - only one Python thread can run at any given moment, which makes multi-threading useful only in the case where all modules but one actually run C code. However, thanks to the impressive new Python Magazine, I‚Äôve stumbled across a package called processing, paraphrasing python‚Äôs built-in threading package. Essentially, the package provides an API identical to Python‚Äôs threading, but uses processes and pipes (or other mechanisms on non-posix operating systems) instead. What the magazine does not cover is the fact that this can also benefit GUI applications; updating a progressbar in the application doesn‚Äôt need to slow down heavy computations being done in a separate thread. To show how easy the integration is, take the following example which shows usage of either threads or processes at the user‚Äôs choice: import processing import threading import Queue import time import gtk import gobject gtk.gdk.threads_init() USE_PROCESSING = False WORKER_DELAY = 1.0 GUI_DELAY = 0.5 def f(q, sq): print \"Init other thread\" i = 0 while sq.empty(): time.sleep(WORKER_DELAY) q.put(i) print \"Other thread: %d\" % i i += 1 def update_label((l, q, sq)): print \"Updating label\" try: i = q.get_nowait() l.set_text(\"Number in thread: %d\" % i) except Queue.Empty: l.set_text(\"Queue is empty!\") except processing.Queue.Empty: l.set_text(\"Queue is empty!\") return sq.empty() def close(window, sq): sq.put(True) gtk.main_quit() if __name__ == '__main__': if USE_PROCESSING: q = processing.Queue() sq = processing.Queue() p = processing.Process(target = f, args = [q, sq]) else: q = Queue.Queue() sq = Queue.Queue() p = threading.Thread(target = f, args = [q, sq]) p.start() w = gtk.Window() l = gtk.Label() gobject.timeout_add(int(1000*GUI_DELAY), update_label, (l,q,sq)) w.add(l) w.connect('destroy', close, sq) w.show_all() print \"Mainloop!\" gtk.main() ","date":"2007-10-13","objectID":"/posts/on-threading-vs-processing/:0:0","tags":["software","python"],"title":"On Threading vs. Processing","uri":"/posts/on-threading-vs-processing/"},{"categories":null,"content":"My girlfriend just asked me what just might be the hardest question I‚Äôve heard all semester; What do I like better, The Simpsons or beer? ","date":"2007-09-25","objectID":"/posts/tough-question/:0:0","tags":["life"],"title":"Tough Question","uri":"/posts/tough-question/"},{"categories":null,"content":"I‚Äôve been a very big proponent of Subversion so far, especially as a tool for collaborating on coding homework. However, I‚Äôve recently been trying out Linus‚Äôs git. It‚Äôs very nice so far, and really seems to be catching on. Some good points: Fast as all hell (much faster than Bazaar, although I haven‚Äôt given that the proper attention) No need for a central server; hell, no need for an internet connection at all, everything can be done over USB keys or whatnot No real need to configure any special server; just install git on it Very nice alternative to configuring write-control for all of the users Very easy branching and merging, finally! SVN really shows its weakness here One thing I couldn‚Äôt find out how to do is limiting read-access to git repositories without special server configuration. It would be nice if git had support for .htpasswd-compatible authentication, those are pretty easy to use. ","date":"2007-09-18","objectID":"/posts/really-liking-this-git-thing/:0:0","tags":["git"],"title":"Really liking this git thing","uri":"/posts/really-liking-this-git-thing/"},{"categories":null,"content":"Lately I‚Äôve been working on a project that has me using DBus a lot. After trying to figure out how to work DBus with C, and seeing how easy it is to do in Python, we figured we‚Äôd try to use embedded Python to do this. Fortunately, it‚Äôs very simple to use - especially thanks to this guide. It later turned out to be much easier to do in C, as described in Faster Languages. Now, we couldn‚Äôt have the Python code throwing exceptions outwards, so we had each function return, along with its actual return value (if any), a numeric code identifying the error. Unfortunately, this made the code get really big, really fast - especially once DBus exceptions are thrown into the mix. But once I learned how to use decorators, I accomplished something like this diff: +@wrap_exceptions((False,)) def checkSomething(): - global error_string - - error_string = \"\" - - try: - return (try_doing_something_over_dbus(), RET_OK) - except dbus.DBusException, e: - error_string = str(e) - if _nm_dbus_exception(e, \"ServiceUnknown\"): - return (False, RET_SERVICE_NOT_RUNNING) - return (False, RET_ERROR) - except Exception, e: - error_string = str(e) - return (False, RET_ERROR) - + return (try_doing_something_over_dbus(), RET_OK) Now, the duplicate DBus/non-DBus exception handling, global error_string, etc. - that happened in a lot of functions. Unfortunately, they didn‚Äôt all return their values in the same way. Some just returned a RET_VALUE, but most had other values before it in the tuple (not the ideal design, come to think of it‚Ä¶). Here‚Äôs the decorator I wrote: class wrap_exceptions: def __init__(self, prepend_tuple=None): self.prepend_tuple = prepend_tuple def tuplize(self, retval): # Change retval into a default tuple form, if necessary if not self.prepend_tuple: return retval return tuple(list(self.prepend_tuple) + [retval]) def __call__(self, f): def exception_wrapped(*args, **kargs): global error_string error_string = \"\" try: return f(*args, **kargs) except dbus.DBusException, e: # Check known DBus Exceptions first if _nm_dbus_exception(e, \"ServiceUnknown\"): return self.tuplize(RET_SERVICE_NOT_RUNNING) # Unknown exceptions (DBus) error_string = str(e) # Includes get_dbus_name return self.tuplize(RET_ERROR) except Exception, e: # Unknown exceptions (non-DBus) error_string = repr(e) return self.tuplize(RET_ERROR) return exception_wrapped ","date":"2007-09-16","objectID":"/posts/exception-handling-decorators-and-python/:0:0","tags":["software","python"],"title":"Exception handling, decorators, and python","uri":"/posts/exception-handling-decorators-and-python/"},{"categories":null,"content":"First of all, new iPods won‚Äôt work on Linux. Now, while it‚Äôs very obvious that the idea is to block competition against other music vendors, that makes it even less legitimate. Good thing we‚Äôre starting to see some very nice cheap players out there - I‚Äôve been rather impressed with the Meizu M6 MiniPlayer. Secondly, they didn‚Äôt think of this: Indexed search within the ‚ÄúOpen‚Äù dialog. It‚Äôs in Ubuntu Gutsy, and really makes desktop search (implemented with Tracker in gutsy) worthwhile. Especially when attaching files in GMail :) ","date":"2007-09-16","objectID":"/posts/two-reasons-apple-suck/:0:0","tags":["software"],"title":"Two reasons Apple suck","uri":"/posts/two-reasons-apple-suck/"},{"categories":null,"content":"Despite having a critical midterm Sunday, as well as being sick, I could not, and should not have, give up on the NaNuchKa show. Some of the best music I‚Äôve ever heard, no doubt, and with the unexpectedly intimate setting, I had the opportunity to get to know the truly incredible Yula after the show. They‚Äôre playing in Tel-Aviv today, at the Koltura, where I was supposed to‚Ä¶ Fantastic music, at any rate. Keep your ears open! ","date":"2007-07-27","objectID":"/posts/nanuchka/:0:0","tags":["music"],"title":"NaNuchKa","uri":"/posts/nanuchka/"},{"categories":null,"content":"Some things renew your faith in people, in the time you spend with them. Amazingly small things, considering their grand scope. Making things worse is known to be easy, and rebuilding is one of the hardest things we have to do in life. But sometimes, when things turn out to be completely different than they seem - new perspective is gained, old perspective is found again, and like something out of an old Disney cartoon, kitschy clouds of gloom make way for kitschy rays of sunshine. Complete with the smiling sun and everything. Like freakin‚Äô Roger Rabbit :) Finally, the story gets the ending it deserves. ","date":"2007-07-23","objectID":"/posts/some-things-make-you-feel-good/:0:0","tags":["life"],"title":"Some things make you feel good","uri":"/posts/some-things-make-you-feel-good/"},{"categories":null,"content":" Paradox the cow Another action shot with Paradox I present to you, the only creature which is more of a celebrity in the undergrad CS world than I am‚Ä¶ The Cow. (Paradox) Edit: Yes, that‚Äôs me. No, that‚Äôs not my bass. That‚Äôs a very good friend‚Äôs Fender Fat Stratocaster. So smooooth‚Ä¶ Edit: Photo by some chum ;) ","date":"2007-06-07","objectID":"/posts/all-hail-the-cow/:0:0","tags":["asides","technion"],"title":"All hail the cow!","uri":"/posts/all-hail-the-cow/"},{"categories":null,"content":"Recording this morning was excellent! Awesome studio, not expensive at all, and a whole lot of fun. We‚Äôve posted one song at our myspace page, and it seems that Lior has found an apt name for the CD (hint) ;) For those of you who don‚Äôt want to visit Myspace (can‚Äôt blame you), here‚Äôs the song we posted, as well as an extra track (my personal favorite), Falsely Accused. The deal Falsely Accused I really want to point out the incredible recording studio we used - it‚Äôs a place called MIX◊°◊ï◊ú◊ô◊ì◊ô in Tel Hanania. The man charged us very little, and the equipment and space are excellent. As you can probably tell, those are just demo recordings - recorded ‚Äúlive‚Äù, with plenty of mistakes, and with very minimal balance and sound tweaking. We‚Äôll definitely be going back there to record a more serious version. ","date":"2007-06-02","objectID":"/posts/some-music-posted-to-myspace/:0:0","tags":["music"],"title":"Some music posted to myspace","uri":"/posts/some-music-posted-to-myspace/"},{"categories":null,"content":"This Saturday we‚Äôre going to record our material, and hopefully a cover we‚Äôve been working on - Venom‚Äôs excellent ‚ÄúSchool Daze‚Äù. We took some photos yesterday, visible here: http://www.myspace.com/switchblade777/photos/albums/my-photos/8265381 We have a show at the Koltura Club on July 12th.2 Link modified to accomodate mists of time.¬†‚Ü©Ô∏é Poster lost in the mists of time, show ended up being cancelled at the last moment.¬†‚Ü©Ô∏é ","date":"2007-05-31","objectID":"/posts/some-band-stuff/:0:0","tags":["music"],"title":"Some band stuff","uri":"/posts/some-band-stuff/"},{"categories":null,"content":"Life is good, for the most part. And as a technology enthusiast, there are many new and cool things to see online. For example, there‚Äôs the new Schools site, part of the Vaya project which helps Israeli schools use Linux; this site uses the up-and-coming Lahak CMS, built on the Django framework, and looks very promising to the eyes of the bidi-lingual webmaster. However, some things just plain suck. One of them is myspace; today, in an attempt to make it more legible, I found that My Band‚Äôs Page implements all of its styling changes by a ‚Äústyle‚Äù tag hidden within the ‚ÄúMembers‚Äù text block. Myspace doesn‚Äôt filter this out - nor does it provide any other means of changing the styling. This, combined with myspace‚Äôs horrid administration interface, makes editing incredible unwieldy. I‚Äôm considering opening another Wordpress site for the band here on this server‚Ä¶ And on that topic - Wordpress 2.2 is out. Shinier. Faster. Built-in support for sidebar modules. And K2 broke :(. I love K2‚Ä¶ Even though now that sidebars are implemented, the only thing I really need is a very simple template that allows me an ordinary, rectangular logo. Update: I didn‚Äôt even notice, but the excellent K2 guys released a fix. However, it seems that when you copy the plugin they created directly, it inadvertantly adds a space to the end of the file - and PHP proceeds to barf. Hard to believe people still use this junk to develop websites‚Ä¶ They should use other junk. ","date":"2007-05-17","objectID":"/posts/myspace-sucks/:0:0","tags":["music","software"],"title":"Myspace sucks","uri":"/posts/myspace-sucks/"},{"categories":null,"content":"By now I‚Äôve lost count of how long ago my last class was. The strike has begun immediately after passover, and is certainly beginning to take its toll. For one thing, I have no homework deadlines - a rare situation indeed for the Technion student. Furthermore, contemplations are rising about whether or not this coming summer semester will be held, as the current semester will most likely leak into it. This is of special interest to me, as I‚Äôm behind on my degree, which is problematic because of my military scholarship. This is shaping up to be the second time in which, while I‚Äôve been authorized by the military to take a summer semester for completion, I am not able to. However, one cannot trivially dismiss this strike; in a country which is known worldwide mostly for its technological exports and frequent bloodbaths, one shouldn‚Äôt take the matter of tuition lightly. The vacation was not, however, boring - I got to spend a lot of time with my lovely girlfriend, a chance to see friends I have not seen in a long time, and a lot of posts racked up in various forums. The vacation actually expanded far enough to contain independence day, so I managed to experience the closest thing to a hangover I‚Äôd ever had (But that was some great scotch). Actually, independence day could have been truly superb; the whole thing got me thinking about what the perfect night out would be: It‚Äôs obviously best with my girlfriend. It would probably start with a rock show of sorts, continue with food and beer, and end in my girlfriend‚Äôs bed. Better yet - if I‚Äôm in the show. Better still - if there‚Äôs no reason to get up early the following day. Another item of interest is that I‚Äôve joined a band. Hopefully I‚Äôll be able to keep up the 3-hours-on-Saturday rehearsals. It‚Äôs a ‚ÄúTrash Metal‚Äù band which has evidently had really bad experience with bass players. Unfortunately, we seem to have a myspace page. It looks‚Ä¶ myspaceish. However, I really think the group has potential, as well as excellent influences. Furthermore, I‚Äôm an attention whore :D. Hopefully I‚Äôll be able to help influence the band into more of a heavy-metal direction by harassing them with melodic basslines. Very little geek news this time, other than the fact that Feisty Fawn is out. My verdict - get it. It‚Äôs awesome. Period. Suspend works much better, NetworkManager is now installed by default, a lot of things have really been polished, and - can you believe it - Sudoku :)! If you already run Ubuntu, I‚Äôd advise against using the update manager - it works, but it takes a long time, and cannot run unattended. Also, a word of caution to server admins though - sqlite3 is the new default, so if you have sqlite2 databases you‚Äôll need to convert them (use the sqlite and sqlite3 binaries to do this) - otherwise you‚Äôll get ‚Äúfile is not a database, or is encrypted‚Äù errors. Whew - that‚Äôs much better. My thoughts have been depleted into the bits and bytes before you. I‚Äôll just plug a friend‚Äôs blog and hit the publish button now ;) ","date":"2007-04-24","objectID":"/posts/on-the-matter-of-a-really-long-vacation/:0:0","tags":["music","technion","life"],"title":"On the matter of a really long vacation","uri":"/posts/on-the-matter-of-a-really-long-vacation/"},{"categories":null,"content":"A lot of people ask me how to change the default operating system booted after installing Linux. The answer they get in Ubuntu‚Äôs case, ‚ÄúEdit /boot/grub/menu.lst, it‚Äôs self-explanatory‚Äù, is often unsatisfactory. Attached is the solution :) Actual script lost in the mists of time‚Ä¶ Download the file, open a terminal, and run gksudo python grubmenu.py I‚Äôll try and make a package of this soon, so it becomes a menu entry and that much easier to use. ","date":"2007-04-19","objectID":"/posts/grub-menu-lst-editor/:0:0","tags":["linux"],"title":"Grub menu.lst editor","uri":"/posts/grub-menu-lst-editor/"},{"categories":null,"content":"Why was it down, you ask? Well, it was out here in the lab, because of a shortage of network ports in the server room. From the acpid log: [Sun Apr 15 18:53:07 2007] received event \"button/power PWRF 00000080 00000001\" That is, at 18:53, someone simply pushed the power button. The server promptly closed all processes and properly shut itself down. I‚Äôve moved it into the server room now‚Ä¶ ","date":"2007-04-16","objectID":"/posts/yasmin-back-up/:0:0","tags":["linux"],"title":"Yasmin back up","uri":"/posts/yasmin-back-up/"},{"categories":null,"content":"The more I use Python, the nicer it becomes. I‚Äôm currently working on a project for a course, which involves somewhat heavy-duty database and algorithm work. Python is my language of choice for it - let‚Äôs hope it works out well. In the meantime, I‚Äôve found a really nice python shell called iPython (available in apt) - it adds a bunch of stuff to the python shell which I sorely missed from irb - autocompletion, auto-indentation, and - it seems - adds a whole lot more. Looks like I‚Äôll have to check django out as well. I‚Äôve been working with Ruby on Rails for quite a while now (and that‚Äôs how I got introduced to Ruby in the first place). Odd as it may be‚Ä¶ do I have a new favorite language? ","date":"2007-03-04","objectID":"/posts/ipython/:0:0","tags":["software","python"],"title":"IPython","uri":"/posts/ipython/"},{"categories":null,"content":"A very neat find for those of you who want to use Jabber from within the Technion, but with your client of choice rather than a web-based one: Many Jabber servers, including Google Talk, support using Port 443 over SSL. Since the Technion does not block outbound SSL connections, this will work there as well. Be sure to mark the appropriate ‚ÄòUse old SSL protocol‚Äô option in your jabber client (that‚Äôs what it‚Äôs called in gaim and pidgin, at any rate). ","date":"2007-02-27","objectID":"/posts/using-jabber-from-within-the-technion/:0:0","tags":["networking","technion"],"title":"Using Jabber from within the Technion","uri":"/posts/using-jabber-from-within-the-technion/"},{"categories":null,"content":"Check that the RAID it supports is actual Raid. My experience today: Decide that secondary server should gradually become more and more primary Decide that since it has two 160GB hard drives and built-in RAID, we should use that for mirroring Mail (both!) users of the secondary server that it‚Äôll be down for rebuilding Set up RAID array from BIOS, clearing all old information Insert installation CD Notice that installation still sees two hard drives Discover that built-in NVRaid is actually software RAID Disable built in RAID in favor of LVM, proceed to reinstall :( ","date":"2007-02-26","objectID":"/posts/before-reinstalling-your-server-for-raid/:0:0","tags":["hardware"],"title":"Before reinstalling your server for RAID","uri":"/posts/before-reinstalling-your-server-for-raid/"},{"categories":null,"content":"I brought my Fender Squier Jazz Bass up to my Technion apartment. I hope it won‚Äôt have too much of an adverse effect on my studying‚Ä¶ playing it (loud) is great for stress, and I‚Äôm taking a jazz improvisation course next semester. By the way - if any of you record with one of these, I highly recommend Arour, using a low-pass LADSPA filter. Also, activating both pickups on about 80% does wonders against hum if you connect directly. ","date":"2007-02-25","objectID":"/posts/bass-guitar/:0:0","tags":["music"],"title":"Bass guitar","uri":"/posts/bass-guitar/"},{"categories":null,"content":"I‚Äôve converted my Antigibberish script1 (converts ‚Äúbroken hebrew‚Äù into proper hebrew, useful for sent-offline ICQ messages) to Python‚Ä¶ it‚Äôs quite a nice language, and the interpreter is FAST! I‚Äôm really torn between it and Ruby :( Used to have a copy of antigibberish.py, but it‚Äôs been lost in the mists of time. It used to do the equivalent of this: iconv -f utf-8 -t iso8859-1 | iconv -f iso8859-8 -t utf-8¬†‚Ü©Ô∏é ","date":"2007-02-25","objectID":"/posts/really-liking-the-whole-python-thing/:0:0","tags":["software","python"],"title":"Really liking the whole Python thing","uri":"/posts/really-liking-the-whole-python-thing/"},{"categories":null,"content":" def factor(grade, params = {}) return 100 if params.empty? # Optimistic, eh? case params[:type] when :pass return 55 when :fail return 54 when :root params[:gamma] = 0.5 end grade = grade.to_f return params[:proc].call(grade) if params[:proc] grade *= params[:coefficient] if params[:coefficient] if params[:gamma] grade /= 100 grade **= params[:gamma] grade *= 100 end if params[:offset] grade += params[:offset] end return grade if params[:idnoclip] [ grade, 100 ].min end ","date":"2007-02-14","objectID":"/posts/heres-hoping/:0:0","tags":["technion"],"title":"Here's hoping","uri":"/posts/heres-hoping/"},{"categories":null,"content":"In the Haifa Bay Central bus station (◊û◊®◊õ◊ñ◊ô◊™ ◊î◊û◊§◊®◊•), it‚Äôs possible to get an internet connection. HTTPS works automatically, and setting the proxy to proxy.technion.ac.il:8080 works for HTTP. I was unsuccessful in using corkscrew to get SSH connections to tunnel over it as well, but perhaps there is still a way. ","date":"2007-02-10","objectID":"/posts/internet-in-haifa-bay-central/:0:0","tags":["networking"],"title":"Internet in Haifa Bay Central","uri":"/posts/internet-in-haifa-bay-central/"},{"categories":null,"content":"This man has some beautiful design ideas for the Linux desktop. ","date":"2007-02-08","objectID":"/posts/beautiful-ideas/:0:0","tags":["software","linux"],"title":"Beautiful ideas","uri":"/posts/beautiful-ideas/"},{"categories":null,"content":"I‚Äôve heard the latest Security Now, regarding the debate between Dave Marsh and Peter Guttman on DRM in Windows Vista. While a few good points were made, the major one - in my opinion - was not. DRM, in a practical sense, is deeply flawed: The idea is to give you your media - say, a WMA piece of music - and a program to play it with - say, Windows Media Player - but encrypt the media. Now, naturally, Media Player will need the decryption key for the media, and the idea is that Media Player will verify that you are allowed to listen to the song, and only then decrypt it - as it is played. However, something is clearly wrong here - both the encrypted media and the decryption key are sitting locally on your computer. It‚Äôs like giving you a locked box, as well as a butler (which will live in your house, where you presumably have a shotgun) with the key, and telling the butler not to open the box for anyone unauthorized. That is, you can open the Windows Media Player executable with your favorite hex editor, and dig away for the key. This is, of course, very complicated to do - but there are advanced ways of finding these keys, and once they‚Äôre found - they‚Äôre out. That‚Äôs why we keep hearing about WMA and iTunes‚Äô equivalent format being cracked every once in a while, when they change it. No matter how sophisticated the DRM, you still get both the locked box and the key. They might build bigger butlers, but we can build deadlier shotguns. (Sorry for the violent analogy, but DRM kinda does that to me ;)) So, what can the *AA/Microsoft/Apple/DRM scapegoats inc. do about this? Well, they could supposedly have Windows recognize that you are trying to view the Windows Media Player executable, and stop you (I‚Äôd be surprised if they haven‚Äôt done this yet). However, currently you can still, for example, run Linux on the computer, and use that to view the executable. And if, by some crazy coincidence, all variants of Linux stop you from viewing the executable - you can pick your favorite, change the source code so it doesn‚Äôt, and use that. To stop you from running whatever unprotected operating system you want, changes to the hardware must be made. This is exactly what worries me about Vista. For the first time, we are seeing major effects like HDMI/HDCP, where the operating system interacts with the hardware directly to figure out exactly what the user is or isn‚Äôt allowed to do. Also, Vista boasts the ‚ÄúTrustworthy Computing‚Äù project, which is all too reminiscent of ‚ÄúTrusted Computing‚Äù - a project in which, through integrating protection from the bottom of the hardware (with a TPM, Trusted Platform Module chip) to the top of the software, the computer verifies that it is only running authorized operating systems, which run only authorized programs. Now, the media companies would love this. Say HD-DVD‚Äôs been completely cracked, and an alternative, open-source, unprotected player has been released. If your system is TPM-protected, it simply won‚Äôt allow this software to run. Your own compiled applications can be forbidden from running as well, seeing as their source code just might be the HD-DVD cracking code. Unauthorized operating systems would, naturally, not be allowed to run. Now, I‚Äôm not explicitly blaming Microsoft for this. Fact of the matter is, the protection they‚Äôve built into Vista, although probably (for the reasons I‚Äôve mentioned) insufficient, was required by the media companies in order for HD-DVD support to be (legally/technically) possible in Vista. Would Microsoft go so far as to enable the horror scenario I‚Äôve pictured above? Probably not. But I do believe we all need to be aware of the risks, just to be on the safe side. ","date":"2007-02-07","objectID":"/posts/why-vista-worries-me/:0:0","tags":["software","security"],"title":"Why Vista worries me","uri":"/posts/why-vista-worries-me/"},{"categories":null,"content":"Well, penny knows. But I have proof she knows‚Ä¶ http://www.wisdom.weizmann.ac.il/~naor/PUZZLES/waldo.html ","date":"2007-02-05","objectID":"/posts/i-know-where-waldo-is/:0:0","tags":["security"],"title":"I know where waldo is","uri":"/posts/i-know-where-waldo-is/"},{"categories":null,"content":"Everyone knew this was going to be an interesting one to watch. Die-hard Microsoft fans were sure Vista would be the final nail in the Open Source coffin, die-hard Linux fans were sure that the release would be Microsoft‚Äôs demise. Myself - I‚Äôm sitting and enjoying the show. It‚Äôs always very interesting to show Beryl to non-Linux users. They are almost always highly impressed, and are often completely in shock that Linux is a graphical system - many people still believe Linux is command-line only. But the funniest thing is that they always seem to care more about useless, spinning, transparent desktop cubes than, say, security. This holds for Vista‚Äôs flashy new graphics, as well - mainstream media seems to be focusing on Vista‚Äôs GUI a lot more than they are about its controversial new security features. Very interesting, keeping in mind that Windows has never been ‚Äúnot pretty enough‚Äù in consumer‚Äôs eyes, but rather too unstable or virus-prone. Controversial security? Yup. And I‚Äôm not even talking about the actually controversy-worth topics, like DRM‚Ä¶ I‚Äôm talking about the system asking if you‚Äôre sure you want to set the clock. I‚Äôve heard more noise about this than the fact that all of Vista‚Äôs new features pale in comparison to 7-year-old OS X which, incidentally, also ‚Äúasks if you‚Äôre sure‚Äù that you want to set the clock. Nobody complains about that however. Why? In my opinion - it‚Äôs the password prompt. Just as people complained about Windows XP‚Äôs ‚ÄúFisher-Price‚Äù theme, they‚Äôre now complaining about being treated like little kids. ‚ÄúAre you sure you want to set your clock?‚Äù - how condescending of the operating system. The reason it works well in Linux and OS X is that the system phrases the exact same question completely differently - ‚ÄúYou are attempting to run ‚Äúsystem-config-date‚Äù which requires administrative privileges‚Äù. Cryptic, right? I think they changed that for Ubuntu, too (I‚Äôm writing this off a Fedora box). But most users won‚Äôt have a hard time understanding that this, coupled with the password entry box, means that the system wants to make sure you are indeed someone allowed to set the clock. Hell, I believe that most people won‚Äôt have a problem making the logical leap from there to ‚Äúhmm, perhaps setting the clock (im)properly can really mess up my system‚Äù. Either way, it‚Äôs much more pleasing than Vista‚Äôs seemingly endless, senseless sequences of ‚ÄúAre you sure?‚Äù dialog boxes. A password prompt like this tells the user - ‚ÄúYou‚Äôre opening the hood here, watch your step‚Äù, the idea being that the user takes a hint and, realizing he has arrived at a password-protected part of his system, will indeed watch his proverbial step. But nobody is going to ditch windows over a couple of dialog boxes. There are much more interesting reasons to do that - I‚Äôve heard of much instability, inavailability of drivers, confusions in the user interface‚Ä¶ all of the things that Microsoft worked very hard to get rid of when XP was released, making Vista look like a step back. But most of all - it‚Äôs the timing. Vista‚Äôs 2007 release has given the world time to hear about shiny new Linux distributions, macs that run all of their old software, indexing services at least as powerful as Vista‚Äôs (now that WinFS has gone down the drain), more advanced graphical ‚Äúshinyness‚Äù which works on older systems, and the horrors of DRM (thanks for that one, Sony). With nothing really new to give them, a high price tag (because it often includes a new computer), and several years of not being in the habit of buying a new OS, people have very little motivation to upgrade to Vista. But I don‚Äôt think that Microsoft and Windows are going anywhere, anytime soon. I do think Vista‚Äôs lost the battle - but to XP. Vista‚Äôs launch made people realize how successful XP was as an operating system, and the sheer momentum will keep people there. If Microsoft locks people out of technologies like DirectX 10 by making them Vista-only, this will keep people leaking away to OS X and Li","date":"2007-02-04","objectID":"/posts/on-vista/:0:0","tags":["software"],"title":"On Vista","uri":"/posts/on-vista/"},{"categories":null,"content":"This is absolutely antique (2000), but it‚Äôs good to hear an artist with a clue. http://archive.salon.com/tech/feature/2000/06/14/love/print.html ","date":"2007-02-02","objectID":"/posts/courtney-love-on-piracy/:0:0","tags":["life"],"title":"Courtney Love on Piracy","uri":"/posts/courtney-love-on-piracy/"},{"categories":null,"content":"If you‚Äôre like me, and don‚Äôt use Gnome or KDE, then you probably use the pmount or pmount-hal applications to mount removable media. Here‚Äôs a neat thing to add to your .bash_aliases: function pmh { pmount-hal $1 UDI=`hal-find-by-property --key block.device --string $1` cd \"`hal-get-property --udi $UDI --key volume.mount_point`\" } ","date":"2007-02-01","objectID":"/posts/pmount-hal-cd/:0:0","tags":["linux"],"title":"Pmount-hal + cd","uri":"/posts/pmount-hal-cd/"},{"categories":null,"content":"I do type mesmerizingly fast, though‚Ä¶ :) Wanted poster I am told these were scattered around Taub‚Ä¶ I haven‚Äôt been there to day, but it feels good to be infamous. ","date":"2007-01-31","objectID":"/posts/i-do-not-kick-puppies/:0:0","tags":["asides"],"title":"I do NOT kick puppies!","uri":"/posts/i-do-not-kick-puppies/"},{"categories":null,"content":"My lecture slides. Have a peek if you like :) sybilproof Reputation Mechanisms - Seminar ","date":"2007-01-30","objectID":"/posts/i-might-need-these-tomorrow/:0:0","tags":["technion"],"title":"I might need these tomorrow...","uri":"/posts/i-might-need-these-tomorrow/"},{"categories":null,"content":"When approaching a port, the Scotsman: You will never find a more wretched hive of scum and villany. And the crab cakes ain‚Äôt too bad, either! Later on: Is it fast? It sure is. But it‚Äôs gonna cost ya - 10,000 up-front. 10,000? We could buy our own ship for that! But who‚Äôs gonna sail it? I can. I piloted (some smaller kind of ship) back when I was a kid. (and if you haven‚Äôt seen Star Wars, you‚Äôre just not gonna get it) ","date":"2007-01-30","objectID":"/posts/samurai-jack-ingenious/:0:0","tags":["asides"],"title":"Samurai Jack - Ingenious!","uri":"/posts/samurai-jack-ingenious/"},{"categories":null,"content":"I‚Äôm going home for the weekend, as usual. Unfortunately, the first bus of my route comes by at highly unpredictable times - I‚Äôve had it be an hour late on me once. There are plenty of Wi-fi networks around the station - either WPA, WEP or MAC-whitelisted‚Ä¶ fortunately, someone was using the latter long enough for me to catch him with Kismet. Thank you, stranger! :) It‚Äôs a sad state of affairs that people go ahead and limit access to their wireless network. I keep mine wide open - ◊û◊ô ◊©◊ê◊ï◊õ◊ú ◊ú◊ë◊ì, ◊û◊™ ◊ú◊ë◊ì. ","date":"2007-01-25","objectID":"/posts/waiting-for-the-bus/:0:0","tags":["networking"],"title":"Waiting for the bus","uri":"/posts/waiting-for-the-bus/"},{"categories":null,"content":"My new work desktop has a GeForce 4 MX, so I naturally installed Beryl on it. The graphics card has relatively little RAM, so it finds handling my 1280x1024 resolution difficult when additional texture memory is needed - so using something like Firefox really slows it down when Beryl is activated, making me keep it off most of the time. However, for coding, I‚Äôm finding that Beryl is very useful - it actually helps me that the code windows are transparent, so that I can see what‚Äôs underneath them, and the ‚ÄúExpose‚Äù effect still leaves text legible, which is great for reading off a lot of terminals at once. So is Beryl‚Ä¶ a programmer‚Äôs tool? ","date":"2007-01-25","objectID":"/posts/3d-effects-for-coders/:0:0","tags":["software"],"title":"3D effects for coders?","uri":"/posts/3d-effects-for-coders/"},{"categories":null,"content":"Sometimes imperfections in Software drive me nuts. It‚Äôs what drove me away from Windows. It‚Äôs what keeps me switching back and forth between desktop environments. It‚Äôs what has me wasting a lot of time getting the software to do what I want, instead of getting anything done. I even have two particularily good examples. Firefox¬†and¬†Opera¬†are¬†my¬†two¬†favorite¬†browsers.¬†Opera¬†is¬†actually¬†not¬†as¬†good, in my taste, as Firefox. Firefox‚Äôs slew of extensions (especially my latest favorites - Del.icio.us bookmarks and Firebug), better font handling (on Linux) and Open-Source nature¬†keep¬†it¬†ahead, if¬†all¬†things¬†were¬†equal. However, Opera is¬†much¬†faster¬†on¬†my¬†laptop.¬†Way¬†faster. And with the kind of browsing I usually do - zillions of tabs open and all, that difference counts. My other good example is LaTeX. I have the Beamer package, which makes absolutely stunning presentations in my favorite style of document creation - writing and compiling source code. However, one little thing drives me nuts about it - the symbols in math mode, even if I set it to Serif (Beamer uses sans-serif fonts by default), are not the default ones, which I prefer. For example, the symbol for ‚Äú\\in‚Äù (a member of a set) looks horrible in my opinion. This tiny little thing had me chasing font preferences around for half an hour, to no avail. Graphviz. Ruby on Rails. Networkmanager. Openbox. IVMan. The list goes on‚Ä¶ almost every piece of software I use has a little imperfection - not necessarily a bug, usually a missing features - that drives me crazy. Maybe I should quit my degree so I have time to fix all of those? ","date":"2007-01-25","objectID":"/posts/software-perfection-lost-in-the-details/:0:0","tags":["software"],"title":"Software Perfection - Lost in the details","uri":"/posts/software-perfection-lost-in-the-details/"},{"categories":null,"content":"Just finished downloading an episode of American¬†Dad off Bittorrent. TV has ancient episodes of Family Guy. Took about an hour though‚Ä¶ I tells ya, I‚Äôd pay for this kind of service if it were faster‚Ä¶ ;) ","date":"2007-01-23","objectID":"/posts/alright-american-dad/:0:0","tags":["show downloading"],"title":"Alright, American Dad!","uri":"/posts/alright-american-dad/"},{"categories":null,"content":"Myself, I‚Äôm a Ruby hacker. I send everyone within earshot to TryRuby, code my sites using Rails, am surprised that I‚Äôm using a php-based blog‚Ä¶ you get the picture. Ruby is sometimes called the Japanese Python, and comparisons are inevitable. I know very little about Python, but I do know that‚Ä¶ It has a larger community More GUI applications are written in it More bindings are available for it Its interpreter is much faster Not a far inferior language Ruby certainly does have its advantages over it - trivial class expansion, extremely concise syntax, seemingly better-suited for heavy usage of closures, and Matz. Ya gotta love Matz. I will be giving Python a try soon‚Ä¶ I love learning new programming languages. That‚Äôs why I‚Äôm taking Programming Languages this coming semester. ","date":"2007-01-23","objectID":"/posts/as-for-python/:0:0","tags":["software","technion"],"title":"As for Python","uri":"/posts/as-for-python/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. ◊ß◊¶◊™ ◊í◊ô◊ß◊ô◊ï◊™ ◊ô◊™◊®◊î, ◊ë◊®◊©◊ï◊™◊õ◊ù üòâ ◊î◊™◊ß◊†◊™◊ô ◊ê◊™ ◊î◊í◊ô◊®◊°◊î ◊û-CVS ◊©◊ú ◊û◊†◊î◊ú ◊î◊ó◊ú◊ï◊†◊ï◊™ ◊î◊ê◊î◊ï◊ë ◊¢◊ú◊ô◊ô, Openbox, ◊ú◊ß◊®◊ê◊™ ◊î◊í◊®◊°◊î ◊î◊û◊™◊¢◊™◊ì◊™ ◊ú◊¶◊ê◊™ 3.3, ◊ï◊û◊ê◊ï◊ì ◊î◊™◊®◊©◊û◊™◊ô ◊ú◊ò◊ï◊ë◊î: ◊†◊ï◊°◊§◊î ◊™◊û◊ô◊õ◊î ◊ë-Pango, ◊ê◊ñ ◊¢◊ë◊®◊ô◊™ ◊°◊ï◊£-◊°◊ï◊£ ◊¢◊ï◊ë◊ì◊™ ◊õ◊û◊ï ◊©◊¶◊®◊ô◊ö (◊ô◊© ◊ú◊ß◊û◊§◊ú ◊¢◊ù ◊î◊ì◊í◊ú with-pango ◊î◊§◊ê◊•‚Äô ◊ú-Split gradients ◊†◊õ◊†◊°, ◊û◊î ◊©◊†◊ï◊™◊ü ◊ú-Themes ◊û◊û◊© ◊ô◊§◊ô◊ù ◊ú◊¢◊ë◊ï◊ì. ◊û◊î ◊©◊õ◊ü, ◊î◊ù ◊©◊ô◊†◊ï ◊ê◊™ ◊©◊ù ◊î◊î◊í◊ì◊®◊î ◊û-‚Äúsplit‚Äù ◊ú-‚Äúsplitvertical‚Äù, ◊ê◊ñ ◊¶◊®◊ô◊ö ◊ú◊©◊†◊ï◊™ ◊ê◊™ ◊ñ◊î ◊ë◊ß◊ï◊ë◊• themerc ◊©◊ú ◊õ◊ú theme ◊®◊ú◊ï◊ï◊†◊ò◊ô ◊û◊¶\"◊ë ◊™◊û◊ï◊†◊™-◊û◊°◊ö. ◊©◊û◊ô◊ô◊ó ‚ò∫Ô∏è (◊™◊û◊ï◊†◊™-◊î◊û◊°◊ö ◊†◊©◊û◊®◊î ◊ë-Imageshack, ◊ï◊û◊ê◊ñ ◊†◊û◊ó◊ß◊î) ◊¢◊®◊ô◊õ◊î: ◊ê◊†◊ô ◊®◊ï◊¶◊î ◊í◊ù ◊ú◊¶◊ô◊ô◊ü ◊ú◊©◊ë◊ó ◊ê◊™ Obmenu, ◊™◊ï◊õ◊†◊î ◊©◊û◊ê◊ï◊ì ◊û◊ß◊ú◊î ◊¢◊ú ◊¢◊®◊ô◊õ◊™ ◊î◊™◊§◊®◊ô◊ò◊ô◊ù ◊©◊ú Openbox. ","date":"2006-08-26","objectID":"/posts/openbox-cvs/:0:0","tags":["hebrew"],"title":"Openbox CVS","uri":"/posts/openbox-cvs/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. Context: 2006 Lebanon War ◊î◊ó◊ë◊®‚Äô◊î ◊î◊ò◊ï◊ë◊ô◊ù ◊ë-lgf ◊û◊®◊ê◊ô◊ù - ◊î◊§◊ú◊ê ◊ï◊§◊ú◊ê - ◊ê◊ô◊ö ◊ë◊î◊©◊ï◊ï◊ê◊î ◊ë◊ô◊ü ◊†◊ñ◊ß ◊§◊í◊ô◊¢◊ï◊™ ◊ô◊©◊ô◊®◊ï◊™ ◊©◊ú ◊ß◊ò◊ô◊ï◊©◊ï◊™ ◊ï◊ò◊ô◊ú◊ô ◊ê◊ï◊ï◊ô◊®-◊ß◊®◊ß◊¢ ◊ô◊©◊®◊ê◊ú◊ô◊ô◊ù, ◊î◊ß◊ò◊ô◊ï◊©◊î ◊¢◊ï◊©◊î ◊î◊®◊ë◊î ◊ô◊ï◊™◊® ◊†◊ñ◊ß. ◊ë◊†◊ï◊°◊£, ◊ê◊ú ◊™◊õ◊†◊°◊ï ◊ú◊ë◊ú◊ï◊í ◊©◊ú ◊ê◊ó◊û◊ì◊ô◊†◊ô◊í‚Äô◊ê◊ì ◊¢◊ù ◊ê◊ß◊°◊§◊ú◊ï◊®◊®. ◊ñ◊î ◊û◊°◊ï◊õ◊ü. ◊û◊ï◊ï◊™ ◊ú◊ß◊ô◊¶◊ï◊†◊ô◊ù üòâ ","date":"2006-08-15","objectID":"/posts/katyusha-damage/:0:0","tags":["hebrew"],"title":"◊ê◊î◊ë◊™◊ô ◊ê◊™ ◊©◊†◊ô ◊ê◊ú◊î","uri":"/posts/katyusha-damage/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. ◊û◊®◊¶ ◊û◊¶◊ô◊¢◊î: ◊ú◊î◊ï◊¶◊ô◊ê ◊ê◊™ ◊©◊ô◊™◊ï◊£ ◊î◊ß◊ë◊¶◊ô◊ù ◊ê◊ú ◊û◊ó◊ï◊• ◊ú◊ó◊ï◊ß. ◊î◊õ◊ï◊™◊®◊™ ◊ê◊ï◊ú◊ô ◊†◊©◊û◊¢◊™ ◊û◊ò◊¢◊î, ◊ô◊ó◊©◊ï◊ë ◊ú◊ï ◊î◊ß◊ï◊®◊ê ◊î◊™◊û◊ô◊ù - ◊î◊®◊ô ◊ï◊ï◊ì◊ê◊ô ◊ï÷º◊ï◊ï◊ì◊ê◊ô ◊©◊ú◊û◊®◊• ◊ê◊ô◊ü ◊ë◊¢◊ô◊î ◊¢◊ù ◊©◊ô◊™◊ï◊£ ◊ß◊ë◊¶◊ô◊ù ◊ë◊ê◊ï◊§◊ü ◊õ◊ú◊ú◊ô, ◊ï◊õ◊û◊ï◊ë◊ü ◊©◊î◊û◊ê◊ë◊ß ◊©◊ú◊î◊ù ◊û◊®◊ï◊°◊ü ◊ú◊¢◊†◊ô◊ô◊ü ◊¢◊ë◊ô◊®◊ï◊™ ◊ë◊†◊ï◊©◊ê ◊ß◊†◊ô◊ô◊ü ◊®◊ï◊ó◊†◊ô. ◊ê◊ö ◊ú◊ê ◊ï◊ú◊ê - ◊î◊°◊¢◊ô◊£ ◊î◊®◊ë◊ô◊¢◊ô ◊ë◊î◊¶◊¢◊™ ◊î◊ó◊ï◊ß ◊©◊ú◊î◊ù ◊û◊ï◊¶◊ô◊ê ◊û◊ó◊ï◊• ◊ú◊ó◊ï◊ß ◊™◊ï◊õ◊†◊ï◊™ ◊ï◊©◊ô◊®◊ï◊™◊ô◊ù ◊ú◊©◊ô◊™◊ï◊£ ◊ß◊ë◊¶◊ô◊ù. ◊ë◊õ◊ú◊ú. ◊ñ◊î ◊©◊û◊ê◊ú ◊ñ◊î? ◊ñ◊ï ◊§◊®◊ô◊û◊ô◊ò◊ô◊ï◊ï◊ô◊ï÷º◊™ ◊û◊ó◊©◊ë◊™◊ô◊™ ◊ó◊û◊ï◊®◊î ◊û◊û◊î ◊©◊ê◊†◊ó◊†◊ï ◊®◊ï◊ê◊ô◊ù ◊û◊î-RIAA. ◊ú◊ñ◊õ◊ï◊™◊ù ◊ô◊ê◊û◊® ◊õ◊ô ◊î◊ù ◊™◊ï◊û◊õ◊ô◊ù ◊ë◊§◊™◊®◊ï◊ü ◊ë◊ì◊û◊ï◊™ ◊û◊ô◊°◊ï◊ô ◊©◊ú ◊î◊í◊ï◊ú◊©◊ô◊ù - ◊ê◊ë◊ú ◊¢◊ï◊©◊î ◊®◊ï◊©◊ù ◊©◊î◊ù ◊û◊û◊î◊®◊ô◊ù ◊ú◊ï◊ï◊™◊® ◊ë◊ó◊ñ◊ô◊™ ◊ñ◊ï. ◊ê◊õ◊ñ◊ë◊î ◊¢◊û◊ï◊ß◊î ◊û◊û◊§◊ú◊í◊î ◊©◊®◊ê◊ô◊™◊ô ◊ë◊î ◊°◊ô◊õ◊ï◊ô ◊ú◊®◊§◊ï◊®◊û◊î ◊ë\"◊ß◊†◊ô◊ô◊ü ◊®◊ï◊ó◊†◊ô\" ◊ï◊™◊û◊ô◊õ◊î ◊ë◊™◊ï◊õ◊†◊î ◊ó◊ï◊§◊©◊ô◊™. ","date":"2006-08-15","objectID":"/posts/shame-on-meretz/:0:0","tags":["hebrew"],"title":"◊ë◊ï◊©◊î ◊ï◊ó◊®◊§◊î ◊ú◊û◊®◊¶","uri":"/posts/shame-on-meretz/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. ◊ë◊î◊™◊ó◊ú◊î ◊§◊ú◊ê◊© ◊î◊ô◊î ◊û◊©◊î◊ï ◊ß◊ò◊ü ◊ï◊ó◊û◊ï◊ì. ◊î◊©◊™◊û◊©◊™◊ô ◊ë◊ï ◊ë◊õ◊ô◊™◊î ◊ï‚Äô ◊ë◊©◊ë◊ô◊ú ‚Äú◊§◊®◊ï◊ô◊ô◊ß◊ò ◊°◊ô◊ï◊ù‚Äù ◊¢◊ú ◊í◊ú◊í◊ï◊ú◊ô ◊ê◊†◊®◊í◊ô◊ô◊î, ◊ë◊¢◊ï◊ì ◊©◊ê◊ó◊®◊ô◊ù ◊î◊õ◊ô◊†◊ï ◊û◊õ◊©◊ô◊®◊ô◊ù ◊©◊ú◊ê ◊î◊ô◊ï ◊û◊ë◊ô◊ô◊©◊ô◊ù ◊ê◊™ The Incredible Machine. ◊ñ◊î ◊î◊û◊©◊ô◊ö ◊ë◊õ◊ú ◊û◊ô◊†◊ô ◊û◊©◊ó◊ß◊ô◊ù ◊ß◊ò◊†◊ô◊ù ◊ë◊ê◊™◊® ◊©◊ú Shockwave. ◊ú◊ê◊ò ◊ú◊ê◊ò ◊ñ◊î ◊î◊§◊ö ◊ú◊û◊¢◊¶◊ë◊ü, ◊õ◊©◊ê◊†◊©◊ô◊ù ◊î◊ó◊ú◊ô◊ò◊ï ◊©-HTML ◊ñ◊î ◊°◊™◊ù ◊õ◊û◊î ◊ò◊ê◊í◊ô◊ù ◊©◊©◊û◊ô◊ù ◊õ◊ì◊ô ◊©◊î◊ì◊§◊ì◊§◊ü ◊ô◊¶◊ô◊í ◊ê◊™ ◊î◊§◊ú◊ê◊© ◊©◊î◊ï◊ê ◊ë◊¢◊¶◊ù ◊î◊ê◊™◊®. ◊ê◊ï ◊ú◊ó◊ô◊ú◊ï◊§◊ô◊ü, ◊î◊ó◊ú◊ô◊ò◊ï ◊©◊§◊ú◊ê◊© ◊ñ◊î ◊ê◊ó◊ú◊î ◊û◊ì◊ô◊ï◊ù ◊ú◊§◊®◊°◊ï◊û◊ï◊™, ◊û◊î ◊©◊î◊ï◊ë◊ô◊ú ◊ú◊î◊ï◊§◊¢◊™ AdBlock. ◊ê◊ë◊ú ◊ë◊ñ◊û◊ü ◊î◊ê◊ó◊®◊ï◊ü ◊¢◊ï◊©◊î ◊®◊ï◊©◊ù ◊©◊°◊ï◊£-◊°◊ï◊£ ◊û◊¶◊ê◊ï ◊ê◊™ ◊î◊ô◊ô◊¢◊ï◊ì ◊î◊ê◊û◊ô◊™◊ô ◊©◊ú ◊§◊ú◊ê◊© - ◊°◊®◊ò◊ï◊†◊ô ◊ï◊ï◊ô◊ì◊ê◊ï ◊î◊ô◊™◊ï◊ú◊ô◊ô◊ù. ◊ï◊î◊í◊®◊°◊î ◊î◊ê◊ó◊®◊ï◊†◊î ◊©◊ú ◊§◊ú◊ê◊© ◊¢◊ï◊©◊î ◊ê◊™ ◊ñ◊î ◊†◊î◊ì◊® - ◊ë◊ê◊û◊¶◊¢◊ï◊™ Codec ◊ß◊†◊ô◊ô◊†◊ô ◊ó◊ì◊© ◊ï◊û◊™◊ï◊ó◊õ◊ù, ◊î◊°◊®◊ò◊ô◊ù ◊ô◊ï◊®◊ì◊ô◊ù ◊ó◊ô◊©-◊ß◊ú. ◊î◊ë◊ô◊¶◊ï◊¢◊ô◊ù ◊ò◊ï◊ë◊ô◊ù, ◊î◊¢◊ï◊û◊° ◊¢◊ú ◊î◊û◊¢◊®◊õ◊™ ◊û◊ô◊†◊ô◊û◊ú◊ô‚Ä¶ ◊ë◊ß◊ô◊¶◊ï◊® - ◊õ◊ï◊ú◊ù ◊†◊î◊†◊ô◊ù. ◊ê◊ë◊ú ◊ú◊ê ◊ú◊õ◊ï◊ú◊ù ◊ô◊© ◊ê◊™ ◊î◊í◊®◊°◊ê ◊î◊ê◊ó◊®◊ï◊†◊î ◊î◊ñ◊ï. ◊ú◊ê ◊ú◊õ◊ï◊ú◊ù ◊ê◊§◊ô◊ú◊ï ◊ô◊© ◊ê◊™ ◊í◊®◊°◊î 8. ◊û◊©◊™◊û◊©◊ô ◊ú◊ô◊†◊ï◊ß◊° ◊™◊ß◊ï◊¢◊ô◊ù ◊¢◊ù ◊í◊®◊°◊î 7 - ◊ï◊í◊®◊°◊î ◊í◊®◊ï◊¢◊î ◊©◊ú ◊í◊®◊°◊î 7. ◊õ◊ú ◊ê◊ï◊ë◊ô◊ô◊ß◊ò ◊§◊ú◊ê◊© ◊™◊ï◊§◊° ◊î-◊û-◊ï-◊ü ◊û◊©◊ê◊ë◊ô ◊û◊¢◊®◊õ◊™. ◊î◊ù ◊¢◊ï◊ë◊ì◊ô◊ù ◊ú◊ê◊ò, ◊î◊°◊ê◊ï◊†◊ì ◊ú◊ê ◊û◊°◊ï◊†◊õ◊®◊ü (◊ê◊ú◊ê ◊ê◊ù ◊û◊©◊™◊û◊©◊ô◊ù ◊ë-aoss, ◊û◊î ◊©◊û◊ï◊°◊ô◊£ ◊ú◊§◊í◊ï◊¢ ◊ë◊ô◊¶◊ô◊ë◊ï◊™), ◊ï◊î-Codec ◊î◊ó◊ì◊© ◊ï◊î◊†◊§◊ú◊ê ◊î◊ñ◊î - ◊©◊õ◊ó◊ï ◊û◊û◊†◊ï. ◊ë◊ê◊™◊®◊ô ◊î◊ï◊ï◊ô◊ì◊ê◊ï ◊©◊ë◊õ◊ú ◊ñ◊ê◊™ ◊ì◊ï◊ê◊í◊ô◊ù ◊ú◊™◊û◊ï◊ö ◊ë◊§◊ú◊ê◊© 7 ◊ê◊§◊©◊® ◊ú◊®◊ê◊ï◊™ ◊ê◊™ ◊î◊°◊®◊ò◊ô◊ù ◊ô◊ï◊®◊ì◊ô◊ù ◊ú◊ê◊ò-◊ú◊ê◊ò. ◊ë-Youtube, ◊ú◊û◊¢◊©◊î, ◊ê◊§◊ô◊ú◊ï ◊ê◊™ ◊ñ◊î ◊ê◊ô ◊ê◊§◊©◊® ◊ú◊®◊ê◊ï◊™ - ◊¶◊®◊ô◊ö ◊ú◊†◊ó◊© ◊û◊™◊ô ◊î◊°◊®◊ò ◊°◊ô◊ô◊ù ◊ú◊®◊ì◊™. ◊í◊®◊ï◊¢ ◊û◊õ◊ö, Adobe (◊î◊ë◊¢◊ú◊ô◊ù ◊î◊ó◊ì◊©◊ô◊ù ◊©◊ú ◊§◊ú◊ê◊©) ◊õ◊ú ◊§◊¢◊ù ◊ê◊ï◊û◊®◊ô◊ù ◊©\"◊î◊í◊®◊°◊î ◊î◊ó◊ì◊©◊î ◊ú◊ú◊ô◊†◊ï◊ß◊° ◊ô◊ï◊¶◊ê◊™ ◊ë◊ß◊®◊ï◊ë\". ◊õ◊ö ◊î◊ù ◊ê◊û◊®◊ï ◊ë◊§◊ú◊ê◊© 8. ◊õ◊©◊ú◊ê ◊ô◊¶◊ê, ◊ê◊û◊®◊ï ◊©◊ô◊î◊ô◊î 8.5. ◊¢◊õ◊©◊ô◊ï ◊î◊ù ◊ê◊ï◊û◊®◊ô◊ù ◊ê◊™ ◊ê◊ï◊™◊ï ◊î◊ì◊ë◊® ◊ë-9. ◊õ◊®◊í◊¢ ◊™◊ê◊®◊ô◊ö ◊î◊ô◊¢◊ì ◊î◊û◊§◊ï◊®◊°◊ù ◊î◊ï◊ê ‚Äú◊û◊ï◊ß◊ì◊ù ◊ë-2007‚Äù, ◊ï◊î◊ù ◊ê◊§◊ô◊ú◊ï ◊ò◊®◊ó◊ï ◊ú◊î◊¢◊ú◊ï◊™ ◊ë◊ú◊ï◊í ◊©◊ú ◊ê◊ó◊ì ◊û◊î◊û◊§◊™◊ó◊ô◊ù. ◊û◊¢◊†◊ô◊ô◊ü ◊û◊ê◊ï◊ì ◊û◊î ◊©◊î◊ï◊ú◊ö ◊ë◊ë◊ú◊ï◊í ◊î◊ñ◊î, ◊ê◊í◊ë - ◊î◊ù ◊ê◊ï◊û◊®◊ô◊ù ◊©◊î◊ù ◊¢◊ï◊ë◊ì◊ô◊ù ◊†◊ï◊®◊ê ◊ß◊©◊î ◊¢◊ú ◊ú◊í◊®◊ï◊ù ◊ú◊™◊ê◊ô◊û◊ï◊™ ◊¢◊ù ◊û◊¶◊ú◊û◊ï◊™ ◊ï◊ï◊ô◊ì◊ê◊ï ◊ë◊ú◊ô◊†◊ï◊ß◊°, ◊ï◊ú◊ï◊ï◊ì◊ê ◊©◊õ◊û◊î ◊©◊ô◊ï◊™◊® ◊û◊¶◊ú◊û◊ï◊™ ◊¢◊ï◊ë◊ì◊ï◊™. ◊¢◊õ◊©◊ô◊ï, ◊™◊í◊ô◊ì◊ï ◊ú◊ô - ◊û◊ô◊©◊î◊ï ◊õ◊ê◊ü ◊ê◊ô ◊§◊¢◊ù ◊®◊ê◊î ◊°◊®◊ò◊ï◊ü ◊§◊ú◊ê◊© ◊©◊ê◊©◊õ◊®◊î ◊û◊©◊™◊û◊© ◊ë◊û◊¶◊ú◊û◊™ ◊ï◊ï◊ô◊ì◊ê◊ï? ◊ê◊ô◊§◊î◊©◊î◊ï? ◊©◊ô◊û◊ï ◊ú◊ô◊†◊ß ◊ë◊™◊í◊ï◊ë◊ï◊™. ◊í◊®◊ï◊¢ ◊û◊õ◊ö - ◊î◊ù ◊ê◊ï◊û◊®◊ô◊ù ◊©◊õ◊®◊í◊¢ ◊î◊ù ◊ú◊ê ◊û◊©◊ó◊®◊®◊ô◊ù ◊í◊®◊°◊™ ◊ë◊ò◊ê ◊õ◊ô ◊ú◊û◊®◊ï◊™ ◊©◊î◊°◊ê◊ï◊†◊ì ◊û◊°◊ï◊†◊õ◊®◊ü ◊§◊®◊§◊ß◊ò ◊ï-Youtube ◊¢◊ï◊ë◊ì ◊ì◊ô ◊ò◊ï◊ë, ◊¢◊ì◊ô◊ô◊ü ◊ô◊© ◊î◊®◊ë◊î ◊ë◊¢◊ô◊ï◊™ ◊ô◊¶◊ô◊ë◊ï◊™. ◊ê◊ñ ◊ô◊© ◊ú◊ô ◊ó◊ì◊©◊ï◊™ ◊ë◊©◊ë◊ô◊ú◊õ◊ù ◊ó◊ë◊®◊ô◊ù - ◊í◊ù ◊ë◊í◊ô◊®◊°◊î ◊î◊†◊ï◊õ◊ó◊ô◊™ ◊ô◊© ◊î◊û◊ï◊ü ◊ë◊¢◊ô◊ï◊™ ◊ô◊¶◊ô◊ë◊ï◊™! ◊©◊ó◊®◊®◊ï ◊ê◊™ ◊ñ◊î ◊û◊¶◊ô◊ì◊ô ◊ë◊í◊ô◊®◊°◊™ ‚Äú◊°◊ï◊§◊®-◊î◊ô◊§◊®-◊ê◊ú◊§◊î-◊ê◊ú-◊™◊í◊¢◊ï-◊ô◊ê-◊ó◊ê◊®◊ï◊™‚Äù! ◊ï◊®◊ß ◊¢◊ï◊ì ◊†◊ß◊ï◊ì◊î ◊ê◊ó◊™. ◊ê◊ï◊û◊®◊ô◊ù ◊ë◊§◊ï◊®◊ï◊û◊ô◊ù ◊ê◊ó◊®◊ô◊ù ◊©◊ñ◊î ◊ë◊¢◊ô◊î ◊©◊ú ◊ß◊î◊ô◊ú◊™ ◊î◊ß◊ï◊ì ◊î◊§◊™◊ï◊ó ◊©◊ú◊ê ◊§◊ô◊™◊ó◊†◊ï ◊í◊®◊°◊î ◊û◊©◊ú◊†◊ï ◊ú◊§◊ú◊ê◊©. ◊ú◊û◊®◊ë◊î ◊î◊¶◊¢◊®, ◊§◊ú◊ê◊© ◊û◊©◊™◊û◊© ◊ë◊û◊°◊§◊® ◊ê◊ú◊û◊†◊ò◊ô◊ù ◊ß◊†◊ô◊ô◊†◊ô◊ô◊ù - ◊î◊ó◊©◊ï◊ë ◊ë◊ô◊†◊ô◊î◊ù ◊î◊ï◊ê ◊î◊ß◊ï◊ì◊ß ◊î◊ó◊ì◊© ◊©◊ú ◊î◊ï◊ï◊ô◊ì◊ê◊ï. ◊û◊î ◊ú◊¢◊©◊ï◊™, ◊õ◊ê◊ü ◊ê◊†◊ó◊†◊ï ◊™◊ú◊ï◊ô◊ô◊ù ◊ë-Adobe. ◊ñ◊î◊ï, ◊ô◊¶◊ê ◊î◊ß◊ô◊ò◊ï◊®. ◊ë◊ó◊ñ◊®◊î ◊ú-Youtube. üôÇ ","date":"2006-08-14","objectID":"/posts/flash-in-linux/:0:0","tags":["hebrew"],"title":"◊î◊û◊¶◊ë ◊©◊ú ◊§◊ú◊ê◊© ◊ë◊ú◊ô◊†◊ï◊ß◊°","uri":"/posts/flash-in-linux/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. Context: 2006 Lebanon War ◊û◊û◊© ◊©◊ß◊ò. ◊ú◊ê ◊©◊û◊™◊ô ◊©◊¢◊ï◊ü ◊û◊¢◊ï◊®◊®, ◊õ◊ô ◊°◊û◊õ◊™◊ô ◊¢◊ú ◊î◊†◊°◊®◊ê◊ú◊ú◊î ◊î◊û◊¢◊ï◊®◊®. ◊ë◊õ◊ú◊ú, ◊î◊ô◊©◊ï◊ë ◊©◊ú◊ô ◊û◊ó◊ï◊ë◊® ◊ú◊ê◊ñ◊¢◊ß◊ï◊™ ◊©◊ú ◊õ◊ú ◊î◊ê◊®◊• (◊õ◊ô ◊î◊ï◊ê ◊ë◊ê◊û◊¶◊¢ ◊©◊ï◊ù ◊û◊ß◊ï◊ù) ◊ê◊ñ ◊ê◊†◊ó◊†◊ï ◊û◊ß◊ë◊ú◊ô◊ù ◊í◊ù ◊ê◊ñ◊¢◊ß◊ï◊™ ◊©◊ú ◊ß◊®◊ô◊™ ◊©◊û◊ï◊†◊î. ◊õ◊ë◊® ◊î◊ô◊î ◊õ◊ú ◊õ◊ö ◊©◊ß◊ò, ◊©◊ê◊ë◊ê ◊©◊ú◊ô ◊ß◊¶◊™ ◊î◊ú◊ö ◊ú◊ô◊©◊ï◊ü‚Ä¶ ◊ï◊ê◊ñ ◊ê◊†◊ô ◊©◊ï◊û◊¢ ◊ì◊®◊ö ◊î◊û◊ñ◊í◊ü ◊ê◊ñ◊¢◊ß◊î, ◊¶◊ï◊¢◊ß ‚Äú◊ê◊ñ◊¢◊ß◊î‚Äù, ◊ï◊ê◊û◊ê ◊©◊ú◊ô ◊ê◊ï◊û◊®◊™ ◊ú◊î◊ô◊ï◊™ ◊ë◊©◊ß◊ò ◊õ◊ô ◊ê◊ë◊ê ◊ô◊©◊ü‚Ä¶ ","date":"2006-08-12","objectID":"/posts/nice-and-quiet/:0:0","tags":["hebrew"],"title":"◊ì◊ï◊ï◊ß◊ê ◊î◊ô◊î ◊†◊ó◊û◊ì, ◊©◊ß◊ò ◊ï◊õ◊ê◊ú◊î","uri":"/posts/nice-and-quiet/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. Context: 2006 Lebanon War ◊õ◊ï◊ú◊†◊ï ◊®◊ê◊ô◊†◊ï ◊ê◊ï◊™◊ï ◊ë◊ò◊ú◊ï◊ï◊ô◊ñ◊ô◊î ◊ï◊ë◊™◊û◊ï◊†◊ï◊™. ◊ß◊®◊ê◊†◊ï ◊ê◊™ ◊î◊õ◊™◊ë◊ï◊™, ◊®◊ê◊ô◊†◊ï ◊ê◊™ ◊î◊¶◊ô◊ú◊ï◊û◊ô◊ù ◊©◊ú ◊ê◊ô◊ö ◊©◊î◊ï◊ê ◊û◊ï◊®◊ô◊ì ◊ê◊™ ◊î◊í◊ï◊§◊ï◊™ ◊û◊î◊ê◊û◊ë◊ï◊ú◊†◊° ◊õ◊ì◊ô ◊©◊ô◊¶◊ú◊û◊ï ◊©◊ï◊ë, ◊¢◊ù ◊§◊ï◊ß◊ï◊° ◊ô◊ï◊™◊® ◊ò◊ï◊ë ◊ï◊ë◊ú◊ô ◊©◊ê◊†◊©◊ô◊ù ◊ô◊°◊™◊ô◊®◊ï. ◊ê◊ô◊ö ◊ë◊û◊©◊ö ◊©◊¢◊ï◊™ ◊î◊ï◊ê ◊°◊ï◊ó◊ë ◊ê◊ï◊™◊î ◊í◊ï◊§◊î ◊î◊ú◊ï◊ö ◊ï◊©◊ï◊ë ◊ë◊©◊ë◊ô◊ú ◊î◊û◊¶◊ú◊û◊ï◊™. ◊ï◊©◊ê◊ô◊õ◊©◊î◊ï ◊î◊ï◊ê ◊™◊û◊ô◊ì ◊û◊¶◊ú◊ô◊ó ◊ú◊î◊í◊ô◊¢ ◊ú◊õ◊ú ◊ñ◊ô◊®◊î ◊û◊¶◊ï◊ú◊û◊™. ◊ï◊¢◊õ◊©◊ô◊ï ◊ô◊© ◊ú◊ï ◊ë◊ú◊ï◊í ◊û◊©◊ú◊ï! üôÇ ","date":"2006-08-11","objectID":"/posts/green-helmet-guy/:0:0","tags":["hebrew"],"title":"◊î◊ó◊ë◊ï◊ë ◊¢◊ù ◊î◊ß◊°◊ì◊î ◊î◊ô◊®◊ï◊ß◊î - ◊¢◊õ◊©◊ô◊ï ◊î◊ë◊ú◊ï◊í","uri":"/posts/green-helmet-guy/"},{"categories":null,"content":" Hebrew post This post is written in Hebrew, which was the blog‚Äôs language at the time. Context: 2006 Lebanon War ◊û◊ú◊ó◊û◊î. ◊†◊°◊®◊ê◊ú◊ú◊î ◊©◊ï◊ú◊ó ◊¢◊ú◊ô◊†◊ï ◊ë◊ï◊û◊ô◊ù. ◊ê◊†◊ó◊†◊ï ◊©◊ï◊ú◊ó◊ô◊ù ◊¢◊ú◊ô◊ï ◊ë◊ï◊û◊ô◊ù (◊õ◊ú 10 ◊©◊†◊ô◊ï◊™ ◊ô◊¶◊ô◊ê◊î ◊©◊ú◊†◊ï ◊ê◊™◊û◊ï◊ú ◊ë◊ú◊ô◊ú◊î, ◊ï◊î◊™◊®◊ô◊°◊ô◊ù ◊®◊ï◊¢◊ì◊ô◊ù). ◊ï◊ê◊†◊ô ◊ë◊ë◊ô◊™, ◊¢◊ï◊©◊î ◊ë◊ï◊û◊ô◊ù ◊û◊©◊ú◊ô. ◊ñ◊î ◊ú◊ê ◊õ◊û◊ï ◊ú◊†◊í◊ü ◊¢◊ù ◊ó◊ë◊®◊ô◊ù, ◊ñ◊î ◊ú◊ê ◊õ◊û◊ï ◊ú◊î◊ï◊§◊ô◊¢, ◊ê◊ë◊ú ◊ú◊§◊ó◊ï◊™ ◊°◊ï◊£ ◊°◊ï◊£ ◊í◊ô◊ú◊ô◊™◊ô ◊ê◊ô◊ö ◊ú◊í◊®◊ï◊ù ◊ú◊ñ◊î ◊ú◊î◊ô◊©◊û◊¢ ◊†◊ï◊®◊û◊ê◊ú◊ô. ◊î◊¶◊ô◊ï◊ì - ◊ë◊° ◊í‚Äô◊ê◊ñ ◊©◊ú ◊°◊ß◊ï◊ô◊ô◊®. ◊ê◊ì◊ï◊ù. ◊õ◊ë◊ú LP - ◊í◊ù ◊ê◊ì◊ï◊ù. ◊û◊ß◊ò◊ô◊ü LP ◊ï◊ú◊§◊ò◊ï◊§. ◊î◊™◊ï◊õ◊†◊î - Ardour, ◊ô◊ó◊ì ◊¢◊ù ◊õ◊û◊î ◊§◊ú◊ê◊í◊ô◊†◊ô◊ù ◊©◊ú LADSPA. ◊ê◊ñ ◊û◊î ◊©◊í◊ô◊ú◊ô◊™◊ô ◊ñ◊î ◊õ◊õ◊î - ◊ú◊î◊§◊¢◊ô◊ú ◊ê◊™ ◊©◊†◊ô ◊î◊§◊ô◊ß◊ê◊§◊ô◊ù ◊¢◊ú ◊ê◊ï◊™◊ï ◊ï◊ï◊ú◊ô◊ï◊ù, ◊ï◊©◊ú◊ê ◊ô◊î◊ô◊î ◊¢◊ì ◊î◊°◊ï◊£. ◊õ◊õ◊î ◊î◊ù ◊û◊ë◊ò◊ú◊ô◊ù ◊ê◊™ ◊î◊î◊û◊î◊ï◊ù. ◊ú◊î◊©◊™◊û◊© ◊ë-lowpass filter ◊õ◊ì◊ô ◊ú◊ë◊ò◊ú ◊ê◊™ ◊î◊®◊ó◊©◊ô◊ù ◊î◊í◊ë◊ï◊î◊ô◊ù ◊ú◊î◊©◊™◊û◊© ◊ë-compressor, ◊ï◊ú◊ë◊ó◊ï◊® ◊ê◊ï◊™◊ï ◊ë◊ß◊§◊ô◊ì◊î. ◊õ◊õ◊î ◊ô◊©◊û◊¢◊ï ◊ê◊™ ◊î-hammer-ons/pull-offs ◊î◊®◊ë◊î ◊ô◊ï◊™◊® ◊ò◊ï◊ë, ◊ï◊ê◊§◊©◊® ◊ú◊†◊í◊ü ◊ó◊ú◊© ◊ê◊ï ◊ó◊ñ◊ß ◊ë◊ú◊ô ◊©◊ñ◊î ◊ô◊®◊ì ◊û◊î◊°◊ß◊ê◊ú◊î ◊ë◊û◊°◊¢ ◊ú◊î◊ï◊¶◊ô◊ê ◊ê◊™ ◊î◊ê◊ô◊†◊§◊ï◊®◊û◊¶◊ô◊î ◊î◊ñ◊ï ◊¢◊ú◊ô◊™◊ô ◊¢◊ú ◊ê◊ó◊ú◊î ◊ú◊î◊ß◊î ◊û◊ê◊ô◊ò◊ú◊ô◊î. ◊©◊ï◊ï◊î ◊î◊ê◊ñ◊†◊î. ","date":"2006-08-11","objectID":"/posts/recording-booms/:0:0","tags":["hebrew"],"title":"◊û◊ß◊ú◊ô◊ò◊ô◊ù ◊ë◊ï◊û◊ô◊ù","uri":"/posts/recording-booms/"},{"categories":null,"content":" This is a handy little page for copying the stress mark (acute mark) to clipboard. Useful if your Russian keyboard doesn't support it. ÃÅ Copy","date":"0001-01-01","objectID":"/russian-stress/:0:0","tags":null,"title":"Russian stress mark","uri":"/russian-stress/"}]